{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this notebook , our focus is on implementing linear regression for hedging purposes. To start off, we will begin by implementing some utility functions that will assist us in this process.\n",
    "![](https://miro.medium.com/v2/resize:fit:1200/1*tqBA_mQw1UExgVaF-JBneg.png)\n",
    "### Implementation of Helpful Functions for Linear Regression Hedge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import BDay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function performs rolling linear regression on the provided dataframe and calculates delta values. It provides flexibility to include additional features, leverage calculations, and customization based on different parameters.\n",
    "\n",
    "Rolling linear regression refers to the process of applying a linear regression model to a sliding window of data points. Instead of performing regression on the entire dataset at once, it is done iteratively on sequential subsets of the data.\n",
    "\n",
    "In the context of this code, rolling linear regression is performed within each test period and group. It means that for each period and group combination, the code divides the data into training and testing subsets. The regression model is then fitted using the training data, and the resulting coefficients are used to predict target values for the corresponding testing data.\n",
    "\n",
    "By sliding the window through the dataset, the regression model is updated and applied to different subsets, capturing any changes or patterns in the relationship between the predictors and the target variable over time or across different groups. \n",
    "\n",
    "Code explanation:\n",
    "This code defines the `run_linear_regression` function, which performs rolling linear regression. The function takes several input parameters and returns a dictionary containing the resulting dataframes.\n",
    "\n",
    "- The function then initializes variables and data structures for storing the regression coefficients, fit standard deviations, and leverage values (if applicable).\n",
    "- The code loops through each test period and group in the dataframe. It separates the data into training and testing subsets based on the period and group.\n",
    "- Linear regression is performed on the training data, where the target variable is calculated based on the taret_var parameter and the feature values are multiplied by a factor derived from the stock prices.\n",
    "- The regression model is fitted, and the predicted target values, residuals, and standard deviations are calculated.\n",
    "- If the leverage parameter is set to True, an additional regression is performed on a subset of the training data, and the leverage values are computed based on the regression coefficients.\n",
    "- The regression coefficients, fit standard deviations, and leverage values are stored in their respective dataframes.\n",
    "- Delta values are predicted for the testing data using the regression model.\n",
    "- The delta values are calculated based on the taret_var parameter and the 'delta_bs' column of the original dataframe.\n",
    "- Finally, a dictionary containing the resulting dataframes is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression(sub_res=None, setup_name=None, features=None, df=None, max_period=None, taret_var=None, leverage=False):\n",
    "    \"\"\"\n",
    "    Run the linear regression and store the results in dataframes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Perform rolling linear regression\n",
    "    deltas = pd.Series(index=df.index)\n",
    "    cols_by = ['cp_int']\n",
    "    \n",
    "    grouped = df.groupby(by=cols_by)\n",
    "    group_names = [str(x) for x in grouped.groups.keys()]\n",
    "    tmp = pd.MultiIndex.from_product([group_names, features])\n",
    "    df_coef, df_fit_std = [pd.DataFrame(index=range(max_period+1), columns=tmp) for _ in range(2)]\n",
    "    df_leverage = pd.DataFrame(index=range(max_period+1), columns=group_names) if leverage else None\n",
    "\n",
    "    for i in range(0, max_period + 1):\n",
    "        for name, group in grouped:\n",
    "            is_train = (group[f'period{i}'] == 0) | (group[f'period{i}'] == 1)\n",
    "            is_test = (group[f'period{i}'] == 2)\n",
    "\n",
    "            df_train = group.loc[is_train].copy()\n",
    "            df_test = group.loc[is_test].copy()\n",
    " \n",
    "            if taret_var:\n",
    "                target = df_train['V1_n'] - df_train['V0_n'] * df_train['on_ret'] - df_train['delta_bs'] * (\n",
    "                            df_train['S1_n'] - df_train['S0_n'] * df_train['on_ret'])\n",
    "            else:\n",
    "                target = df_train['V1_n'] - df_train['V0_n'] * df_train['on_ret']\n",
    "\n",
    "            predictors = df_train[features].copy()\n",
    "            predictors = predictors.multiply(df_train['S1_n'] - df_train['S0_n'] * df_train['on_ret'], axis=0)\n",
    "\n",
    "            regression = LinearRegression(fit_intercept=False).fit(predictors, target)\n",
    "\n",
    "            predicted_target = regression.predict(predictors)\n",
    "            residual = (target - predicted_target)\n",
    "            residual_sum_of_squares = (residual ** 2).sum()\n",
    "            sigma_square_hat = residual_sum_of_squares / (predictors.shape[0] - predictors.shape[1])\n",
    "            var_beta = (np.linalg.inv(predictors.T @ predictors) * sigma_square_hat)\n",
    "            std = [var_beta[i, i] ** 0.5 for i in range(len(var_beta))]\n",
    "\n",
    "            if leverage:\n",
    "                is_leverage = df_train['implvol1'].notna()\n",
    "                df_leverage = df_train.loc[is_leverage]\n",
    "                predictors_leverage = (df_leverage['S1_n'] - df_leverage['S0_n']).values.reshape(-1, 1)\n",
    "                target_leverage = df_leverage['implvol1'] - df_leverage['implvol0']\n",
    "                leverage_regression = LinearRegression(fit_intercept=False).fit(predictors_leverage, target_leverage)\n",
    "                var = (leverage_regression.coef_ * df_leverage['vega_n'] / df_leverage['delta_bs']).mean()\n",
    "                df_leverage.loc[i, str(name)] = var\n",
    "\n",
    "            df_coef.loc[i, str(name)] = regression.coef_\n",
    "            df_fit_std.loc[i, str(name)] = std\n",
    "\n",
    "            df_delta = pd.Series(index=df_test.index)\n",
    "            delta = regression.predict(df_test.loc[:, features])\n",
    "            df_delta.loc[:] = delta\n",
    "            deltas.loc[df_test.index] = df_delta\n",
    "\n",
    "    # Calculate delta based on taret_var\n",
    "    if not taret_var:\n",
    "        delta = deltas\n",
    "        results_dict[setup_name] = delta\n",
    "    else:\n",
    "        delta = deltas + df['delta_bs']\n",
    "        results_dict[setup_name] = delta \n",
    "    return {'df_coef': df_coef, 'df_leverage': df_leverage, 'df_fit_std': df_fit_std}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`modify_dataframe` function takes a dataframe, original size, minimum moneyness, and maximum moneyness as input. It removes in-the-money samples and shrinks the moneyness range in the dataframe. It prints information about the sample removal, such as the number of removed samples and the percentage of remaining data.\n",
    "\n",
    "The `modify_dataframe` function shrinks the moneyness range by removing samples that fall outside the specified range.\n",
    "\n",
    "code explanation:\n",
    "\n",
    "1. It first checks whether each sample in the dataframe meets the criteria for being considered in-the-money. For call options, the condition is `df['cp_int'] == 0` and `df['M0'] < 1.001`. For put options, the condition is `df['cp_int'] == 1` and `df['M0'] > 0.999`. The bitwise OR operator (`|`) combines these conditions.\n",
    "\n",
    "2. It calculates the number of samples that meet the in-the-money condition and calculates the percentage of removed samples based on the original size of the dataframe.\n",
    "\n",
    "3. It filters the dataframe to keep only the samples that satisfy the in-the-money condition using the `loc` function.\n",
    "\n",
    "4. Next, it checks whether each sample's moneyness value (`M0`) falls within the specified range (`MIN_MONEYNESS` to `MAX_MONEYNESS`). It uses the bitwise AND operator (`&`) to combine the conditions.\n",
    "\n",
    "5. It calculates the number of samples that fall outside the moneyness range and calculates the corresponding removal percentage.\n",
    "\n",
    "6. It filters the dataframe again to retain only the samples that fall within the desired moneyness range using the `loc` function.\n",
    "\n",
    "7. Finally, it returns the modified dataframe.\n",
    "\n",
    "In summary, the `modify_dataframe` function removes samples that are considered in-the-money or fall outside the specified moneyness range, effectively shrinking the moneyness range of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_dataframe(dataframe, original_size, MIN_MONEYNESS, MAX_MONEYNESS):\n",
    "    \"\"\"\n",
    "    Remove in-the-money samples and shrink the moneyness range in the dataframe.\n",
    "    Print information about sample removal.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove in-the-money samples\n",
    "    in_the_money = ((dataframe['cp_int'] == 0) & (dataframe['M0'] < 1.001)) | ((dataframe['cp_int'] == 1) & (dataframe['M0'] > 0.999))\n",
    "    removed_count = dataframe.shape[0] - sum(in_the_money)\n",
    "    removal_percentage = (removed_count / dataframe.shape[0]) * 100\n",
    "    remaining_percentage = (sum(in_the_money) / original_size) * 100\n",
    "    print(f\"Removing in-the-money samples: {removed_count} samples ({removal_percentage:.2f}%) removed. \"\n",
    "          f\"{remaining_percentage:.2f}% of data remaining. Current size of data: {sum(in_the_money)}.\")\n",
    "\n",
    "    dataframe = dataframe.loc[in_the_money]\n",
    "\n",
    "    # Shrink moneyness range\n",
    "    within_moneyness_range = (dataframe['M0'] >= MIN_MONEYNESS - 0.001) & (dataframe['M0'] <= MAX_MONEYNESS + 0.001)\n",
    "    removed_count = dataframe.shape[0] - sum(within_moneyness_range)\n",
    "    removal_percentage = (removed_count / dataframe.shape[0]) * 100\n",
    "    remaining_percentage = (sum(within_moneyness_range) / original_size) * 100\n",
    "    print(f\"Shrinking moneyness range: {removed_count} samples ({removal_percentage:.2f}%) removed. \"\n",
    "          f\"{remaining_percentage:.2f}% of data remaining. Current size of data: {sum(within_moneyness_range)}.\")\n",
    "\n",
    "    dataframe = dataframe.loc[within_moneyness_range]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `remove_columns_rename` function is responsible for removing specific columns from a dataframe and renaming certain columns based on provided dictionaries. It removes specific columns from the dataframe based on the provided `whole_dictionary` and renames certain columns using the `renaming_dictionary`. This allows for selective column removal and renaming in the dataframe.\n",
    "\n",
    "\n",
    "Code explanation:\n",
    "\n",
    "1. The function takes four parameters: `dataframe` (the input dataframe), `whole_dictionary` (a dictionary containing column information), `single_key` (a key from `whole_dictionary`), and `future_volume` (an optional parameter indicating whether to consider the future volume column).\n",
    "\n",
    "2. It creates a copy of the `whole_dictionary` called `remove_frequency` to prevent modifying the original dictionary.\n",
    "\n",
    "3. The function removes columns from the dataframe based on the values in `remove_frequency`. It iterates over the items in `remove_frequency` using a for loop.\n",
    "\n",
    "4. For each item, it retrieves the tag (value[1]) and identifies columns in the dataframe that contain this tag. It uses a list comprehension to create a list of columns to be removed.\n",
    "\n",
    "5. It then iterates over the columns to be removed and deletes them from the dataframe using the `del` keyword.\n",
    "\n",
    "6. Next, it creates a dictionary called `renaming_dictionary` to store the renaming mappings for specific columns. The dictionary is populated based on the provided `single_key` and the values in `whole_dictionary`.\n",
    "\n",
    "7. The dictionary maps the original column names to their corresponding new names. For example, if `whole_dictionary[single_key][1]` is equal to 2, it renames columns with the pattern `S2` to `S1` and so on.\n",
    "\n",
    "8. If `future_volume` is `True`, it adds an additional mapping for the volume column.\n",
    "\n",
    "9. Finally, it applies the renaming_dictionary to the dataframe using the `rename` function with the `inplace=True` parameter, effectively renaming the columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns_rename(dataframe, whole_dictionary, single_key, future_volume=None):\n",
    "    remove_frequency = whole_dictionary.copy()\n",
    "    remove_frequency.pop(single_key)\n",
    "\n",
    "    for key, value in remove_frequency.items():\n",
    "        tag = value[1]\n",
    "        columns_to_remove = [column for column in dataframe.columns if tag in column]\n",
    "        for col in columns_to_remove:\n",
    "            del dataframe[col]\n",
    "\n",
    "    renaming_dictionary = {\n",
    "        f\"S{whole_dictionary[single_key][1]}\": \"S1\",\n",
    "        f\"V{whole_dictionary[single_key][1]}\": \"V1\",\n",
    "        f\"V{whole_dictionary[single_key][1]}_atm\": \"V1_atm\",\n",
    "        f\"implvol{whole_dictionary[single_key][1]}\": \"implvol1\",\n",
    "        f\"S{whole_dictionary[single_key][1]}_n\": \"S1_n\",\n",
    "        f\"V{whole_dictionary[single_key][1]}_n\": \"V1_n\",\n",
    "        f\"V{whole_dictionary[single_key][1]}_atm_n\": \"V1_atm_n\"\n",
    "    }\n",
    "\n",
    "    if future_volume:\n",
    "        renaming_dictionary[f\"volume{whole_dictionary[single_key][1]}\"] = \"volume1\"\n",
    "\n",
    "    dataframe.rename(columns=renaming_dictionary, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `add_custom_features` function takes an input dataframe and adds custom features to it. Here's a breakdown of the code.\n",
    "\n",
    "Code explanation:\n",
    "\n",
    "1. The function starts by creating a copy of the input dataframe using the `copy()` method to ensure that the original dataframe is not modified.\n",
    "\n",
    "2. The first feature, custom feature 1 , is calculated by taking the square root of the `tau0` column and multiplying it by the `implvol0` column.\n",
    "\n",
    "3. The second feature, custom feature 2 , is calculated by taking the square root of the `tau0` column.\n",
    "\n",
    "4. The third feature, custom feature 3 , is calculated by taking the reciprocal of the square root of the `tau0` column.\n",
    "\n",
    "5. The next set of features, custom feature 4, custom feature 5 , and custom feature 6 , are calculated for additional analysis. custom feature 4 is obtained by dividing the `vega_n` column by the product of the `S0_n` column (stock price) and the square root of the `tau0` column. custom feature 5  is the product of the `delta_bs` column and custom feature 4 , while custom feature 6 is obtained by squaring the `delta_bs` column and multiplying it by custom feature 4.\n",
    "\n",
    "6. Finally, the modified dataframe with the added features is returned.\n",
    "\n",
    "This code allows for the creation of custom features based on various calculations involving existing columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_custom_features(input_df):\n",
    "    \"\"\"\n",
    "    Add custom features to the input dataframe.\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe\n",
    "    df = input_df.copy()\n",
    "\n",
    "    # Calculate the feature: tau0_implvol0\n",
    "    df['tau0_implvol0'] = np.sqrt(df['tau0']) * df['implvol0']\n",
    "\n",
    "    # Calculate the feature: sqrt_tau0\n",
    "    df['sqrt_tau0'] = np.sqrt(df['tau0'])\n",
    "\n",
    "    # Calculate the feature: 1_over_sqrt_tau\n",
    "    df['1_over_sqrt_tau'] = 1 / np.sqrt(df['tau0'])\n",
    "\n",
    "    # Calculate features for additional analysis\n",
    "    df['vega_s'] = df['vega_n'] / (df['S0_n'] * np.sqrt(df['tau0']))\n",
    "    df['delta_vega_s'] = df['delta_bs'] * df['vega_s']\n",
    "    df['delta2_vega_s'] = (df['delta_bs']**2) * df['vega_s']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code explanation:\n",
    "\n",
    "The `assign_data_tag` function is used to assign data tags to a specific period in the dataframe. It takes the following parameters:\n",
    "- `dataframe`: The input dataframe to which the data tags will be assigned.\n",
    "- `data_tag`: The tag indicating whether the data belongs to the train, validation, or test set.\n",
    "- `data_period`: The period for which the data tags will be assigned.\n",
    "- `data_offset`: The business offset used to determine the end of the assigned period.\n",
    "- `start_date`: The start date of the assigned period.\n",
    "- `end_date`: The end date of the assigned period.\n",
    "\n",
    "The function first checks if the `data_offset` is a `pd.Timedelta` object. If it is, and the offset is less than or equal to 2 hours, the `data_end` is set to the `end_date`. Otherwise, the `data_end` is calculated by subtracting the `data_offset` from the `end_date`.\n",
    "\n",
    "Next, the function filters the dataframe based on the specified date range using a boolean mask. The mask is created by checking if the date is within the start and end date range. The filtered rows in the dataframe are then assigned the corresponding data tag using the `loc` indexer and the `f'period{data_period}'` column.\n",
    "\n",
    "Finally, the modified dataframe is returned with the assigned data tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_data_tag(dataframe, data_tag=None, data_period=None, data_offset=None, start_date=None, end_date=None):\n",
    "    \"\"\"\n",
    "    Assign data tags to a specified period in the dataframe.\n",
    "    The data_tag indicates whether the data belongs to the train, validation, or test set.\n",
    "    The assigned data_period is from the start_date to (end_date - business_offset).\n",
    "    \"\"\"\n",
    "    # Check if the offset is a Timedelta object\n",
    "    if isinstance(data_offset, pd.Timedelta):\n",
    "        if data_offset <= pd.Timedelta('2 hours'):\n",
    "            data_end = end_date\n",
    "    else:\n",
    "        data_end = end_date - data_offset\n",
    "    # Filter the dataframe based on the specified date range\n",
    "    date_range = (dataframe['date'] >= start_date) & (dataframe['date'] <= data_end)\n",
    "    dataframe.loc[date_range, f'period{data_period}'] = data_tag\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "\n",
    "In this part we implement a code which  loads and cleans the training and validation data from a CSV file, applies data modifications and feature engineering operations, and prepares the `df_train` DataFrame for further processing in subsequent steps.\n",
    "\n",
    "Implementation steps:\n",
    "\n",
    "- Read the CSV file named 'train_validation_data.csv' located in the specified directory into a Pandas DataFrame (`df`), while specifying the column to be used as the index (`index_col=0`) and parsing the 'date' column as datetime objects (`parse_dates=['date']`).\n",
    "- Store the original size of the DataFrame in the variable `original_size`.\n",
    "- Remove unnecessary columns and rename certain columns in the DataFrame using the `remove_columns_rename` function, passing the DataFrame (`df`), a dictionary containing column removal frequencies (`OFFSET_DICT`), and the desired frequency (`FREQ`).\n",
    "- Create a new column in the DataFrame named 'on_ret', which calculates the exponential of the product of the 'short_rate' column and a constant time interval (`DT`).\n",
    "- Apply tagging to the DataFrame using the `assign_data_tag` function. This assigns a tag of 0 for the first period and a tag of 1 for the second period, based on specified offset values and date ranges.\n",
    "- Print information about loading and cleaning the training and validation data, including the original size of the DataFrame before modifications.\n",
    "- Modify the DataFrame by removing in-the-money samples and shrinking the moneyness range using the `modify_dataframe` function, passing the DataFrame (`df`), the original size  and specified moneyness range limits.\n",
    "- Filter out rows where the 'V1' column is not NaN, and assign the resulting DataFrame to `df_train`.\n",
    "- Perform additional custom feature engineering on the `df_train` DataFrame using the `add_custom_features` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load and clean the training and validation data.\n",
      "Original data size: 579717\n",
      "Removing in-the-money samples: 293046 samples (50.55%) removed. 49.45% of data remaining. Current size of data: 286671.\n",
      "Shrinking moneyness range: 0 samples (0.00%) removed. 49.45% of data remaining. Current size of data: 286671.\n"
     ]
    }
   ],
   "source": [
    "OFFSET_DICT = {\n",
    "    '1D': [BDay(1), '_1D'],\n",
    "    '2D': [BDay(2), '_2D']\n",
    "}\n",
    "DATE_BREAK = pd.Timestamp('2018/07/01') + pd.Timedelta('360D')\n",
    "FREQ = '1D'\n",
    "DT = 1 / 253.\n",
    "MIN_MONEYNESS, MAX_MONEYNESS = 0.8, 1.5\n",
    "seed = 42\n",
    "UNDERLYINGPARAS = {\n",
    "        's0': 2000.,\n",
    "        'volatility': 0.2,\n",
    "        'mu': 0.1,\n",
    "        'start_date': pd.Timestamp('2018/07/01'),\n",
    "        'end_date': pd.Timestamp('2018/07/01') + pd.Timedelta('450D')}\n",
    "\n",
    "df = pd.read_csv('C:/Users/fatem/Desktop/hedging_project/data/train_validation_data.csv', index_col=0, parse_dates=['date'])\n",
    "original_size = df.shape[0]\n",
    "\n",
    "remove_columns_rename(df, OFFSET_DICT, FREQ)\n",
    "df['on_ret'] = np.exp(df['short_rate'] * DT)\n",
    "\n",
    "assign_data_tag(df, 0, 0, OFFSET_DICT[FREQ][0], UNDERLYINGPARAS['start_date'], DATE_BREAK)\n",
    "assign_data_tag(df, 1, 0, OFFSET_DICT[FREQ][0], DATE_BREAK, UNDERLYINGPARAS['end_date'])\n",
    "\n",
    "print('Load and clean the training and validation data.')\n",
    "print('Original data size:', df.shape[0])\n",
    "\n",
    "df = modify_dataframe(df, original_size, MIN_MONEYNESS, MAX_MONEYNESS)\n",
    "bl = df['V1'].notna()\n",
    "df_train = df.loc[bl]\n",
    "df_train = add_custom_features(df_train)\n",
    "original_features =['vega_n', 'gamma_n', 'vanna_n', 'vega_s', 'delta_vega_s', 'delta2_vega_s']\n",
    "\n",
    "def standardize_features(df, feature_list):\n",
    "    \"\"\"\n",
    "    Standardize the selected features in the given DataFrame using the StandardScaler.\n",
    "    :param df: DataFrame containing the data to be standardized.\n",
    "    :param feature_list: List of feature names to be standardized.\n",
    "    :return: DataFrame with standardized features.\n",
    "    \"\"\"\n",
    "    # Copy the DataFrame to avoid modifying the original DataFrame\n",
    "    standardized_df = df.copy()\n",
    "\n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit and transform the selected features\n",
    "    standardized_df[feature_list] = scaler.fit_transform(df[feature_list])\n",
    "\n",
    "    return standardized_df\n",
    "df_train = standardize_features(df_train, original_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is part of a data preprocessing step for a Monte Carlo simulation dataset. The main purpose is to prepare the test set (`df_test`) for evaluation and analysis. \n",
    "\n",
    "1. `df_test = pd.read_csv(PATH, index_col=0, parse_dates=['date'])`: Reads the Monte Carlo data from the specified file (`test_data.csv`) into a DataFrame `df_test`. The 'date' column is parsed as datetime objects.\n",
    "\n",
    "2. `remove_columns_rename(df_test, OFFSET_DICT, FREQ)`: Calls a function `remove_columns_rename` to remove irrelevant columns and rename the remaining columns in the `df_test` DataFrame based on some configuration dictionaries (`OFFSET_DICT` and `FREQ`).\n",
    "\n",
    "3. `df_test['on_ret'] = np.exp(df_test['short_rate'] * DT)`: Calculates a new feature 'on_ret' by taking the exponential of the product of 'short_rate' and a parameter `DT`.\n",
    "\n",
    "4. `assign_data_tag(df_test, 2, 0, OFFSET_DICT[FREQ][0], df_test['date'].min(), df_test['date'].max())`: Calls a function `assign_data_tag` to assign data tags to the test set based on some parameters and the 'date' column.\n",
    "\n",
    "5. `original_size = df_test.shape[0]`: Records the original size (number of rows) of the test set.\n",
    "\n",
    "6. `bl = df_test['V1'].notna()`: Creates a boolean mask `bl` that checks if the 'V1' column is not NaN (not missing).\n",
    "\n",
    "7. `df_test = df_test.loc[bl]`: Removes rows from `df_test` where the 'V1' column is missing.\n",
    "\n",
    "8. Prints information about the removal and the remaining samples.\n",
    "\n",
    "9. `df_test = add_custom_features(df_test)`: Calls a function `add_custom_features` to add custom features to the test set `df_test`.\n",
    "\n",
    "So we load a Monte Carlo dataset, preprocesses it by removing irrelevant rows, calculates new features and assigns data tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We remove samples where S1 is not available. 2582 samples (1.89%) are removed. 98.11% of data is left. Current size of data: 133861.\n"
     ]
    }
   ],
   "source": [
    "# Import Monte Carlo Set and Preprocessing\n",
    "\n",
    "# Read the Monte Carlo data for the current set\n",
    "df_test = pd.read_csv('C:/Users/fatem/Desktop/hedging_project/data/test_data.csv', index_col=0, parse_dates=['date'])\n",
    "\n",
    "# Remove irrelevant columns and rename remaining columns\n",
    "remove_columns_rename(df_test, OFFSET_DICT, FREQ)\n",
    "\n",
    "# Calculate the 'on_ret' feature\n",
    "df_test['on_ret'] = np.exp(df_test['short_rate'] * DT)\n",
    "\n",
    "# Assign data tags for the test set\n",
    "assign_data_tag(df_test, 2, 0, OFFSET_DICT[FREQ][0], df_test['date'].min(), df_test['date'].max())\n",
    "\n",
    "# Record the original size of the test set\n",
    "original_size = df_test.shape[0]\n",
    "\n",
    "# Modify the test set by removing rows where S1 is not available\n",
    "bl = df_test['V1'].notna()\n",
    "df_test = df_test.loc[bl]\n",
    "\n",
    "# Print information about sample removal\n",
    "removal_count = original_size - sum(bl)\n",
    "removal_percentage = (removal_count / original_size) * 100\n",
    "remaining_percentage = (sum(bl) / original_size) * 100\n",
    "print(f'We remove samples where S1 is not available. {removal_count} samples ({removal_percentage:.2f}%) are removed. '\n",
    "      f'{remaining_percentage:.2f}% of data is left. Current size of data: {sum(bl)}.')\n",
    "\n",
    "# Add custom features to the test set\n",
    "df_test = add_custom_features(df_test)\n",
    "df_test = standardize_features(df_test, original_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Feature Sets for Linear Regression Hedge Model:\n",
    "\n",
    "In this section, we have implemented the necessary functions for performing linear regression to hedge our options. We have prepared the data by cleaning and modifying the dataframe, creating relevant features, and tagging the data for training and validation. The dataframe has been processed to remove unnecessary columns and rename relevant ones. Additionally, we have saved the cleaned data for further analysis.\n",
    "\n",
    "Now, we are ready to proceed with the linear regression on different feature setups. We will train our model using various sets of features and evaluate its performance. This will allow us to rank and compare the performance of the model across different feature combinations and select the optimal set of features for our hedge model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the results' dictionary\n",
    "results_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No hedge\n",
    "\n",
    "The purpose of this code is to evaluate the performance of the \"No Hedge\" strategy, where the delta values are set to zero for all trades.\n",
    "\n",
    "Code explanation:\n",
    "\n",
    "  - Create a temporary dataframe (`df_tmp`) by appending the training dataset (`df_train`) and the test dataset (`df_test`).\n",
    "  - Create a zero array (`zero`) with the same length as the temporary dataframe.\n",
    "  - Convert the zero array into a Pandas Series object with index matching the temporary dataframe.\n",
    "  - The delta values are stored in `results_dict` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Hedge\n",
    "\n",
    "df_tmp = df_train.append(df_test)  \n",
    "# Create a zero array for delta values\n",
    "zero = np.array([0.] * len(df_tmp))\n",
    "zero = pd.Series(zero, index=df_tmp.index)\n",
    "results_dict['No_Hedge'] = zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BS\n",
    "\n",
    "The purpose of this part is to evaluate the performance of the \"BS Benchmark\" strategy, where the delta values are determined based on the Black-Scholes model. \n",
    "\n",
    "Code explanation:\n",
    "  - Create a temporary dataframe (`df_tmp`) by appending the training dataset (`df_train`) and the test dataset (`df_test`).\n",
    "  - The delta values are stored in `results_dict` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BS Benchmark\n",
    "df_tmp = df_train.append(df_test)\n",
    "results_dict['BS'] = df_tmp['delta_bs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delta-only\n",
    "\n",
    "The purpose of this part is to evaluate the performance of the \"Delta Only\" strategy, where only the delta value is used as a predictor for hedging. The linear regression is performed for each test set, and the resulting regression coefficients and fit standard deviations are printed.\n",
    "Code explanation:\n",
    "\n",
    "  - Create a temporary dataframe (`df_tmp`) by appending the training dataset (`df_train`) and the test dataset (`df_test`).\n",
    "  - Set up the keyword arguments (`kwargs`) for the `run_linear_regression` function, specifying the features, maximum period, dataframe, delta coefficient setting, and leverage setting.\n",
    "  - Run the linear regression using the `run_linear_regression` function with the specified keyword arguments and store the resulting regression results (`res`).\n",
    "  - The delta values are stored in `results_dict` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1\n",
      "   delta_bs  delta_bs\n",
      "0  0.018715 -0.008668\n"
     ]
    }
   ],
   "source": [
    "# Delta Only\n",
    "df_tmp = df_train.append(df_test)\n",
    "# Set up the keyword arguments for the run_linear_regression function\n",
    "kwargs = {\n",
    "    'features': ['delta_bs'],\n",
    "    'max_period': 0,\n",
    "    'setup_name': 'Delta_only',\n",
    "    'df': df_tmp,\n",
    "    'taret_var': True,\n",
    "    'leverage': True\n",
    "    }\n",
    "# Run linear regression \n",
    "res = run_linear_regression(**kwargs) \n",
    "# Print the results\n",
    "print(res['df_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delta-Vega\n",
    "\n",
    "The purpose of this part is to evaluate the performance of the \"Delta Vega\" strategy, where both the delta and vega values are used as predictors for hedging. The linear regression is performed for each test set, and the resulting regression coefficients and fit standard deviations are printed.\n",
    "\n",
    "Code explanation:\n",
    "  - Create a temporary dataframe (`df_tmp`) by appending the training dataset (`df_train`) and the test dataset (`df_test`).\n",
    "  - Set up the keyword arguments (`kwargs`) for the `run_linear_regression` function, specifying the features, maximum period, dataframe.\n",
    "  - Run the linear regression using the `run_linear_regression` function with the specified keyword arguments and store the resulting regression results (`res`).\n",
    "  - The delta values are stored in `results_dict` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0                   1          \n",
      "   delta_bs    vega_n  delta_bs    vega_n\n",
      "0  0.026721 -0.005973 -0.009803 -0.001172\n"
     ]
    }
   ],
   "source": [
    "# Delta Vega\n",
    "\n",
    "df_tmp = df_train.append(df_test)\n",
    "# Set up the keyword arguments for the run_linear_regression function\n",
    "kwargs = {\n",
    "    'features': ['delta_bs', 'vega_n'],\n",
    "    'max_period': 0,\n",
    "    'setup_name': 'Delta_Vega',\n",
    "    'df': df_tmp,\n",
    "    'taret_var': True,\n",
    "}\n",
    "# Run linear regression\n",
    "res = run_linear_regression(**kwargs)\n",
    "\n",
    "print(res['df_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delta-Gamma\n",
    "\n",
    "The purpose of this part is to evaluate the performance of the \"Delta Gamma\" strategy, where both the delta and gamma values are used as predictors for hedging. The linear regression is performed for each test set, and the resulting regression coefficients and fit standard deviations are printed.\n",
    "Code explanation:\n",
    "\n",
    "  - Create a temporary dataframe (`df_tmp`) by appending the training dataset (`df_train`) and the test dataset (`df_test`).\n",
    "  - Set up the keyword arguments (`kwargs`) for the `run_linear_regression` function, specifying the features, maximum period, dataframe.\n",
    "  - Run the linear regression using the `run_linear_regression` function with the specified keyword arguments and store the resulting regression results (`res`).\n",
    "  - The delta values are stored in `results_dict` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0                  1          \n",
      "   delta_bs  gamma_n  delta_bs   gamma_n\n",
      "0  0.014948  0.00526 -0.008003  0.002232\n"
     ]
    }
   ],
   "source": [
    "# Delta Gamma\n",
    "df_tmp = df_train.append(df_test)\n",
    "# Set up the keyword arguments for the run_linear_regression function\n",
    "kwargs = {\n",
    "    'features': ['delta_bs', 'gamma_n'],\n",
    "    'setup_name': 'Delta_Gamma',\n",
    "    'max_period': 0,\n",
    "    'df': df_tmp,\n",
    "    'taret_var': True,\n",
    "}\n",
    "# Run linear regression\n",
    "res = run_linear_regression(**kwargs)\n",
    "print(res['df_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delta-Vanna\n",
    "\n",
    "The purpose of this part is to evaluate the performance of the \"Delta Vanna\" strategy, where both the delta and vanna values are used as predictors for hedging. The linear regression is performed for each test set, and the resulting regression coefficients and fit standard deviations are printed.\n",
    "\n",
    "Code explanation:\n",
    "\n",
    "  - Create a temporary dataframe (`df_tmp`) by appending the training dataset (`df_train`) and the test dataset (`df_test`).\n",
    "  - Set up the keyword arguments (`kwargs`) for the `run_linear_regression` function, specifying the features, maximum period,,dataframe.\n",
    "  - Run the linear regression using the `run_linear_regression` function with the specified keyword arguments and store the resulting regression results (`res`).\n",
    "  - The delta values are stored in `results_dict` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0                   1          \n",
      "   delta_bs   vanna_n  delta_bs   vanna_n\n",
      "0 -0.006196  0.008258 -0.008322 -0.000485\n"
     ]
    }
   ],
   "source": [
    "# Delta Vanna\n",
    "\n",
    "df_tmp = df_train.append(df_test)\n",
    "# Set up the keyword arguments for the run_linear_regression function\n",
    "kwargs = {\n",
    "    'features': ['delta_bs', 'vanna_n'],\n",
    "    'setup_name': 'Delta_Vanna',\n",
    "    'max_period': 0,\n",
    "    'df': df_tmp,\n",
    "    'taret_var': True,\n",
    "}\n",
    "# Run linear regression\n",
    "res = run_linear_regression(**kwargs) \n",
    "print(res['df_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Delta-Gamma-Vanna\n",
    "\n",
    "The purpose of this part is to evaluate the performance of the \"Delta-Gamma-Vanna\" strategy, where delta, gamma, and vanna values are used as predictors for hedging. The linear regression is performed for each test set, and the resulting regression coefficients and fit standard deviations are printed.\n",
    "\n",
    "Code explanation:\n",
    "\n",
    "  - Create a temporary dataframe (`df_tmp`) by appending the training dataset (`df_train`) and the test dataset (`df_test`).\n",
    "  - Set up the keyword arguments (`kwargs`) for the `run_linear_regression` function, specifying the features, maximum period, dataframe.\n",
    "  - Run the linear regression using the `run_linear_regression` function with the specified keyword arguments and store the resulting regression results (`res`).\n",
    "  - The delta values are stored in `results_dict` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0                             1                    \n",
      "   delta_bs   gamma_n   vanna_n  delta_bs   gamma_n   vanna_n\n",
      "0 -0.005259  0.004145  0.006963 -0.007421  0.002308 -0.000786\n"
     ]
    }
   ],
   "source": [
    "# Delta-Gamma-Vanna\n",
    "\n",
    "df_tmp = df_train.append(df_test) \n",
    "# Set up the keyword arguments for the run_linear_regression function\n",
    "kwargs = {\n",
    "    'features': ['delta_bs', 'gamma_n', 'vanna_n'],\n",
    "    'setup_name': 'Delta_Gamma_Vanna',\n",
    "    'max_period': 0,\n",
    "    'df': df_tmp,\n",
    "    'taret_var': True,\n",
    "}\n",
    "# Run linear regression\n",
    "res = run_linear_regression(**kwargs)\n",
    "\n",
    "print(res['df_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delta-Vega-Gamma\n",
    "\n",
    "The purpose of this part is to evaluate the performance of the \"Delta-Vega-Gamma\" strategy, where delta, vega, and gamma values are used as predictors for hedging. The linear regression is performed for each test set, and the resulting regression coefficients and fit standard deviations are printed.\n",
    "\n",
    "Code explanation:\n",
    "\n",
    "  - Create a temporary dataframe (`df_tmp`) by appending the training dataset (`df_train`) and the test dataset (`df_test`).\n",
    "  - Set up the keyword arguments (`kwargs`) for the `run_linear_regression` function, specifying the features, maximum period, dataframe.\n",
    "  - Run the linear regression using the `run_linear_regression` function with the specified keyword arguments and store the resulting regression results (`res`).\n",
    "  - The delta values are stored in `results_dict` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0                             1                   \n",
      "   delta_bs    vega_n   gamma_n  delta_bs    vega_n  gamma_n\n",
      "0  0.016179 -0.000723  0.004893 -0.009241 -0.001305  0.00232\n"
     ]
    }
   ],
   "source": [
    "# Delta-Vega-Gamma\n",
    "\n",
    "df_tmp = df_train.append(df_test)\n",
    "# Set up the keyword arguments for the run_linear_regression function\n",
    "kwargs = {\n",
    "    'features': ['delta_bs', 'vega_n', 'gamma_n'],\n",
    "    'setup_name': 'Delta_Vega_Gamma',\n",
    "    'df': df_tmp,\n",
    "    'max_period': 0,\n",
    "    'taret_var': True,\n",
    "}\n",
    "    \n",
    "# Run linear regression\n",
    "res = run_linear_regression(**kwargs)\n",
    "print(res['df_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delta-Vega-Vanna\n",
    "\n",
    "The purpose of this part is to evaluate the performance of the \"Delta-Vega-Vanna\" strategy, where delta, vega, and vanna values are used as predictors for hedging. The linear regression is performed for each test set, and the resulting regression coefficients and fit standard deviations are printed.\n",
    "\n",
    "Code explanation:\n",
    "\n",
    "  - Create a temporary dataframe (`df_tmp`) by appending the training dataset (`df_train`) and the test dataset (`df_test`).\n",
    "  - Set up the keyword arguments (`kwargs`) for the `run_linear_regression` function, specifying the features, maximum period, dataframe.\n",
    "  - Run the linear regression using the `run_linear_regression` function with the specified keyword arguments and store the resulting regression results (`res`).\n",
    "  - The delta values are stored in `results_dict` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0                             1                    \n",
      "   delta_bs    vega_n   vanna_n  delta_bs    vega_n   vanna_n\n",
      "0  0.001346 -0.003014  0.007097 -0.010361 -0.001387  0.000489\n"
     ]
    }
   ],
   "source": [
    "# Delta-Vega-Vanna\n",
    "\n",
    "df_tmp = df_train.append(df_test)\n",
    "# Set up the keyword arguments for the run_linear_regression function\n",
    "kwargs = {\n",
    "    'features': ['delta_bs', 'vega_n', 'vanna_n'],\n",
    "    'setup_name': 'Delta_Vega_Vanna',\n",
    "    'df': df_tmp,\n",
    "    'max_period': 0,\n",
    "    'taret_var': True,\n",
    "}\n",
    "# Run linear regression\n",
    "res = run_linear_regression(**kwargs)\n",
    "print(res['df_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delta-Vega-Gamma-Vanna\n",
    "\n",
    "The purpose of this part is to evaluate the performance of the \"Delta-Vega-Gamma-Vanna\" strategy, where delta, vega, gamma, and vanna values are used as predictors for hedging. The linear regression is performed for each test set, and the resulting regression coefficients and fit standard deviations are printed.\n",
    "\n",
    "Code explanation:\n",
    "\n",
    "  - Create a temporary dataframe (`df_tmp`) by appending the training dataset (`df_train`) and the test dataset (`df_test`).\n",
    "  - Set up the keyword arguments (`kwargs`) for the `run_linear_regression` function, specifying the features, maximum period.\n",
    "  - Run the linear regression using the `run_linear_regression` function with the specified keyword arguments and store the resulting regression results (`res`).\n",
    "  - The delta values are stored in `results_dict` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0                                       1                      \\\n",
      "   delta_bs    vega_n   gamma_n   vanna_n  delta_bs    vega_n   gamma_n   \n",
      "0 -0.013602  0.003482  0.005782  0.007793 -0.009458 -0.001386  0.002307   \n",
      "\n",
      "             \n",
      "    vanna_n  \n",
      "0  0.000188  \n"
     ]
    }
   ],
   "source": [
    "# Delta-Vega-Gamma-Vanna\n",
    "\n",
    "df_tmp = df_train.append(df_test)\n",
    "# Set up the keyword arguments for the run_linear_regression function\n",
    "kwargs = {\n",
    "    'features': ['delta_bs', 'vega_n', 'gamma_n', 'vanna_n'],\n",
    "    'setup_name': 'Delta_Vega_Gamma_Vanna',\n",
    "    'df': df_tmp,\n",
    "    'max_period': 0,\n",
    "    'taret_var': True,\n",
    "}\n",
    "# Run linear regression\n",
    "res = run_linear_regression(**kwargs)\n",
    "print(res['df_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanna-only\n",
    "\n",
    "The purpose of this part is to evaluate the performance of the \"Vanna only\" strategy, where vanna values are used as the sole predictor for hedging. The linear regression is performed for each test set, and the resulting regression coefficients and fit standard deviations are printed.\n",
    "\n",
    "Code explanation:\n",
    "\n",
    "  - Create a temporary dataframe (`df_tmp`) by appending the training dataset (`df_train`) and the test dataset (`df_test`).\n",
    "  - Set up the keyword arguments (`kwargs`) for the `run_linear_regression` function, specifying the features, maximum period, dataframe.\n",
    "  - Run the linear regression using the `run_linear_regression` function with the specified keyword arguments and store the resulting regression results (`res`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1\n",
      "    vanna_n   vanna_n\n",
      "0  0.006781 -0.001282\n"
     ]
    }
   ],
   "source": [
    "# Vanna only\n",
    "\n",
    "df_tmp = df_train.append(df_test)\n",
    "# Set up the keyword arguments for the run_linear_regression function\n",
    "kwargs = {\n",
    "    'features': ['vanna_n'],\n",
    "    'setup_name': 'Vanna_only',\n",
    "    'df': df_tmp,\n",
    "    'max_period': 0,\n",
    "    'taret_var': True,\n",
    "    'leverage': True\n",
    "}\n",
    "# Run linear regression\n",
    "res = run_linear_regression(**kwargs) \n",
    "print(res['df_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vega-only\n",
    "\n",
    "The purpose of this part is to evaluate the performance of the \"Vega only\" strategy, where vega values are used as the sole predictor for hedging. The linear regression is performed for each test set, and the resulting regression coefficients and fit standard deviations are printed.\n",
    "\n",
    "Code explanation:\n",
    "\n",
    "  - Create a temporary dataframe (`df_tmp`) by appending the training dataset (`df_train`) and the test dataset (`df_test`).\n",
    "  - Set up the keyword arguments (`kwargs`) for the `run_linear_regression` function, specifying the features, maximum period, dataframe.\n",
    "  - Run the linear regression using the `run_linear_regression` function with the specified keyword arguments and store the resulting regression results (`res`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1\n",
      "     vega_n    vega_n\n",
      "0  0.001077 -0.000382\n"
     ]
    }
   ],
   "source": [
    "# Vega only \n",
    "\n",
    "df_tmp = df_train.append(df_test)\n",
    "# Set up the keyword arguments for the run_linear_regression function\n",
    "kwargs = {\n",
    "    'features': ['vega_n'],\n",
    "    'setup_name': 'Vega_only',\n",
    "    'df': df_tmp,\n",
    "    'max_period': 0,\n",
    "    'taret_var': True,\n",
    "    'leverage': True\n",
    "}\n",
    "# Run linear regression\n",
    "res = run_linear_regression(**kwargs) \n",
    "print(res['df_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gamma-only\n",
    "\n",
    "The purpose of this part is to evaluate the performance of the \"Gamma only\" strategy, where gamma values are used as the sole predictor for hedging. The linear regression is performed for each test set, and the resulting regression coefficients and fit standard deviations are printed.\n",
    "\n",
    "Code explanation:\n",
    "\n",
    "  - Create a temporary dataframe (`df_tmp`) by appending the training dataset (`df_train`) and the test dataset (`df_test`).\n",
    "  - Set up the keyword arguments (`kwargs`) for the `run_linear_regression` function, specifying the features, maximum period, dataframe.\n",
    "  - Run the linear regression using the `run_linear_regression` function with the specified keyword arguments and store the resulting regression results (`res`).\n",
    "  - The delta values are stored in `results_dict` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1\n",
      "    gamma_n   gamma_n\n",
      "0  0.006698  0.002483\n"
     ]
    }
   ],
   "source": [
    "# Gamma only \n",
    "\n",
    "df_tmp = df_train.append(df_test)\n",
    "# Set up the keyword arguments for the run_linear_regression function\n",
    "kwargs = {\n",
    "    'features': ['gamma_n'],\n",
    "    'setup_name': 'Gamma_only',\n",
    "    'df': df_tmp,\n",
    "    'max_period': 0,\n",
    "    'taret_var': True,\n",
    "    'leverage': True\n",
    "}\n",
    "# Run linear regression\n",
    "res = run_linear_regression(**kwargs)\n",
    "print(res['df_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hull White model\n",
    "\n",
    "The purpose of this part is to evaluate the performance of the \"Hull-White\" strategy, where features related to Hull-White regression are used as predictors for hedging. The linear regression is performed for each test set, and the resulting regression coefficients and fit standard deviations are printed.\n",
    "\n",
    "Code explanation:\n",
    "  - Create a temporary dataframe (`df_tmp`) by appending the training dataset (`df_train`) and the test dataset (`df_test`).\n",
    "  - Set up the keyword arguments (`kwargs`) for the `run_linear_regression` function, specifying the features, maximum period, dataframe.\n",
    "  - Run the linear regression using the `run_linear_regression` function with the specified keyword arguments and store the resulting regression results (`res`).\n",
    "  - The delta values are stored in `results_dict` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0                                    1                           \n",
      "     vega_s delta_vega_s delta2_vega_s    vega_s delta_vega_s delta2_vega_s\n",
      "0 -0.003199     0.013996     -0.010568 -0.000181    -0.003915     -0.000848\n"
     ]
    }
   ],
   "source": [
    "# Hull-White \n",
    "\n",
    "df_tmp = df_train.append(df_test)\n",
    "# Set up the keyword arguments for the run_linear_regression function\n",
    "kwargs = {\n",
    "    'features': ['vega_s', 'delta_vega_s', 'delta2_vega_s'],\n",
    "    'setup_name': 'Hull_White',\n",
    "    'df': df_tmp,\n",
    "    'max_period': 0,\n",
    "    'taret_var': True\n",
    "}\n",
    "# Run linear regression\n",
    "res = run_linear_regression(**kwargs)\n",
    "print(res['df_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relaxed Hull-White\n",
    "\n",
    "The purpose of this part is to evaluate the performance of the \"Hull-White (Relaxed)\" strategy, where features related to Hull-White regression are used as predictors for hedging. The linear regression is performed for each test set, and the resulting regression coefficients and fit standard deviations are printed.\n",
    "\n",
    "Code explanation:\n",
    "  - Create a temporary dataframe (`df_tmp`) by appending the training dataset (`df_train`) and the test dataset (`df_test`).\n",
    "  - Set up the keyword arguments (`kwargs`) for the `run_linear_regression` function, specifying the features, maximum period, dataframe.\n",
    "  - Run the linear regression using the `run_linear_regression` function with the specified keyword arguments and store the resulting regression results (`res`).\n",
    "  - The delta values are stored in `results_dict` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0                                             1            \\\n",
      "   delta_bs   vega_s delta_vega_s delta2_vega_s  delta_bs    vega_s   \n",
      "0  0.277922 -0.00588    -0.061727     -0.009143 -0.042472 -0.000179   \n",
      "\n",
      "                              \n",
      "  delta_vega_s delta2_vega_s  \n",
      "0     0.014984      0.003384  \n"
     ]
    }
   ],
   "source": [
    "# Hull-White (Relaxed) \n",
    "df_tmp = df_train.append(df_test)\n",
    "# Set up the keyword arguments for the run_linear_regression function\n",
    "kwargs = {\n",
    "    'features': ['delta_bs', 'vega_s', 'delta_vega_s', 'delta2_vega_s'],\n",
    "    'setup_name': 'Hull_White_relaxed',\n",
    "    'df': df_tmp,\n",
    "    'max_period': 0,\n",
    "    'taret_var': True\n",
    "}\n",
    "# Run linear regression\n",
    "res = run_linear_regression(**kwargs)\n",
    "print(res['df_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Linear Regression Results for Different  Configurations\n",
    "In this analysis, we explore and visualize the results of linear regression for various configurations, providing insights into their performance and potential differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No_Hedge\n",
      "15        0.0\n",
      "23        0.0\n",
      "24        0.0\n",
      "30        0.0\n",
      "38        0.0\n",
      "         ... \n",
      "136432    0.0\n",
      "136434    0.0\n",
      "136435    0.0\n",
      "136437    0.0\n",
      "136438    0.0\n",
      "Length: 419553, dtype: float64\n",
      "\n",
      "BS\n",
      "15        0.509384\n",
      "23        0.494956\n",
      "24        0.488504\n",
      "30        0.488214\n",
      "38        0.462669\n",
      "            ...   \n",
      "136432   -0.467822\n",
      "136434   -0.472030\n",
      "136435   -0.471145\n",
      "136437   -0.475343\n",
      "136438   -0.474465\n",
      "Name: delta_bs, Length: 419553, dtype: float64\n",
      "\n",
      "Delta_only\n",
      "15        0.528098\n",
      "23        0.513670\n",
      "24        0.507219\n",
      "30        0.506928\n",
      "38        0.481380\n",
      "            ...   \n",
      "136432   -0.463767\n",
      "136434   -0.467938\n",
      "136435   -0.467062\n",
      "136437   -0.471223\n",
      "136438   -0.470352\n",
      "Length: 419553, dtype: float64\n",
      "\n",
      "Delta_Vega\n",
      "15        0.545613\n",
      "23        0.531185\n",
      "24        0.524734\n",
      "30        0.524443\n",
      "38        0.498886\n",
      "            ...   \n",
      "136432   -0.465260\n",
      "136434   -0.469438\n",
      "136435   -0.468553\n",
      "136437   -0.472720\n",
      "136438   -0.471843\n",
      "Length: 419553, dtype: float64\n",
      "\n",
      "Delta_Gamma\n",
      "15        0.517194\n",
      "23        0.502767\n",
      "24        0.496316\n",
      "30        0.496024\n",
      "38        0.470508\n",
      "            ...   \n",
      "136432   -0.464604\n",
      "136434   -0.468780\n",
      "136435   -0.467899\n",
      "136437   -0.472066\n",
      "136438   -0.471190\n",
      "Length: 419553, dtype: float64\n",
      "\n",
      "Delta_Vanna\n",
      "15        0.509804\n",
      "23        0.495375\n",
      "24        0.488921\n",
      "30        0.488634\n",
      "38        0.462926\n",
      "            ...   \n",
      "136432   -0.464529\n",
      "136434   -0.468722\n",
      "136435   -0.467840\n",
      "136437   -0.472023\n",
      "136438   -0.471148\n",
      "Length: 419553, dtype: float64\n",
      "\n",
      "Delta_Gamma_Vanna\n",
      "15        0.504080\n",
      "23        0.489651\n",
      "24        0.483198\n",
      "30        0.482910\n",
      "38        0.457252\n",
      "            ...   \n",
      "136432   -0.465867\n",
      "136434   -0.470080\n",
      "136435   -0.469189\n",
      "136437   -0.473392\n",
      "136438   -0.472508\n",
      "Length: 419553, dtype: float64\n",
      "\n",
      "Delta_Vega_Gamma\n",
      "15        0.520075\n",
      "23        0.505647\n",
      "24        0.499196\n",
      "30        0.498905\n",
      "38        0.473385\n",
      "            ...   \n",
      "136432   -0.466298\n",
      "136434   -0.470483\n",
      "136435   -0.469592\n",
      "136437   -0.473766\n",
      "136438   -0.472882\n",
      "Length: 419553, dtype: float64\n",
      "\n",
      "Delta_Vega_Vanna\n",
      "15        0.521212\n",
      "23        0.506784\n",
      "24        0.500330\n",
      "30        0.500042\n",
      "38        0.474352\n",
      "            ...   \n",
      "136432   -0.464765\n",
      "136434   -0.468921\n",
      "136435   -0.468041\n",
      "136437   -0.472187\n",
      "136438   -0.471313\n",
      "Length: 419553, dtype: float64\n",
      "\n",
      "Delta_Vega_Gamma_Vanna\n",
      "15        0.488638\n",
      "23        0.474210\n",
      "24        0.467756\n",
      "30        0.467468\n",
      "38        0.441809\n",
      "            ...   \n",
      "136432   -0.466103\n",
      "136434   -0.470279\n",
      "136435   -0.469390\n",
      "136437   -0.473556\n",
      "136438   -0.472673\n",
      "Length: 419553, dtype: float64\n",
      "\n",
      "Vanna_only\n",
      "15        0.514816\n",
      "23        0.500388\n",
      "24        0.493934\n",
      "30        0.493646\n",
      "38        0.467966\n",
      "            ...   \n",
      "136432   -0.469410\n",
      "136434   -0.473671\n",
      "136435   -0.472774\n",
      "136437   -0.477026\n",
      "136438   -0.476135\n",
      "Length: 419553, dtype: float64\n",
      "\n",
      "Vega_only\n",
      "15        0.507669\n",
      "23        0.493241\n",
      "24        0.486790\n",
      "30        0.486499\n",
      "38        0.460955\n",
      "            ...   \n",
      "136432   -0.468482\n",
      "136434   -0.472692\n",
      "136435   -0.471806\n",
      "136437   -0.476006\n",
      "136438   -0.475126\n",
      "Length: 419553, dtype: float64\n",
      "\n",
      "Gamma_only\n",
      "15        0.500296\n",
      "23        0.485868\n",
      "24        0.479417\n",
      "30        0.479125\n",
      "38        0.453620\n",
      "            ...   \n",
      "136432   -0.468407\n",
      "136434   -0.472618\n",
      "136435   -0.471728\n",
      "136437   -0.475929\n",
      "136438   -0.475046\n",
      "Length: 419553, dtype: float64\n",
      "\n",
      "Hull_White\n",
      "15        0.526497\n",
      "23        0.512069\n",
      "24        0.505617\n",
      "30        0.505327\n",
      "38        0.479720\n",
      "            ...   \n",
      "136432   -0.462425\n",
      "136434   -0.466610\n",
      "136435   -0.465730\n",
      "136437   -0.469906\n",
      "136438   -0.469033\n",
      "Length: 419553, dtype: float64\n",
      "\n",
      "Hull_White_relaxed\n",
      "15        0.828165\n",
      "23        0.813736\n",
      "24        0.807279\n",
      "30        0.806995\n",
      "38        0.781070\n",
      "            ...   \n",
      "136432   -0.469385\n",
      "136434   -0.473497\n",
      "136435   -0.472633\n",
      "136437   -0.476734\n",
      "136438   -0.475877\n",
      "Length: 419553, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print delta values\n",
    "for setup,results in results_dict.items():\n",
    "    print(setup)\n",
    "    print(results)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No_Hedge HMSE: 0.5841938456661125\n",
      "BS HMSE: 0.0012855653441444655\n",
      "Delta_only HMSE: 0.0013307338673194662\n",
      "Delta_Vega HMSE: 0.0015386190552253362\n",
      "Delta_Gamma HMSE: 0.0011941685820317206\n",
      "Delta_Vanna HMSE: 0.001332793949772294\n",
      "Delta_Gamma_Vanna HMSE: 0.0012500598246228765\n",
      "Delta_Vega_Gamma HMSE: 0.0012065560389979333\n",
      "Delta_Vega_Vanna HMSE: 0.0012410582133362386\n",
      "Hull_White_relaxed HMSE: 0.024310208830454722\n",
      "Hull_White HMSE: 0.0012479273029527339\n",
      "Gamma_only HMSE: 0.0011941844000625062\n",
      "Vega_only HMSE: 0.0012866928369154305\n",
      "Vanna_only HMSE: 0.0012936925576464604\n",
      "Delta_Vega_Gamma_Vanna HMSE: 0.0014297587646802143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNo_Hedge HMSE: 78200.77237471062\\nBS HMSE: 172.08706253252208\\nDelta_only HMSE: 178.13336621325516\\nDelta_Vega HMSE: 205.961085351517\\nDelta_Gamma HMSE: 159.85260055934697\\nDelta_Vanna HMSE: 178.40913091047253\\nDelta_Gamma_Vanna HMSE: 167.334258183844\\nDelta_Vega_Gamma HMSE: 161.51079793630348\\nDelta_Vega_Vanna HMSE: 166.12929349540215\\nHull_White_relaxed HMSE: 3254.188864253527\\nHull_White HMSE: 167.04879670055396\\nGamma_only HMSE: 159.85471797676715\\nVega_only HMSE: 172.23798984232994\\nVanna_only HMSE: 173.1749794591121\\nDelta_Vega_Gamma_Vanna HMSE: 191.38893799885713\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcualte MSHE for different configurations\n",
    "hmse_dict= {}\n",
    "def calculate_pnl(df, delta, target_column='V1_n'):\n",
    "    \"\"\"\n",
    "    Calculate the Profit and Loss (PnL) for a given DataFrame and delta values.\n",
    "    We assume short option.\n",
    "    :param df: DataFrame containing the required columns (S0_n, S1_n, V0_n, V1_n, on_ret).\n",
    "    :param delta: Array of predicted delta values.\n",
    "    :param target_column: The target column name to compare to (default is 'V1_n').\n",
    "    :return: Series containing PnL values.\n",
    "    \"\"\"\n",
    "    s0, s1 = df['S0_n'], df['S1_n']\n",
    "    v0, v1 = df['V0_n'], df[target_column]\n",
    "    on_ret = df['on_ret']\n",
    "    \n",
    "    v1_hat = (v0 - delta * s0) * on_ret + delta * s1\n",
    "    pnl = v1_hat - v1\n",
    "    return pnl\n",
    "\n",
    "configurations = [\n",
    "    'No_Hedge', 'BS', 'Delta_only', 'Delta_Vega', 'Delta_Gamma',\n",
    "    'Delta_Vanna', 'Delta_Gamma_Vanna', 'Delta_Vega_Gamma',\n",
    "    'Delta_Vega_Vanna', 'Hull_White_relaxed', 'Hull_White',\n",
    "    'Gamma_only', 'Vega_only', 'Vanna_only', 'Delta_Vega_Gamma_Vanna'\n",
    "]\n",
    "\n",
    "for config in configurations:\n",
    "    df_result = results_dict[config]\n",
    "    # Calculate and print HMSE for the current configuration\n",
    "    pnl_reg = calculate_pnl(df_test, df_result[-df_test.shape[0]:])\n",
    "#     hmse = calculate_hmse(df_result[-df_test.shape[0]:],df_test)\n",
    "    hmse_reg = np.mean((df_test['V1_n'] - (df_test['V1_n'] + pnl_reg)) ** 2)\n",
    "    hmse_dict[config]= hmse_reg\n",
    "    print(f'{config} HMSE: {hmse_reg}')\n",
    "\n",
    "'''\n",
    "No_Hedge HMSE: 0.5841938456661125\n",
    "BS HMSE: 0.0012855653441444655\n",
    "Delta_only HMSE: 0.0013307338673194662\n",
    "Delta_Vega HMSE: 0.0015386190552253362\n",
    "Delta_Gamma HMSE: 0.0011941685820317206\n",
    "Delta_Vanna HMSE: 0.001332793949772294\n",
    "Delta_Gamma_Vanna HMSE: 0.0012500598246228765\n",
    "Delta_Vega_Gamma HMSE: 0.0012065560389979333\n",
    "Delta_Vega_Vanna HMSE: 0.0012410582133362386\n",
    "Hull_White_relaxed HMSE: 0.024310208830454722\n",
    "Hull_White HMSE: 0.0012479273029527339\n",
    "Gamma_only HMSE: 0.0011941844000625062\n",
    "Vega_only HMSE: 0.0012866928369154305\n",
    "Vanna_only HMSE: 0.0012936925576464604\n",
    "Delta_Vega_Gamma_Vanna HMSE: 0.0014297587646802143\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next section calculates and prints the improvement in HMSE (Hedging Mean Squared Error) over the \"No_Hedge\" strategy for each configuration in the \"imp_dict\" dictionary. It then creates a bar plot using Matplotlib to visualize the HMSE values for each configuration. The x-axis represents the different configurations, and the y-axis shows the corresponding HMSE values. The title of the plot is \"HMSE for different configurations.\" The code also sets the figure size, labels, and rotation of x-axis labels for better readability. Finally, it displays the results. This allows us to compare the HMSE values of different configurations and observe their relative performance compared to the \"No_Hedge\" strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement over No_Hedge strategy\n",
      "Hull_White_relaxed: 0.5598836368356578\n",
      "Delta_Vega: 0.5826552266108872\n",
      "Delta_Vega_Gamma_Vanna: 0.5827640869014323\n",
      "Delta_Vanna: 0.5828610517163403\n",
      "Delta_only: 0.5828631117987931\n",
      "Vanna_only: 0.5829001531084661\n",
      "Vega_only: 0.5829071528291971\n",
      "Delta_Gamma_Vanna: 0.5829437858414896\n",
      "Hull_White: 0.5829459183631598\n",
      "Delta_Vega_Vanna: 0.5829527874527763\n",
      "Delta_Vega_Gamma: 0.5829872896271147\n",
      "Gamma_only: 0.5829996612660501\n",
      "Delta_Gamma: 0.5829996770840808\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Improvement over No_Hedge strategy')\n",
    "imp_dict = {}\n",
    "for config in configurations:\n",
    "    if config != 'No_Hedge' and config != 'BS':\n",
    "        imp_dict[config] = hmse_dict['No_Hedge'] - hmse_dict[config]\n",
    "\n",
    "# Sort the imp_dict by values (HMSE difference with No_Hedge)\n",
    "sorted_imp_dict = {k: v for k, v in sorted(imp_dict.items(), key=lambda item: item[1])}\n",
    "\n",
    "# Print HMSE difference for each configuration\n",
    "for config, improvement in sorted_imp_dict.items():\n",
    "    print(f'{config}: {improvement}')\n",
    "\n",
    "# Define the starting value for the y-axis\n",
    "y_axis_start = 0\n",
    "\n",
    "# Plotting the HMSE values sorted by HMSE difference\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(sorted_imp_dict.keys(), sorted_imp_dict.values())\n",
    "plt.xlabel('Configuration')\n",
    "plt.ylabel('HMSE(No Hedge) - HMSE')\n",
    "plt.title('HMSE difference with No_Hedge for different configurations')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Set the y-axis limits to start from the specified value\n",
    "plt.ylim(y_axis_start, max(sorted_imp_dict.values()) * 1.1)  # You can adjust the multiplier for padding\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
