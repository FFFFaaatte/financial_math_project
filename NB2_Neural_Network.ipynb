{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Hedging:  From Implementation to Hyperparameter Tuning and Results Analysis\n",
    "This notebook showcases the application of neural networks in the context of hedging. We start by implementing essential functions, then proceed with hyperparameter tuning, training, testing, and finally, presenting insightful visualizations of the obtained results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://financialtribune.com/sites/default/files/field/image/17january/14_artificial.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![architecture](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The architecture of the HedgeNet model can be described as follows:\n",
    "\n",
    "1. Input Layers:\n",
    "   - 'features': Input layer for the features used in the model.\n",
    "   - 'cp_int': Input layer for the control parameter representing call or put (0 or 1).\n",
    "   - 'V0': Input layer for the initial portfolio value.\n",
    "   - 'S0': Input layer for the initial stock price.\n",
    "   - 'S1': Input layer for the final stock price.\n",
    "   - 'on_ret': Input layer for a one-day return of the stock.\n",
    "\n",
    "2. Hidden Layers:\n",
    "   - The model has multiple hidden layers, with the number of nodes specified by the 'nodes_per_layer' parameter during model building. Each hidden layer uses ReLU activation and L2 regularization.\n",
    "\n",
    "3. Output Layer:\n",
    "   - 'out_trainable': Output layer representing the predicted delta values before applying the control parameter.\n",
    "\n",
    "4. Final Calculations:\n",
    "   - The predicted delta values are subtracted from the 'cp_int' input to get the final delta values ('delta' layer).\n",
    "   - The 'delta' values are then used to calculate intermediate results for cash flows and final portfolio value ('V1_hat').\n",
    "\n",
    "5. Model Compilation:\n",
    "   - The model is compiled using the Adam optimizer with the specified learning rate ('lr') and the loss function is Mean Squared Error ('mse').\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Import essential Python libraries and modules that will be used throughout the notebook for various tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import BDay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The HedgeNet Class\n",
    "\n",
    "A class is defined called `HedgeNet`, which encapsulates methods for building, training, and using a neural network for hedging financial instruments. The class includes the following main methods:\n",
    "\n",
    "1. `__init__`: The constructor initializes the class instance and sets the model attribute to None.\n",
    "\n",
    "2. `build_model`: This method builds the neural network model for hedging using the provided parameters, such as the shape of the input features, the number of nodes per hidden layer, learning rate, activation functions, loss function, and regularization. \n",
    "\n",
    "3. `fit`: This method trains the neural network using the training data and evaluates its performance on the validation data. It takes as input the training and validation datasets, a list of feature names to be used during training, the target column name for V1, and optional parameters like the number of epochs and batch size.The function essentially performs the training of the neural network model using the provided training data (`train_data`) and validates its performance using the provided validation data (`val_data`). The model is trained for the specified number of epochs with the specified batch size, and the training metrics are recorded in the `history` object. The trained model can then be used for predictions on new data.\n",
    "\n",
    "4. `calculate_delta`: This method calculates the delta using the trained model and a given DataFrame containing input features. It takes as input the DataFrame and a list of feature names to be used during inference and returns an array of predicted delta values.\n",
    "\n",
    "The code uses the Keras library for building and training the neural network. It defines the architecture of the model with multiple hidden layers and different activation functions for each layer. The model is compiled with the Adam optimizer and the specified loss function. The `fit` method is used for training the model on the training data and evaluating it on the validation data. The `calculate_delta` method is used for making predictions using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense, Subtract, Multiply, Add\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "\n",
    "class HedgeNet:\n",
    "    \"\"\"\n",
    "    This class encapsulates methods including building a neural network for hedging, fitting it with training data,\n",
    "    and evaluating its performance on validation data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def build_model(self, feature_shape, nodes_per_layer, lr=0.001, outact=None, loss='mse',\n",
    "                    metrics=[None], reg_alpha=1e-4):\n",
    "        \"\"\"\n",
    "        Build the neural network model for hedging.\n",
    "        :param feature_shape: Shape of the input features.\n",
    "        :param nodes_per_layer: A list representing the number of nodes for each hidden layer.\n",
    "        :param lr: Learning rate for the optimizer.\n",
    "        :param outact: Activation function for the output layer.\n",
    "        :param loss: Loss function for training the model.\n",
    "        :param metrics: Evaluation metrics used during training.\n",
    "        :param reg_alpha: L2 regularization parameter for the dense layers.\n",
    "        \"\"\"\n",
    "        # This line creates an input layer with the specified shape feature_shape for the\n",
    "        # input features. The layer is named 'features' \n",
    "        features = Input(shape=feature_shape, dtype='float32', name='features')\n",
    "        \n",
    "        # This line creates the first hidden layer with nodes_per_layer[0] nodes. The\n",
    "        # activation function used is ReLU, and L2 regularization with the strength of\n",
    "        # reg_alpha is applied to the layer.\n",
    "        x = Dense(nodes_per_layer[0], activation='relu', kernel_regularizer=l2(reg_alpha))(features)\n",
    "        #  Initiate a loop to create additional hidden layers for each value in \n",
    "        # nodes_per_layer after the first element.\n",
    "        for num_nodes in nodes_per_layer[1:]:       \n",
    "            # Create a hidden layer with num_nodes nodes and applies ReLU activation and L2 \n",
    "            # regularization.\n",
    "            x = Dense(num_nodes, activation='relu', kernel_regularizer=l2(reg_alpha))(x)\n",
    "            \n",
    "        #  Create the output layer with a single node (output size 1).\n",
    "        # The activation function for this layer is specified by outact, and the \n",
    "        # layer is named 'delta_before_flag'.\n",
    "        out_trainable = Dense(1, activation=outact, name='delta_before_flag')(x)\n",
    "\n",
    "        #  Creates an input layer for cp_int, which represents a flag representing call\n",
    "        # or put (0 or 1)\n",
    "        cp_int = Input((1,), dtype='float32', name='cp_int')\n",
    "        \n",
    "        # Create a layer that performs the element-wise subtraction between the output\n",
    "        # layer out_trainable and the cp_int input. The layer is named 'delta'.\n",
    "        delta = Subtract(name='delta')([out_trainable, cp_int])\n",
    "        \n",
    "        # V0 represents the initial portfolio value\n",
    "        V0 = Input((1,), dtype='float32', name='V0')\n",
    "        \n",
    "        # S0 represents the initial stock price\n",
    "        S0 = Input((1,), dtype='float32', name='S0')\n",
    "        \n",
    "        # S1 represents the final stock price\n",
    "        S1 = Input((1,), dtype='float32', name='S1')\n",
    "        \n",
    "        # on_ret, which represents a one-day return of the stock.\n",
    "        on_ret = Input((1,), dtype='float32', name='on_ret')\n",
    " \n",
    "        # This line creates a layer that performs the element-wise multiplication between \n",
    "        # the S0 input and the 'delta' layer. The layer is named 'delta_S0'.\n",
    "        delta_S0 = Multiply(name='delta_S0')([S0, delta])\n",
    "        \n",
    "        # This line creates a layer that performs the element-wise multiplication between\n",
    "        # the S1 input and the 'delta' layer. The layer is named 'delta_S1'.\n",
    "        delta_S1 = Multiply(name='delta_S1')([S1, delta])\n",
    "        \n",
    "        # This line creates a layer that performs the element-wise subtraction between\n",
    "        # the V0 input and the 'delta_S0' layer. The layer is named 'cash0'.\n",
    "        cash0 = Subtract(name='cash0')([V0, delta_S0])\n",
    "        \n",
    "        # This line creates a layer that performs the element-wise multiplication between\n",
    "        # the 'cash0' layer and the on_ret input. The layer is named 'cash1'.\n",
    "        cash1 = Multiply(name='cash1')([cash0, on_ret])\n",
    "        \n",
    "        # This line creates a layer that performs the element-wise addition between the \n",
    "        # 'cash1' layer and the 'delta_S1' layer. The layer is named 'V1_hat'.\n",
    "        V1_hat = Add(name='V1_hat')([cash1, delta_S1])\n",
    "\n",
    "        # This line creates the final model using the Keras Model class. It specifies the\n",
    "        # input layers as [features, cp_int, V0, S0, S1, on_ret] and the output layer as\n",
    "        # [V1_hat].\n",
    "        self.model = Model(\n",
    "            inputs=[features, cp_int, V0, S0, S1, on_ret],\n",
    "            outputs=[V1_hat]\n",
    "        )\n",
    "        \n",
    "        # This line compiles the model using the Adam optimizer with the specified learning\n",
    "        # rate (lr), loss function (loss), and evaluation metrics (metrics). The model is\n",
    "        # now ready for training.\n",
    "        self.model.compile(\n",
    "            optimizer=Adam(lr=lr),\n",
    "            loss=loss,\n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "    def fit(self, train_data, val_data, used_features, V1, epochs=1, batch_size=64):\n",
    "        \"\"\"\n",
    "        Train the neural network using training data and evaluate its performance on validation data.\n",
    "        :param train_data: Training data.\n",
    "        :param val_data: Validation data.\n",
    "        :param used_features: A list of feature names to be used for training.\n",
    "        :param V1: The column name for the target V1.\n",
    "        :param epochs: Number of epochs for training the model.\n",
    "        :param batch_size: Batch size used during training.\n",
    "        :return: History object with training metrics.\n",
    "        \"\"\"\n",
    "        \n",
    "        # A dictionary that contains the training data used for fitting the model.\n",
    "        # The dictionary has two keys, 'x' and 't', where 'x' contains the input\n",
    "        # features required for training, and 't' contains the target variable 'V1_hat'\n",
    "        # representing the final portfolio value.\n",
    "        train_pair = {\n",
    "            'x': {\n",
    "                'features': train_data[used_features].values,\n",
    "                'cp_int': train_data['cp_int'].values,\n",
    "                'V0': train_data['V0_n'].values,\n",
    "                'S0': train_data['S0_n'].values,\n",
    "                'S1': train_data['S1_n'].values,\n",
    "                'on_ret': train_data['on_ret'].values\n",
    "            },\n",
    "            't': {'V1_hat': train_data[V1].values}\n",
    "        }\n",
    "        \n",
    "        # A dictionary similar to train_pair, but containing the validation data used\n",
    "        # for evaluating the model's performance.\n",
    "        val_pair = {\n",
    "            'x': {\n",
    "                'features': val_data[used_features].values,\n",
    "                'cp_int': val_data['cp_int'].values,\n",
    "                'V0': val_data['V0_n'].values,\n",
    "                'S0': val_data['S0_n'].values,\n",
    "                'S1': val_data['S1_n'].values,\n",
    "                'on_ret': val_data['on_ret'].values\n",
    "            },\n",
    "            't': {'V1_hat': val_data[V1].values}\n",
    "        }\n",
    "\n",
    "        # The training history object that captures the training metrics during the\n",
    "        # training process.\n",
    "        # V1_hat = cash1 + delta_S1\n",
    "        \n",
    "        '''\n",
    "        x: The input data for training (train_pair['x']), which includes the features,\n",
    "        control parameter, initial portfolio value, initial stock price, final stock price,\n",
    "        and one-day return of the stock.\n",
    "\n",
    "       y: The target data for training (train_pair['t']), which includes the target variable\n",
    "       'V1_hat' representing the final portfolio value.\n",
    "\n",
    "       batch_size: The number of samples per gradient update. It specifies how many samples\n",
    "       are processed before the model's weights are updated.\n",
    "\n",
    "       epochs: The number of times the entire dataset is passed forward and backward\n",
    "       through the neural network during training.\n",
    "\n",
    "       validation_data: The validation data used for evaluating the model's performance\n",
    "       during training. It is a tuple containing the input data (val_pair['x']) and the\n",
    "       target data (val_pair['t']).\n",
    "       '''\n",
    "        history = self.model.fit(\n",
    "            x=train_pair['x'],\n",
    "            y=train_pair['t'],\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(val_pair['x'], val_pair['t']),\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def calculate_delta(self, df, used_features):\n",
    "        \"\"\"\n",
    "        Calculate the delta using the trained model and given DataFrame.\n",
    "        :param df: DataFrame containing the input features.\n",
    "        :param used_features: A list of feature names to be used for inference.\n",
    "        :return: Array of predicted delta values.\n",
    "        \"\"\"\n",
    "        \n",
    "        # This variable stores the name of the output layer of the neural network that\n",
    "        # represents the predicted delta values.\n",
    "        output_name = 'delta'\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        A new submodel is created using the Keras functional API. It takes the following\n",
    "        arguments:\n",
    "\n",
    "        - inputs: A list of input layers required for inference, which includes 'features'\n",
    "           and 'cp_int'.\n",
    "\n",
    "        - outputs: The output layer of the submodel, which is the layer corresponding to\n",
    "          the predicted delta values.\n",
    "\n",
    "          The purpose of creating the submodel is to extract the predicted delta values \n",
    "          using specific input features from the original neural network model.\n",
    "        '''\n",
    "    \n",
    "        submodel = Model(\n",
    "            inputs=[self.model.get_layer('features').input,\n",
    "                    self.model.get_layer('cp_int').input],\n",
    "            outputs=self.model.get_layer(name=output_name).output)\n",
    "        \n",
    "        '''\n",
    "         The function then uses the submodel to predict the delta values for the given\n",
    "         DataFrame. It calls the predict method on the submodel and provides the input\n",
    "         data for inference as a dictionary. The input data includes the features\n",
    "         ('features') and the control parameter ('cp_int') from the DataFrame df.\n",
    "        '''\n",
    "        var = submodel.predict(\n",
    "            x={'features': df[used_features].values, 'cp_int': df['cp_int'].values})\n",
    "        \n",
    "        # Return the predicted delta values as a flattened NumPy array\n",
    "        return var.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Helpful Functions\n",
    "\n",
    "The function below, takes a list of dataframes, standardizes the specified features in each dataframe using the given scaler, and returns a new list of dataframes with the standardized features. This process is useful for preparing data for machine learning models, as it ensures that all features have the same scale, which can improve the performance and stability of the models.\n",
    "\n",
    "\n",
    "Code explanation:\n",
    "\n",
    "1. The `standardize_feature` function takes three parameters: `list_of_dataframes`, `scaler`, and `original_features`.\n",
    "2. The function creates new feature names with a `_t` suffix to represent the standardized features.\n",
    "3. The `transformed_df` is appended to the `standardized_dataframes` list.\n",
    "4. The function returns the list of standardized dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_feature(list_of_df, scaler, original_features):\n",
    "    \"\"\"\n",
    "    Standardize the selected features in the given DataFrame or list of DataFrames using the provided scaler.\n",
    "    :param list_of_df: DataFrame or list of DataFrames containing the data to be standardized.\n",
    "    :param scaler: The scaler used for normalization.\n",
    "    :param original_features: List of feature names to be standardized.\n",
    "    :return: DataFrame or list of DataFrames with standardized features.\n",
    "    \"\"\"\n",
    "    if not isinstance(list_of_df, list):\n",
    "        # If a single DataFrame is provided, convert it to a list\n",
    "        list_of_df = [list_of_df]\n",
    "\n",
    "    trans_fea = [x + '_t' for x in original_features]\n",
    "    std_res = []\n",
    "    for df in list_of_df:\n",
    "        # Copy the DataFrame to avoid modifying the original DataFrame\n",
    "        var = df.copy()\n",
    "        var[trans_fea] = scaler.transform(var[original_features])\n",
    "        std_res.append(var)\n",
    "\n",
    "    # If only one DataFrame was provided in the list, return it directly instead of a list\n",
    "    if len(std_res) == 1:\n",
    "        return std_res[0]\n",
    "    return std_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `calculate_pnl` function is used to compute the PnL based on the predicted delta values and the provided DataFrame containing relevant features (`'S0_n'`, `'S1_n'`, `'V0_n'`, `'V1_n'`, and `'on_ret'`). The resulting PnL values indicate the profit or loss that would be obtained based on the predictions compared to the actual values.\n",
    "Code explanation:\n",
    "\n",
    "1. The `calculate_pnl` function takes three parameters: `df`, `delta`, and `target_column`.\n",
    "2. The function calculates the Profit and Loss (PnL) based on the provided DataFrame (`df`) and the array of predicted delta values (`delta`).\n",
    "3. It assumes short option and uses the columns `'S0_n'`, `'S1_n'`, `'V0_n'`, `'V1_n'`, and `'on_ret'` from the DataFrame.\n",
    "4. The calculated PnL is the difference between the predicted `v1_hat` and the actual `v1`.\n",
    "5. The `target_column` parameter allows you to specify the target column name in case you want to compare the PnL to a different column instead of the default `'V1_n'`.\n",
    "6. The function returns a Series containing the calculated PnL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pnl(df, delta, target_column='V1_n'):\n",
    "    \"\"\"\n",
    "    Calculate the Profit and Loss (PnL) for a given DataFrame and delta values.\n",
    "    We assume short option.\n",
    "    :param df: DataFrame containing the required columns (S0_n, S1_n, V0_n, V1_n, on_ret).\n",
    "    :param delta: Array of predicted delta values.\n",
    "    :param target_column: The target column name to compare to (default is 'V1_n').\n",
    "    :return: Series containing PnL values.\n",
    "    \"\"\"\n",
    "    s0, s1 = df['S0_n'], df['S1_n']\n",
    "    v0, v1 = df['V0_n'], df[target_column]\n",
    "    on_ret = df['on_ret']\n",
    "    \n",
    "    v1_hat = (v0 - delta * s0) * on_ret + delta * s1\n",
    "    pnl = v1_hat - v1\n",
    "    return pnl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `remove_columns_rename` function is responsible for removing specific columns from a dataframe and renaming certain columns based on provided dictionaries. It removes specific columns from the dataframe based on the provided `whole_dictionary` and renames certain columns using the `renaming_dictionary`. This allows for selective column removal and renaming in the dataframe.\n",
    "\n",
    "\n",
    "Code explanation:\n",
    "\n",
    "1. The function takes four parameters: `dataframe` (the input dataframe), `whole_dictionary` (a dictionary containing column information), `single_key` (a key from `whole_dictionary`), and `future_volume` (an optional parameter indicating whether to consider the future volume column).\n",
    "\n",
    "2. It creates a copy of the `whole_dictionary` called `remove_frequency` to prevent modifying the original dictionary.\n",
    "\n",
    "3. The function removes columns from the dataframe based on the values in `remove_frequency`. It iterates over the items in `remove_frequency` using a for loop.\n",
    "\n",
    "4. For each item, it retrieves the tag (value[1]) and identifies columns in the dataframe that contain this tag. It uses a list comprehension to create a list of columns to be removed.\n",
    "\n",
    "5. It then iterates over the columns to be removed and deletes them from the dataframe using the `del` keyword.\n",
    "\n",
    "6. Next, it creates a dictionary called `renaming_dictionary` to store the renaming mappings for specific columns. The dictionary is populated based on the provided `single_key` and the values in `whole_dictionary`.\n",
    "\n",
    "7. The dictionary maps the original column names to their corresponding new names. For example, if `whole_dictionary[single_key][1]` is equal to 2, it renames columns with the pattern `S2` to `S1` and so on.\n",
    "\n",
    "8. If `future_volume` is `True`, it adds an additional mapping for the volume column.\n",
    "\n",
    "9. Finally, it applies the renaming_dictionary to the dataframe using the `rename` function with the `inplace=True` parameter, effectively renaming the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns_rename(dataframe, whole_dictionary, single_key, future_volume=None):\n",
    "    remove_frequency = whole_dictionary.copy()\n",
    "    remove_frequency.pop(single_key)\n",
    "\n",
    "    for key, value in remove_frequency.items():\n",
    "        tag = value[1]\n",
    "        columns_to_remove = [column for column in dataframe.columns if tag in column]\n",
    "        for col in columns_to_remove:\n",
    "            del dataframe[col]\n",
    "\n",
    "    renaming_dictionary = {\n",
    "        f\"S{whole_dictionary[single_key][1]}\": \"S1\",\n",
    "        f\"V{whole_dictionary[single_key][1]}\": \"V1\",\n",
    "        f\"V{whole_dictionary[single_key][1]}_atm\": \"V1_atm\",\n",
    "        f\"implvol{whole_dictionary[single_key][1]}\": \"implvol1\",\n",
    "        f\"S{whole_dictionary[single_key][1]}_n\": \"S1_n\",\n",
    "        f\"V{whole_dictionary[single_key][1]}_n\": \"V1_n\",\n",
    "        f\"V{whole_dictionary[single_key][1]}_atm_n\": \"V1_atm_n\"\n",
    "    }\n",
    "\n",
    "    if future_volume:\n",
    "        renaming_dictionary[f\"volume{whole_dictionary[single_key][1]}\"] = \"volume1\"\n",
    "\n",
    "    dataframe.rename(columns=renaming_dictionary, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code explanation:\n",
    "\n",
    "The `assign_data_tag` function is used to assign data tags to a specific period in the dataframe. It takes the following parameters:\n",
    "- `dataframe`: The input dataframe to which the data tags will be assigned.\n",
    "- `data_tag`: The tag indicating whether the data belongs to the train, validation, or test set.\n",
    "- `data_period`: The period for which the data tags will be assigned.\n",
    "- `data_offset`: The business offset used to determine the end of the assigned period.\n",
    "- `start_date`: The start date of the assigned period.\n",
    "- `end_date`: The end date of the assigned period.\n",
    "\n",
    "The function first checks if the `data_offset` is a `pd.Timedelta` object. If it is, and the offset is less than or equal to 2 hours, the `data_end` is set to the `end_date`. Otherwise, the `data_end` is calculated by subtracting the `data_offset` from the `end_date`.\n",
    "\n",
    "Next, the function filters the dataframe based on the specified date range using a boolean mask. The mask is created by checking if the date is within the start and end date range. The filtered rows in the dataframe are then assigned the corresponding data tag using the `loc` indexer and the `f'period{data_period}'` column.\n",
    "\n",
    "Finally, the modified dataframe is returned with the assigned data tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_data_tag(dataframe, data_tag=None, data_period=None, data_offset=None, start_date=None, end_date=None):\n",
    "    \"\"\"\n",
    "    Assign data tags to a specified period in the dataframe.\n",
    "    The data_tag indicates whether the data belongs to the train, validation, or test set.\n",
    "    The assigned data_period is from the start_date to (end_date - business_offset).\n",
    "    \"\"\"\n",
    "    # Check if the offset is a Timedelta object\n",
    "    if isinstance(data_offset, pd.Timedelta):\n",
    "        if data_offset <= pd.Timedelta('2 hours'):\n",
    "            data_end = end_date\n",
    "    else:\n",
    "        data_end = end_date - data_offset\n",
    "    # Filter the dataframe based on the specified date range\n",
    "    date_range = (dataframe['date'] >= start_date) & (dataframe['date'] <= data_end)\n",
    "    dataframe.loc[date_range, f'period{data_period}'] = data_tag\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `add_custom_features` function takes an input dataframe and adds custom features to it.\n",
    "\n",
    "Code explanation:\n",
    "\n",
    "1. The function starts by creating a copy of the input dataframe using the `copy()` method to ensure that the original dataframe is not modified.\n",
    "\n",
    "2. The first feature, custom feature 1 , is calculated by taking the square root of the `tau0` column and multiplying it by the `implvol0` column.\n",
    "\n",
    "3. The second feature, custom feature 2 , is calculated by taking the square root of the `tau0` column.\n",
    "\n",
    "4. The third feature, custom feature 3 , is calculated by taking the reciprocal of the square root of the `tau0` column.\n",
    "\n",
    "5. The next set of features, custom feature 4, custom feature 5 , and custom feature 6 , are calculated for additional analysis. custom feature 4 is obtained by dividing the `vega_n` column by the product of the `S0_n` column (stock price) and the square root of the `tau0` column. custom feature 5  is the product of the `delta_bs` column and custom feature 4 , while custom feature 6 is obtained by squaring the `delta_bs` column and multiplying it by custom feature 4.\n",
    "\n",
    "6. Finally, the modified dataframe with the added features is returned.\n",
    "\n",
    "This code allows for the creation of custom features based on various calculations involving existing columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_custom_features(input_df):\n",
    "    \"\"\"\n",
    "    Add custom features to the input dataframe.\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe\n",
    "    df = input_df.copy()\n",
    "\n",
    "    # Calculate the feature: tau0_implvol0\n",
    "    df['tau0_implvol0'] = np.sqrt(df['tau0']) * df['implvol0']\n",
    "\n",
    "    # Calculate the feature: sqrt_tau0\n",
    "    df['sqrt_tau0'] = np.sqrt(df['tau0'])\n",
    "\n",
    "    # Calculate the feature: 1_over_sqrt_tau\n",
    "    df['1_over_sqrt_tau'] = 1 / np.sqrt(df['tau0'])\n",
    "\n",
    "    # Calculate features for additional analysis\n",
    "    df['vega_s'] = df['vega_n'] / (df['S0_n'] * np.sqrt(df['tau0']))\n",
    "    df['delta_vega_s'] = df['delta_bs'] * df['vega_s']\n",
    "    df['delta2_vega_s'] = (df['delta_bs']**2) * df['vega_s']\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`modify_dataframe` function takes a dataframe, original size, minimum moneyness, and maximum moneyness as input. It removes in-the-money samples and shrinks the moneyness range in the dataframe. It prints information about the sample removal, such as the number of removed samples and the percentage of remaining data.\n",
    "\n",
    "The `modify_dataframe` function shrinks the moneyness range by removing samples that fall outside the specified range.\n",
    "\n",
    "code explanation:\n",
    "\n",
    "1. It first checks whether each sample in the dataframe meets the criteria for being considered in-the-money. For call options, the condition is `df['cp_int'] == 0` and `df['M0'] < 1.001`. For put options, the condition is `df['cp_int'] == 1` and `df['M0'] > 0.999`. The bitwise OR operator (`|`) combines these conditions.\n",
    "\n",
    "2. It calculates the number of samples that meet the in-the-money condition and calculates the percentage of removed samples based on the original size of the dataframe.\n",
    "\n",
    "3. It filters the dataframe to keep only the samples that satisfy the in-the-money condition using the `loc` function.\n",
    "\n",
    "4. Next, it checks whether each sample's moneyness value (`M0`) falls within the specified range (`min_moneyness` to `max_moneyness`). It uses the bitwise AND operator (`&`) to combine the conditions.\n",
    "\n",
    "5. It calculates the number of samples that fall outside the moneyness range and calculates the corresponding removal percentage.\n",
    "\n",
    "6. It filters the dataframe again to retain only the samples that fall within the desired moneyness range using the `loc` function.\n",
    "\n",
    "7. Finally, it returns the modified dataframe.\n",
    "\n",
    "In summary, the `modify_dataframe` function removes samples that are considered in-the-money or fall outside the specified moneyness range, effectively shrinking the moneyness range of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_dataframe(dataframe, original_size, min_moneyness, max_moneyness):\n",
    "    \"\"\"\n",
    "    Remove in-the-money samples and shrink the moneyness range in the dataframe.\n",
    "    Print information about sample removal.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove in-the-money samples\n",
    "    in_the_money = ((dataframe['cp_int'] == 0) & (dataframe['M0'] < 1.001)) | ((dataframe['cp_int'] == 1) & (dataframe['M0'] > 0.999))\n",
    "    removed_count = dataframe.shape[0] - sum(in_the_money)\n",
    "    removal_percentage = (removed_count / dataframe.shape[0]) * 100\n",
    "    remaining_percentage = (sum(in_the_money) / original_size) * 100\n",
    "    print(f\"Removing in-the-money samples: {removed_count} samples ({removal_percentage:.2f}%) removed. \"\n",
    "          f\"{remaining_percentage:.2f}% of data remaining. Current size of data: {sum(in_the_money)}.\")\n",
    "\n",
    "    dataframe = dataframe.loc[in_the_money]\n",
    "\n",
    "    # Shrink moneyness range\n",
    "    within_moneyness_range = (dataframe['M0'] >= min_moneyness - 0.001) & (dataframe['M0'] <= max_moneyness + 0.001)\n",
    "    removed_count = dataframe.shape[0] - sum(within_moneyness_range)\n",
    "    removal_percentage = (removed_count / dataframe.shape[0]) * 100\n",
    "    remaining_percentage = (sum(within_moneyness_range) / original_size) * 100\n",
    "    print(f\"Shrinking moneyness range: {removed_count} samples ({removal_percentage:.2f}%) removed. \"\n",
    "          f\"{remaining_percentage:.2f}% of data remaining. Current size of data: {sum(within_moneyness_range)}.\")\n",
    "\n",
    "    dataframe = dataframe.loc[within_moneyness_range]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "\n",
    "In this part we implement a code which  loads and cleans the training and validation data from a CSV file, applies data modifications and feature engineering operations, and prepares the `df_train` DataFrame for further processing in subsequent steps.\n",
    "\n",
    "Implementation steps:\n",
    "\n",
    "1. Define the directory path where the data files are located.\n",
    "2. Read the CSV file named 'train_validation_data.csv' located in the specified directory into a Pandas DataFrame (`df`), while specifying the column to be used as the index (`index_col=0`) and parsing the 'date' column as datetime objects (`parse_dates=['date']`).\n",
    "3. Store the original size of the DataFrame in the variable `original_size`.\n",
    "4. Remove unnecessary columns and rename certain columns in the DataFrame using the `remove_columns_rename` function, passing the DataFrame (`df`), a dictionary containing column removal frequencies (`OFFSET_DICT`), and the desired frequency (`FREQ`).\n",
    "5. Create a new column in the DataFrame named 'on_ret', which calculates the exponential of the product of the 'short_rate' column and a constant time interval (`DT`).\n",
    "6. Apply tagging to the DataFrame using the `assign_data_tag` function. This assigns a tag of 0 for the first period and a tag of 1 for the second period, based on specified offset values and date ranges.\n",
    "7. Print information about loading and cleaning the training and validation data, including the original size of the DataFrame before modifications.\n",
    "8. Modify the DataFrame by removing in-the-money samples and shrinking the moneyness range using the `modify_dataframe` function, passing the DataFrame (`df`), the original size  and specified moneyness range limits.\n",
    "9. Filter out rows where the 'V1' column is not NaN, and assign the resulting DataFrame to `df_train`.\n",
    "10. Perform additional custom feature engineering on the `df_train` DataFrame using the `add_custom_features` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load and clean the training and validation data.\n",
      "Original data size is 579717\n",
      "Removing in-the-money samples: 293046 samples (50.55%) removed. 49.45% of data remaining. Current size of data: 286671.\n",
      "Shrinking moneyness range: 0 samples (0.00%) removed. 49.45% of data remaining. Current size of data: 286671.\n"
     ]
    }
   ],
   "source": [
    "OFFSET_DICT = {\n",
    "    '1D': [BDay(1), '_1D'],\n",
    "    '2D': [BDay(2), '_2D']\n",
    "}\n",
    "DATE_BREAK = pd.Timestamp('2018/07/01') + pd.Timedelta('360D')\n",
    "FREQ = '1D'\n",
    "DT = 1 / 253.\n",
    "MIN_M, MAX_M = 0.8, 1.5\n",
    "seed = 42\n",
    "UNDERLYINGPARAS = {\n",
    "        's0': 2000.,\n",
    "        'volatility': 0.2,\n",
    "        'mu': 0.1,\n",
    "        'start_date': pd.Timestamp('2018/07/01'),\n",
    "        'end_date': pd.Timestamp('2018/07/01') + pd.Timedelta('450D')}\n",
    "\n",
    "df = pd.read_csv('C:/Users/fatem/Desktop/hedging_project/data/train_validation_data.csv', index_col=0, parse_dates=['date'])\n",
    "original_size = df.shape[0]\n",
    "\n",
    "remove_columns_rename(df, OFFSET_DICT, FREQ)\n",
    "df['on_ret'] = np.exp(df['short_rate'] * DT)\n",
    "\n",
    "assign_data_tag(df, 0, 0, OFFSET_DICT[FREQ][0], UNDERLYINGPARAS['start_date'], DATE_BREAK)\n",
    "assign_data_tag(df, 1, 0, OFFSET_DICT[FREQ][0], DATE_BREAK, UNDERLYINGPARAS['end_date'])\n",
    "\n",
    "print(\"Load and clean the training and validation data.\")\n",
    "print(f'Original data size is {df.shape[0]}')\n",
    "\n",
    "df = modify_dataframe(df, original_size, MIN_M, MAX_M)\n",
    "bl = df['V1'].notna()\n",
    "df_train = df.loc[bl]\n",
    "df_train = add_custom_features(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>S0</th>\n",
       "      <th>K</th>\n",
       "      <th>tau0</th>\n",
       "      <th>optionid</th>\n",
       "      <th>short_rate</th>\n",
       "      <th>M0</th>\n",
       "      <th>r</th>\n",
       "      <th>implvol0</th>\n",
       "      <th>V0</th>\n",
       "      <th>...</th>\n",
       "      <th>vanna_n</th>\n",
       "      <th>is_test_sample</th>\n",
       "      <th>on_ret</th>\n",
       "      <th>period0</th>\n",
       "      <th>tau0_implvol0</th>\n",
       "      <th>sqrt_tau0</th>\n",
       "      <th>1_over_sqrt_tau</th>\n",
       "      <th>vega_s</th>\n",
       "      <th>delta_vega_s</th>\n",
       "      <th>delta2_vega_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-07-02</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.055336</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>37.534770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046910</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047047</td>\n",
       "      <td>0.235236</td>\n",
       "      <td>4.251050</td>\n",
       "      <td>0.398832</td>\n",
       "      <td>0.203158</td>\n",
       "      <td>0.103486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>1998.273253</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.023715</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>23.709246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086651</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.153998</td>\n",
       "      <td>6.493587</td>\n",
       "      <td>0.398910</td>\n",
       "      <td>0.197443</td>\n",
       "      <td>0.097726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>1997.590376</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.019763</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>21.234924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113522</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028116</td>\n",
       "      <td>0.140580</td>\n",
       "      <td>7.113368</td>\n",
       "      <td>0.398777</td>\n",
       "      <td>0.194804</td>\n",
       "      <td>0.095163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2018-07-02</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>0.055336</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>35.134593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152719</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047047</td>\n",
       "      <td>0.235236</td>\n",
       "      <td>4.251050</td>\n",
       "      <td>0.398768</td>\n",
       "      <td>0.194684</td>\n",
       "      <td>0.095047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>1998.273253</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>0.023715</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>21.376550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247278</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.153998</td>\n",
       "      <td>6.493587</td>\n",
       "      <td>0.397194</td>\n",
       "      <td>0.183769</td>\n",
       "      <td>0.085024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579510</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>2870.292079</td>\n",
       "      <td>2870.0</td>\n",
       "      <td>0.830040</td>\n",
       "      <td>2580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>208.203738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179860</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.182213</td>\n",
       "      <td>0.911065</td>\n",
       "      <td>1.097616</td>\n",
       "      <td>0.397270</td>\n",
       "      <td>-0.184127</td>\n",
       "      <td>0.085340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579564</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>2870.292079</td>\n",
       "      <td>2865.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>2583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.001847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>215.191095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169944</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.190693</td>\n",
       "      <td>0.953463</td>\n",
       "      <td>1.048809</td>\n",
       "      <td>0.396748</td>\n",
       "      <td>-0.181781</td>\n",
       "      <td>0.083288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579582</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>2870.292079</td>\n",
       "      <td>2870.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>2584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>217.870857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188256</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.190693</td>\n",
       "      <td>0.953463</td>\n",
       "      <td>1.048809</td>\n",
       "      <td>0.397113</td>\n",
       "      <td>-0.183390</td>\n",
       "      <td>0.084691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579636</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>2870.292079</td>\n",
       "      <td>2865.0</td>\n",
       "      <td>1.007905</td>\n",
       "      <td>2587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.001847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>226.685962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180836</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200789</td>\n",
       "      <td>1.003945</td>\n",
       "      <td>0.996071</td>\n",
       "      <td>0.396554</td>\n",
       "      <td>-0.180975</td>\n",
       "      <td>0.082591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579654</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>2870.292079</td>\n",
       "      <td>2870.0</td>\n",
       "      <td>1.007905</td>\n",
       "      <td>2588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>229.376260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198235</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200789</td>\n",
       "      <td>1.003945</td>\n",
       "      <td>0.996071</td>\n",
       "      <td>0.396917</td>\n",
       "      <td>-0.182508</td>\n",
       "      <td>0.083920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285692 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date           S0       K      tau0  optionid  short_rate  \\\n",
       "15     2018-07-02  2000.000000  2000.0  0.055336         2         0.0   \n",
       "23     2018-07-12  1998.273253  2000.0  0.023715         2         0.0   \n",
       "24     2018-07-13  1997.590376  2000.0  0.019763         2         0.0   \n",
       "30     2018-07-02  2000.000000  2005.0  0.055336         3         0.0   \n",
       "38     2018-07-12  1998.273253  2005.0  0.023715         3         0.0   \n",
       "...           ...          ...     ...       ...       ...         ...   \n",
       "579510 2019-08-30  2870.292079  2870.0  0.830040      2580         0.0   \n",
       "579564 2019-08-30  2870.292079  2865.0  0.909091      2583         0.0   \n",
       "579582 2019-08-30  2870.292079  2870.0  0.909091      2584         0.0   \n",
       "579636 2019-08-30  2870.292079  2865.0  1.007905      2587         0.0   \n",
       "579654 2019-08-30  2870.292079  2870.0  1.007905      2588         0.0   \n",
       "\n",
       "              M0    r  implvol0          V0  ...   vanna_n  is_test_sample  \\\n",
       "15      1.000000  0.0       0.2   37.534770  ...  0.046910           False   \n",
       "23      0.999137  0.0       0.2   23.709246  ...  0.086651           False   \n",
       "24      0.998795  0.0       0.2   21.234924  ...  0.113522           False   \n",
       "30      0.997506  0.0       0.2   35.134593  ...  0.152719           False   \n",
       "38      0.996645  0.0       0.2   21.376550  ...  0.247278           False   \n",
       "...          ...  ...       ...         ...  ...       ...             ...   \n",
       "579510  1.000102  0.0       0.2  208.203738  ...  0.179860           False   \n",
       "579564  1.001847  0.0       0.2  215.191095  ...  0.169944           False   \n",
       "579582  1.000102  0.0       0.2  217.870857  ...  0.188256           False   \n",
       "579636  1.001847  0.0       0.2  226.685962  ...  0.180836           False   \n",
       "579654  1.000102  0.0       0.2  229.376260  ...  0.198235           False   \n",
       "\n",
       "        on_ret  period0  tau0_implvol0  sqrt_tau0  1_over_sqrt_tau    vega_s  \\\n",
       "15         1.0      0.0       0.047047   0.235236         4.251050  0.398832   \n",
       "23         1.0      0.0       0.030800   0.153998         6.493587  0.398910   \n",
       "24         1.0      0.0       0.028116   0.140580         7.113368  0.398777   \n",
       "30         1.0      0.0       0.047047   0.235236         4.251050  0.398768   \n",
       "38         1.0      0.0       0.030800   0.153998         6.493587  0.397194   \n",
       "...        ...      ...            ...        ...              ...       ...   \n",
       "579510     1.0      1.0       0.182213   0.911065         1.097616  0.397270   \n",
       "579564     1.0      1.0       0.190693   0.953463         1.048809  0.396748   \n",
       "579582     1.0      1.0       0.190693   0.953463         1.048809  0.397113   \n",
       "579636     1.0      1.0       0.200789   1.003945         0.996071  0.396554   \n",
       "579654     1.0      1.0       0.200789   1.003945         0.996071  0.396917   \n",
       "\n",
       "        delta_vega_s  delta2_vega_s  \n",
       "15          0.203158       0.103486  \n",
       "23          0.197443       0.097726  \n",
       "24          0.194804       0.095163  \n",
       "30          0.194684       0.095047  \n",
       "38          0.183769       0.085024  \n",
       "...              ...            ...  \n",
       "579510     -0.184127       0.085340  \n",
       "579564     -0.181781       0.083288  \n",
       "579582     -0.183390       0.084691  \n",
       "579636     -0.180975       0.082591  \n",
       "579654     -0.182508       0.083920  \n",
       "\n",
       "[285692 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Features for Training\n",
    "\n",
    "In  this part of the code we set the features and the subdirectory path based on the selected feature set, allowing the rest of the code to use the appropriate features and store the results in the correct subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_SET = 'normal_feature'\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "if FEATURE_SET == 'normal_feature':\n",
    "    original_features = ['M0', 'tau0_implvol0']\n",
    "\n",
    "if FEATURE_SET == 'delta_vega':\n",
    "    original_features = ['delta_bs', '1_over_sqrt_tau', 'vega_n']\n",
    "\n",
    "if FEATURE_SET == 'delta_vega_vanna':\n",
    "    original_features = ['delta_bs', '1_over_sqrt_tau', 'vega_n', 'vanna_n']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "The code below is splitting the original DataFrame `df_train` into two separate DataFrames: `df_train` and `df_val`.\n",
    "\n",
    "1. `df_val = df_train.loc[df_train['period0'] == 1].copy()`: This line creates a new DataFrame `df_val` by selecting rows from `df_train` where the value of the column 'period0' is equal to 1. The `.loc` method is used for label-based indexing, and the `.copy()` method is used to make a copy of the selected rows to ensure that `df_val` is independent of `df_train`.\n",
    "\n",
    "2. `df_train = df_train.loc[df_train['period0'] == 0].copy()`: This line updates the `df_train` DataFrame by selecting rows from the original `df_train` where the value of the column 'period0' is equal to 0. The `.loc` method is again used for label-based indexing, and the `.copy()` method is used to make a copy of the selected rows.\n",
    "\n",
    "After this operation, `df_train` will contain only those rows where 'period0' is equal to 0, and `df_val` will contain only those rows where 'period0' is equal to 1. This is a common technique used in machine learning to create separate training and validation datasets. The rows where 'period0' is 0 are used for training, and the rows where 'period0' is 1 are used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_train.loc[df_train['period0'] == 1].copy()\n",
    "df_train = df_train.loc[df_train['period0'] == 0].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is performing feature scaling on the selected features of the DataFrames `df_train` and `df_val` using `StandardScaler`.\n",
    "\n",
    "1. `used_features = [x + '_t' for x in original_features] + ['cp_int']`: This line creates a new list `used_features` by appending the suffix '_t' to each feature name in the `original_features` list and also includes the feature 'cp_int'. This suggests that '_t' suffix indicates the standardized version of the original feature names.\n",
    "\n",
    "2. `scaler = StandardScaler().fit(X=df_train[original_features])`: This line initializes a `StandardScaler` object and fits it to the training data `df_train[original_features]`. The `StandardScaler` is used to compute the mean and standard deviation of each feature in `original_features`, which will be used later to scale the data.\n",
    "\n",
    "3. `df_train = standardize_feature(df_train, scaler, original_features)`: This line applies the function `standardize_feature` to the DataFrame `df_train` using the previously fitted scaler and the `original_features` list. The function standardizes the selected features in `df_train` using the provided scaler, and the standardized features are added with the suffix '_t'.\n",
    "\n",
    "4. `df_val = standardize_feature(df_val, scaler, original_features)`: Similarly, this line applies the same feature scaling to the DataFrame `df_val` using the previously fitted scaler and the `original_features` list. The selected features in `df_val` are standardized using the same scaling parameters obtained from the training data.\n",
    "\n",
    "After these operations, both `df_train` and `df_val` will have their selected features standardized and appended with the '_t' suffix, and the 'cp_int' feature will be included in the standardized features. This preprocessing step ensures that the input features are on the same scale, which is a common requirement for many machine learning algorithms to work effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_features = [x + '_t' for x in original_features] + ['cp_int']\n",
    "\n",
    "scaler = StandardScaler().fit(X=df_train[original_features])\n",
    "df_train = standardize_feature(df_train, scaler, original_features)\n",
    "df_val = standardize_feature(df_val, scaler, original_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M0_t', 'tau0_implvol0_t', 'cp_int']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is part of a data preprocessing step for a Monte Carlo simulation dataset. The main purpose is to prepare the test set (`df_test`) for evaluation and analysis. \n",
    "\n",
    "1. `df_test = pd.read_csv(PATH, index_col=0, parse_dates=['date'])`: Reads the Monte Carlo data from the specified file (`test_data.csv`) into a DataFrame `df_test`. The 'date' column is parsed as datetime objects.\n",
    "\n",
    "2. `remove_columns_rename(df_test, OFFSET_DICT, FREQ)`: Calls a function `remove_columns_rename` to remove irrelevant columns and rename the remaining columns in the `df_test` DataFrame based on some configuration dictionaries (`OFFSET_DICT` and `FREQ`).\n",
    "\n",
    "3. `df_test['on_ret'] = np.exp(df_test['short_rate'] * DT)`: Calculates a new feature 'on_ret' by taking the exponential of the product of 'short_rate' and a parameter `DT`.\n",
    "\n",
    "4. `assign_data_tag(df_test, 2, 0, OFFSET_DICT[FREQ][0], df_test['date'].min(), df_test['date'].max())`: Calls a function `assign_data_tag` to assign data tags to the test set based on some parameters and the 'date' column.\n",
    "\n",
    "5. `original_size = df_test.shape[0]`: Records the original size (number of rows) of the test set.\n",
    "\n",
    "6. `bl = df_test['V1'].notna()`: Creates a boolean mask `bl` that checks if the 'V1' column is not NaN (not missing).\n",
    "\n",
    "7. `df_test = df_test.loc[bl]`: Removes rows from `df_test` where the 'V1' column is missing.\n",
    "\n",
    "8. Prints information about the removal and the remaining samples.\n",
    "\n",
    "9. `df_test = add_custom_features(df_test)`: Calls a function `add_custom_features` to add custom features to the test set `df_test`.\n",
    "\n",
    "So we load a Monte Carlo dataset, preprocesses it by removing irrelevant rows, calculates new features and assigns data tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We remove samples when S1 is not available. 2582 samples (1.89%) are removed. 98.11% of data is left. Current size of data: 133861.\n"
     ]
    }
   ],
   "source": [
    "# Import Monte Carlo Set and Preprocessing\n",
    "\n",
    "# Read the Monte Carlo data for the current set\n",
    "df_test = pd.read_csv('C:/Users/fatem/Desktop/hedging_project/data/test_data.csv', index_col=0, parse_dates=['date'])\n",
    "\n",
    "# Remove irrelevant columns and rename remaining columns\n",
    "remove_columns_rename(df_test, OFFSET_DICT, FREQ)\n",
    "\n",
    "# Calculate the 'on_ret' feature\n",
    "df_test['on_ret'] = np.exp(df_test['short_rate'] * DT)\n",
    "\n",
    "# Assign data tags for the test set\n",
    "assign_data_tag(df_test, 2, 0, OFFSET_DICT[FREQ][0], df_test['date'].min(), df_test['date'].max())\n",
    "\n",
    "# Record the original size of the test set\n",
    "original_size = df_test.shape[0]\n",
    "\n",
    "# Modify the test set by removing rows where S1 is not available\n",
    "bl = df_test['V1'].notna()\n",
    "df_test = df_test.loc[bl]\n",
    "\n",
    "# Print information about sample removal\n",
    "removal_count = original_size - sum(bl)\n",
    "removal_percentage = (removal_count / original_size) * 100\n",
    "remaining_percentage = (sum(bl) / original_size) * 100\n",
    "print(f'We remove samples when S1 is not available. {removal_count} samples ({removal_percentage:.2f}%) are removed. '\n",
    "      f'{remaining_percentage:.2f}% of data is left. Current size of data: {sum(bl)}.')\n",
    "\n",
    "# Add custom features to the test set\n",
    "df_test = add_custom_features(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "The purpose of this section is for tuning and training a neural network for a hedging model. We define functions to train and test the neural network with different hyperparameter settings, specifically focusing on the `reg_alpha` parameter. The code then loops over a set of predefined values for `reg_alpha`, trains the neural network with each value, and tests it on a test dataset. It keeps track of the best hyperparameter value for `reg_alpha` based on the lowest validation mean squared error (MSE). Finally, it prints the best hyperparameter value and plots the MSE history for each value of `reg_alpha`.\n",
    "\n",
    "Code explanation:\n",
    "\n",
    "1. The code starts with importing required libraries and defining some global variables like `best_hyperparams`, `best_val_loss`, and `best_model` to keep track of the best hyperparameters and model during training.\n",
    "\n",
    "2. The function `plot_training_progress` is defined to plot the mean squared error (MSE) history during training and validation. It calculates the MSE and plots it.\n",
    "\n",
    "3. The function `train_neural_network` is the core function used for training the neural network. It builds a neural network using the provided hyperparameters, fits it to the training data, and returns the training history.\n",
    "\n",
    "4. The function `test_selected_model` is the core function used for testing the trained neural network on the test data. It builds the neural network with the best hyperparameters, loads the weights of the best model, calculates delta values for the test set, and returns the delta values.\n",
    "\n",
    "5. The main part of the code contains the hyperparameters (`hypers`) and the list of values to tune (`set_of_values`). It also initializes dictionaries to store the MSE history for each alpha (`mse_history`) and the best hyperparameter values for each parameter (`best_hyperparameter_value`).\n",
    "\n",
    "6. The code then loops over the `set_of_values` and tunes the hyperparameter `reg_alpha` by training the neural network and testing it on the test set. It saves the MSE history for each value of `reg_alpha`.\n",
    "\n",
    "7. After the loop, the best hyperparameter values for each parameter are printed.\n",
    "\n",
    "8. Finally, the function `plot_training_progress` is called to plot the MSE history for each value of `reg_alpha`.\n",
    "\n",
    "Note that the provided code is for tuning a single hyperparameter (`reg_alpha`) using the value set `[1e-2, 1e-3, 1e-4, 1e-5, 1e-6]`. If we have multiple hyperparameters to tune, we would need to modify the code accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.1920 - mean_squared_error: 0.0153 - val_loss: 0.0580 - val_mean_squared_error: 0.0022\n",
      "Epoch 2/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0255 - mean_squared_error: 0.0036 - val_loss: 0.0085 - val_mean_squared_error: 0.0020\n",
      "Epoch 3/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0079 - mean_squared_error: 0.0035 - val_loss: 0.0054 - val_mean_squared_error: 0.0018\n",
      "Epoch 4/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0066 - mean_squared_error: 0.0033 - val_loss: 0.0048 - val_mean_squared_error: 0.0017\n",
      "Epoch 5/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0061 - mean_squared_error: 0.0031 - val_loss: 0.0045 - val_mean_squared_error: 0.0016\n",
      "Epoch 6/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0058 - mean_squared_error: 0.0030 - val_loss: 0.0043 - val_mean_squared_error: 0.0015\n",
      "Epoch 7/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0056 - mean_squared_error: 0.0029 - val_loss: 0.0042 - val_mean_squared_error: 0.0015\n",
      "Epoch 8/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0055 - mean_squared_error: 0.0029 - val_loss: 0.0040 - val_mean_squared_error: 0.0015\n",
      "Epoch 9/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0053 - mean_squared_error: 0.0028 - val_loss: 0.0039 - val_mean_squared_error: 0.0014 loss: 0.0053 \n",
      "Epoch 10/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0052 - mean_squared_error: 0.0028 - val_loss: 0.0038 - val_mean_squared_error: 0.0015\n",
      "Epoch 11/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0051 - mean_squared_error: 0.0027 - val_loss: 0.0037 - val_mean_squared_error: 0.0014\n",
      "Epoch 12/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0050 - mean_squared_error: 0.0027 - val_loss: 0.0037 - val_mean_squared_error: 0.0015\n",
      "Epoch 13/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0049 - mean_squared_error: 0.0027 - val_loss: 0.0035 - val_mean_squared_error: 0.0013\n",
      "Epoch 14/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0048 - mean_squared_error: 0.0026 - val_loss: 0.0035 - val_mean_squared_error: 0.0014\n",
      "Epoch 15/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0047 - mean_squared_error: 0.0026 - val_loss: 0.0034 - val_mean_squared_error: 0.0013\n",
      "Epoch 16/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0046 - mean_squared_error: 0.0026 - val_loss: 0.0033 - val_mean_squared_error: 0.0013\n",
      "Epoch 17/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0046 - mean_squared_error: 0.0026 - val_loss: 0.0033 - val_mean_squared_error: 0.0013\n",
      "Epoch 18/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0045 - mean_squared_error: 0.0025 - val_loss: 0.0032 - val_mean_squared_error: 0.0013\n",
      "Epoch 19/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0044 - mean_squared_error: 0.0025 - val_loss: 0.0032 - val_mean_squared_error: 0.0013\n",
      "Epoch 20/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0044 - mean_squared_error: 0.0025 - val_loss: 0.0031 - val_mean_squared_error: 0.0013\n",
      "Epoch 21/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0043 - mean_squared_error: 0.0025 - val_loss: 0.0032 - val_mean_squared_error: 0.0013\n",
      "Epoch 22/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0043 - mean_squared_error: 0.0024 - val_loss: 0.0030 - val_mean_squared_error: 0.0012\n",
      "Epoch 23/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0042 - mean_squared_error: 0.0024 - val_loss: 0.0030 - val_mean_squared_error: 0.0012\n",
      "Epoch 24/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0042 - mean_squared_error: 0.0024 - val_loss: 0.0030 - val_mean_squared_error: 0.0012\n",
      "Epoch 25/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0042 - mean_squared_error: 0.0024 - val_loss: 0.0029 - val_mean_squared_error: 0.0012\n",
      "Epoch 26/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0041 - mean_squared_error: 0.0024 - val_loss: 0.0029 - val_mean_squared_error: 0.0012\n",
      "Epoch 27/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0041 - mean_squared_error: 0.0024 - val_loss: 0.0029 - val_mean_squared_error: 0.0012\n",
      "Epoch 28/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0040 - mean_squared_error: 0.0024 - val_loss: 0.0028 - val_mean_squared_error: 0.0011\n",
      "Epoch 29/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0040 - mean_squared_error: 0.0024 - val_loss: 0.0029 - val_mean_squared_error: 0.0012\n",
      "Epoch 30/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0040 - mean_squared_error: 0.0023 - val_loss: 0.0028 - val_mean_squared_error: 0.0012\n",
      "Epoch 31/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0040 - mean_squared_error: 0.0023 - val_loss: 0.0027 - val_mean_squared_error: 0.0011\n",
      "Epoch 32/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0039 - mean_squared_error: 0.0023 - val_loss: 0.0028 - val_mean_squared_error: 0.0013\n",
      "Epoch 33/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0039 - mean_squared_error: 0.0023 - val_loss: 0.0027 - val_mean_squared_error: 0.0011\n",
      "Epoch 34/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0039 - mean_squared_error: 0.0023 - val_loss: 0.0028 - val_mean_squared_error: 0.0012\n",
      "Epoch 35/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0038 - mean_squared_error: 0.0023 - val_loss: 0.0026 - val_mean_squared_error: 0.0011\n",
      "Epoch 36/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0038 - mean_squared_error: 0.0023 - val_loss: 0.0026 - val_mean_squared_error: 0.0011\n",
      "Epoch 37/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0038 - mean_squared_error: 0.0023 - val_loss: 0.0026 - val_mean_squared_error: 0.0011\n",
      "Epoch 38/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0038 - mean_squared_error: 0.0023 - val_loss: 0.0026 - val_mean_squared_error: 0.0011\n",
      "Epoch 39/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0037 - mean_squared_error: 0.0023 - val_loss: 0.0026 - val_mean_squared_error: 0.0011\n",
      "Epoch 40/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0037 - mean_squared_error: 0.0023 - val_loss: 0.0025 - val_mean_squared_error: 0.0011\n",
      "Epoch 41/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0037 - mean_squared_error: 0.0023 - val_loss: 0.0025 - val_mean_squared_error: 0.0011\n",
      "Epoch 42/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0037 - mean_squared_error: 0.0022 - val_loss: 0.0025 - val_mean_squared_error: 0.0011\n",
      "Epoch 43/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0037 - mean_squared_error: 0.0022 - val_loss: 0.0025 - val_mean_squared_error: 0.0011\n",
      "Epoch 44/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0036 - mean_squared_error: 0.0022 - val_loss: 0.0025 - val_mean_squared_error: 0.0011\n",
      "Epoch 45/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0036 - mean_squared_error: 0.0022 - val_loss: 0.0025 - val_mean_squared_error: 0.0011\n",
      "Epoch 46/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0036 - mean_squared_error: 0.0022 - val_loss: 0.0025 - val_mean_squared_error: 0.0011\n",
      "Epoch 47/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0036 - mean_squared_error: 0.0022 - val_loss: 0.0024 - val_mean_squared_error: 0.0011\n",
      "Epoch 48/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0036 - mean_squared_error: 0.0022 - val_loss: 0.0025 - val_mean_squared_error: 0.0011\n",
      "Epoch 49/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0036 - mean_squared_error: 0.0022 - val_loss: 0.0024 - val_mean_squared_error: 0.0011\n",
      "Epoch 50/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0022 - val_loss: 0.0024 - val_mean_squared_error: 0.0010\n",
      "Epoch 51/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0022 - val_loss: 0.0024 - val_mean_squared_error: 0.0011\n",
      "Epoch 52/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0022 - val_loss: 0.0024 - val_mean_squared_error: 0.0010\n",
      "Epoch 53/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0022 - val_loss: 0.0024 - val_mean_squared_error: 0.0011\n",
      "Epoch 54/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0022 - val_loss: 0.0024 - val_mean_squared_error: 0.0011\n",
      "Epoch 55/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0022 - val_loss: 0.0024 - val_mean_squared_error: 0.0011\n",
      "Epoch 56/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0022 - val_loss: 0.0023 - val_mean_squared_error: 0.0010\n",
      "Epoch 57/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0034 - mean_squared_error: 0.0022 - val_loss: 0.0024 - val_mean_squared_error: 0.0010\n",
      "Epoch 58/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0034 - mean_squared_error: 0.0022 - val_loss: 0.0023 - val_mean_squared_error: 0.0011\n",
      "Epoch 59/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0034 - mean_squared_error: 0.0022 - val_loss: 0.0023 - val_mean_squared_error: 0.0010\n",
      "Epoch 60/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0034 - mean_squared_error: 0.0021 - val_loss: 0.0023 - val_mean_squared_error: 0.0010\n",
      "Epoch 61/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0034 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_mean_squared_error: 0.0012\n",
      "Epoch 62/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0034 - mean_squared_error: 0.0021 - val_loss: 0.0023 - val_mean_squared_error: 0.0010\n",
      "Epoch 63/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0034 - mean_squared_error: 0.0021 - val_loss: 0.0023 - val_mean_squared_error: 0.0011\n",
      "Epoch 64/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0034 - mean_squared_error: 0.0021 - val_loss: 0.0022 - val_mean_squared_error: 9.9657e-04\n",
      "Epoch 65/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0034 - mean_squared_error: 0.0021 - val_loss: 0.0023 - val_mean_squared_error: 0.0011\n",
      "Epoch 66/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0033 - mean_squared_error: 0.0021 - val_loss: 0.0023 - val_mean_squared_error: 0.0011\n",
      "Epoch 67/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0033 - mean_squared_error: 0.0021 - val_loss: 0.0022 - val_mean_squared_error: 9.9922e-04\n",
      "Epoch 68/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0033 - mean_squared_error: 0.0021 - val_loss: 0.0022 - val_mean_squared_error: 0.0010\n",
      "Epoch 69/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0033 - mean_squared_error: 0.0021 - val_loss: 0.0022 - val_mean_squared_error: 9.9828e-04\n",
      "Epoch 70/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0033 - mean_squared_error: 0.0021 - val_loss: 0.0022 - val_mean_squared_error: 0.0010\n",
      "Epoch 71/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0033 - mean_squared_error: 0.0021 - val_loss: 0.0022 - val_mean_squared_error: 0.0010\n",
      "Epoch 72/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0033 - mean_squared_error: 0.0021 - val_loss: 0.0022 - val_mean_squared_error: 0.0011\n",
      "Epoch 73/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0033 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 9.8623e-04\n",
      "Epoch 74/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0033 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 9.9839e-04\n",
      "Epoch 75/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0033 - mean_squared_error: 0.0021 - val_loss: 0.0022 - val_mean_squared_error: 0.0010\n",
      "Epoch 76/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0032 - mean_squared_error: 0.0021 - val_loss: 0.0022 - val_mean_squared_error: 0.0011\n",
      "Epoch 77/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0032 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 9.7336e-04\n",
      "Epoch 78/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0032 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 9.7341e-04\n",
      "Epoch 79/150\n",
      "3463/3463 [==============================] - 6s 2ms/step - loss: 0.0032 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 9.5223e-04\n",
      "Epoch 80/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0032 - mean_squared_error: 0.0021 - val_loss: 0.0022 - val_mean_squared_error: 0.0011\n",
      "Epoch 81/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0032 - mean_squared_error: 0.0021 - val_loss: 0.0022 - val_mean_squared_error: 0.0010\n",
      "Epoch 82/150\n",
      "3463/3463 [==============================] - 6s 2ms/step - loss: 0.0032 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 9.7898e-04\n",
      "Epoch 83/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0032 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 9.5979e-04\n",
      "Epoch 84/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0032 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 9.9854e-04\n",
      "Epoch 85/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0032 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 9.5343e-04\n",
      "Epoch 86/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0032 - mean_squared_error: 0.0021 - val_loss: 0.0022 - val_mean_squared_error: 0.0011\n",
      "Epoch 87/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0032 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 0.0010\n",
      "Epoch 88/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_squared_error: 9.8069e-04\n",
      "Epoch 89/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0032 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 9.8163e-04\n",
      "Epoch 90/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_squared_error: 9.7145e-04\n",
      "Epoch 91/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_squared_error: 9.6195e-04\n",
      "Epoch 92/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 0.0010\n",
      "Epoch 93/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_squared_error: 9.6084e-04\n",
      "Epoch 94/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 0.0010\n",
      "Epoch 95/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 9.9084e-04\n",
      "Epoch 96/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_squared_error: 9.6483e-04\n",
      "Epoch 97/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_squared_error: 9.9476e-04\n",
      "Epoch 98/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_squared_error: 9.8684e-04\n",
      "Epoch 99/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0031 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_squared_error: 9.8907e-04\n",
      "Epoch 100/150\n",
      "3463/3463 [==============================] - 6s 2ms/step - loss: 0.0031 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_squared_error: 9.4458e-04\n",
      "Epoch 101/150\n",
      "3463/3463 [==============================] - 6s 2ms/step - loss: 0.0031 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_squared_error: 9.4512e-04\n",
      "Epoch 102/150\n",
      "3463/3463 [==============================] - 6s 2ms/step - loss: 0.0031 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_squared_error: 0.0010\n",
      "Epoch 103/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_squared_error: 0.0010\n",
      "Epoch 104/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_squared_error: 9.6684e-04\n",
      "Epoch 105/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_squared_error: 9.4756e-04\n",
      "Epoch 106/150\n",
      "3463/3463 [==============================] - 6s 2ms/step - loss: 0.0031 - mean_squared_error: 0.0020 - val_loss: 0.0021 - val_mean_squared_error: 0.0011\n",
      "Epoch 107/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0020 - val_mean_squared_error: 9.9318e-04\n",
      "Epoch 108/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0020 - val_mean_squared_error: 0.0010\n",
      "Epoch 109/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 9.6084e-04\n",
      "Epoch 110/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0021 - val_mean_squared_error: 0.0011\n",
      "Epoch 111/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 9.2222e-04\n",
      "Epoch 112/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0020 - val_mean_squared_error: 9.8898e-04\n",
      "Epoch 113/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 9.5354e-04\n",
      "Epoch 114/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 9.3058e-04\n",
      "Epoch 115/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0020 - val_mean_squared_error: 0.0010\n",
      "Epoch 116/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 9.3826e-04\n",
      "Epoch 117/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0020 - val_mean_squared_error: 0.0011\n",
      "Epoch 118/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0021 - val_mean_squared_error: 0.0011\n",
      "Epoch 119/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0020 - val_mean_squared_error: 0.0010\n",
      "Epoch 120/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0020 - val_mean_squared_error: 0.0010\n",
      "Epoch 121/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 9.1532e-04\n",
      "Epoch 122/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 9.3722e-04\n",
      "Epoch 123/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 9.3473e-04\n",
      "Epoch 124/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 9.4934e-04\n",
      "Epoch 125/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 9.5293e-04\n",
      "Epoch 126/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 9.4367e-04\n",
      "Epoch 127/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 9.7097e-04\n",
      "Epoch 128/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 9.3556e-04\n",
      "Epoch 129/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 9.8534e-04\n",
      "Epoch 130/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 9.1621e-04\n",
      "Epoch 131/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_mean_squared_error: 0.0013\n",
      "Epoch 132/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 9.7930e-04\n",
      "Epoch 133/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 9.7819e-04\n",
      "Epoch 134/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 0.0010\n",
      "Epoch 135/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 9.0116e-04\n",
      "Epoch 136/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 9.8878e-04\n",
      "Epoch 137/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 9.1012e-04\n",
      "Epoch 138/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 0.0010\n",
      "Epoch 139/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 9.2828e-04\n",
      "Epoch 140/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 9.1339e-04\n",
      "Epoch 141/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 9.2419e-04\n",
      "Epoch 142/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 0.0010\n",
      "Epoch 143/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 0.0010\n",
      "Epoch 144/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 9.2371e-04\n",
      "Epoch 145/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 9.2715e-04\n",
      "Epoch 146/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 9.1397e-04\n",
      "Epoch 147/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 0.0010\n",
      "Epoch 148/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 9.1032e-04\n",
      "Epoch 149/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 9.6684e-04\n",
      "Epoch 150/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 9.0585e-04\n",
      "Epoch 1/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0664 - mean_squared_error: 0.0425 - val_loss: 0.0200 - val_mean_squared_error: 0.0022\n",
      "Epoch 2/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0168 - mean_squared_error: 0.0029 - val_loss: 0.0116 - val_mean_squared_error: 0.0012\n",
      "Epoch 3/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0100 - mean_squared_error: 0.0022 - val_loss: 0.0069 - val_mean_squared_error: 0.0011\n",
      "Epoch 4/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0067 - mean_squared_error: 0.0021 - val_loss: 0.0048 - val_mean_squared_error: 0.0010\n",
      "Epoch 5/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0052 - mean_squared_error: 0.0020 - val_loss: 0.0037 - val_mean_squared_error: 9.6002e-04\n",
      "Epoch 6/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0045 - mean_squared_error: 0.0020 - val_loss: 0.0032 - val_mean_squared_error: 9.2758e-04\n",
      "Epoch 7/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0040 - mean_squared_error: 0.0019 - val_loss: 0.0028 - val_mean_squared_error: 9.3723e-04\n",
      "Epoch 8/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0037 - mean_squared_error: 0.0019 - val_loss: 0.0026 - val_mean_squared_error: 9.2464e-04\n",
      "Epoch 9/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_mean_squared_error: 9.6431e-04\n",
      "Epoch 10/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0033 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_mean_squared_error: 9.0043e-04\n",
      "Epoch 11/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0032 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_mean_squared_error: 9.2204e-04\n",
      "Epoch 12/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0019 - val_loss: 0.0020 - val_mean_squared_error: 8.7650e-04\n",
      "Epoch 13/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0019 - val_loss: 0.0020 - val_mean_squared_error: 8.6161e-04\n",
      "Epoch 14/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0019 - val_loss: 0.0019 - val_mean_squared_error: 8.7353e-04\n",
      "Epoch 15/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0019 - val_loss: 0.0019 - val_mean_squared_error: 8.5586e-04\n",
      "Epoch 16/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0029 - mean_squared_error: 0.0019 - val_loss: 0.0018 - val_mean_squared_error: 8.6642e-04\n",
      "Epoch 17/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0028 - mean_squared_error: 0.0019 - val_loss: 0.0018 - val_mean_squared_error: 8.5896e-04\n",
      "Epoch 18/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0028 - mean_squared_error: 0.0019 - val_loss: 0.0018 - val_mean_squared_error: 8.5259e-04\n",
      "Epoch 19/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0027 - mean_squared_error: 0.0019 - val_loss: 0.0017 - val_mean_squared_error: 8.4317e-04\n",
      "Epoch 20/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0027 - mean_squared_error: 0.0018 - val_loss: 0.0017 - val_mean_squared_error: 8.5577e-04\n",
      "Epoch 21/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0027 - mean_squared_error: 0.0018 - val_loss: 0.0017 - val_mean_squared_error: 8.7436e-04\n",
      "Epoch 22/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0026 - mean_squared_error: 0.0018 - val_loss: 0.0016 - val_mean_squared_error: 8.3715e-04\n",
      "Epoch 23/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0026 - mean_squared_error: 0.0018 - val_loss: 0.0017 - val_mean_squared_error: 8.7868e-04\n",
      "Epoch 24/150\n",
      "3463/3463 [==============================] - 6s 2ms/step - loss: 0.0026 - mean_squared_error: 0.0018 - val_loss: 0.0016 - val_mean_squared_error: 8.7910e-04\n",
      "Epoch 25/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0026 - mean_squared_error: 0.0018 - val_loss: 0.0016 - val_mean_squared_error: 8.5079e-04\n",
      "Epoch 26/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0026 - mean_squared_error: 0.0018 - val_loss: 0.0016 - val_mean_squared_error: 8.3371e-04\n",
      "Epoch 27/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0025 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 8.2918e-04\n",
      "Epoch 28/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0025 - mean_squared_error: 0.0018 - val_loss: 0.0016 - val_mean_squared_error: 8.6518e-04\n",
      "Epoch 29/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0025 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 8.2669e-04\n",
      "Epoch 30/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0025 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 8.5951e-04\n",
      "Epoch 31/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0025 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 8.3037e-04\n",
      "Epoch 32/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0025 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 8.2874e-04\n",
      "Epoch 33/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0025 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 8.3233e-04\n",
      "Epoch 34/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0018 - val_loss: 0.0014 - val_mean_squared_error: 8.0766e-04\n",
      "Epoch 35/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0018 - val_loss: 0.0014 - val_mean_squared_error: 8.2756e-04\n",
      "Epoch 36/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 9.1064e-04\n",
      "Epoch 37/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0018 - val_loss: 0.0014 - val_mean_squared_error: 8.0432e-04\n",
      "Epoch 38/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0018 - val_loss: 0.0014 - val_mean_squared_error: 8.0924e-04\n",
      "Epoch 39/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0018 - val_loss: 0.0014 - val_mean_squared_error: 8.6902e-04\n",
      "Epoch 40/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0018 - val_loss: 0.0014 - val_mean_squared_error: 8.1053e-04\n",
      "Epoch 41/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0018 - val_loss: 0.0014 - val_mean_squared_error: 8.3672e-04\n",
      "Epoch 42/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0018 - val_loss: 0.0014 - val_mean_squared_error: 8.0506e-04\n",
      "Epoch 43/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0018 - val_loss: 0.0014 - val_mean_squared_error: 8.2362e-04\n",
      "Epoch 44/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 9.2259e-04\n",
      "Epoch 45/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0018 - val_loss: 0.0014 - val_mean_squared_error: 8.3015e-04\n",
      "Epoch 46/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 7.9930e-04\n",
      "Epoch 47/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 8.0593e-04\n",
      "Epoch 48/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0018 - val_loss: 0.0014 - val_mean_squared_error: 8.8806e-04\n",
      "Epoch 49/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0018 - val_loss: 0.0014 - val_mean_squared_error: 8.6079e-04\n",
      "Epoch 50/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 7.9694e-04\n",
      "Epoch 51/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 7.9651e-04\n",
      "Epoch 52/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 8.1879e-04\n",
      "Epoch 53/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 8.2781e-04\n",
      "Epoch 54/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 7.9437e-04\n",
      "Epoch 55/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 8.5353e-04\n",
      "Epoch 56/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 8.2941e-04\n",
      "Epoch 57/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 8.0284e-04\n",
      "Epoch 58/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 8.0383e-04\n",
      "Epoch 59/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 7.9124e-04\n",
      "Epoch 60/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 7.9031e-04_err\n",
      "Epoch 61/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 8.3053e-04\n",
      "Epoch 62/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 8.4502e-04\n",
      "Epoch 63/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 8.0576e-04\n",
      "Epoch 64/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 8.0553e-04\n",
      "Epoch 65/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 8.5660e-04\n",
      "Epoch 66/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 8.4134e-04\n",
      "Epoch 67/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0018 - val_loss: 0.0012 - val_mean_squared_error: 7.9023e-04\n",
      "Epoch 68/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.7321e-04\n",
      "Epoch 69/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.9284e-04\n",
      "Epoch 70/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.8061e-042 - mean_squared_e - ETA: 1s - loss: 0.0022 -  - ETA\n",
      "Epoch 71/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.7955e-04\n",
      "Epoch 72/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.6877e-04\n",
      "Epoch 73/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.8745e-04\n",
      "Epoch 74/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0017 - val_loss: 0.0013 - val_mean_squared_error: 8.4608e-04\n",
      "Epoch 75/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.7948e-04\n",
      "Epoch 76/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.9381e-04\n",
      "Epoch 77/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.8867e-04\n",
      "Epoch 78/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0017 - val_loss: 0.0013 - val_mean_squared_error: 8.4253e-04\n",
      "Epoch 79/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.7492e-04\n",
      "Epoch 80/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.3309e-04\n",
      "Epoch 81/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.6509e-04\n",
      "Epoch 82/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.2018e-04\n",
      "Epoch 83/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.8571e-04\n",
      "Epoch 84/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.6049e-04\n",
      "Epoch 85/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.8543e-04\n",
      "Epoch 86/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.7276e-04\n",
      "Epoch 87/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.4758e-04\n",
      "Epoch 88/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.6989e-04\n",
      "Epoch 89/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.6023e-04\n",
      "Epoch 90/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.8238e-04\n",
      "Epoch 91/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.6967e-04\n",
      "Epoch 92/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.4265e-04\n",
      "Epoch 93/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.7711e-04\n",
      "Epoch 94/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.8162e-04\n",
      "Epoch 95/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.1341e-04\n",
      "Epoch 96/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.7381e-04\n",
      "Epoch 97/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.2373e-04\n",
      "Epoch 98/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.6769e-04\n",
      "Epoch 99/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.0382e-04\n",
      "Epoch 100/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.9859e-04\n",
      "Epoch 101/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.5609e-04\n",
      "Epoch 102/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.3063e-04\n",
      "Epoch 103/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.6212e-04\n",
      "Epoch 104/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.7161e-04\n",
      "Epoch 105/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.6475e-04\n",
      "Epoch 106/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.5311e-04\n",
      "Epoch 107/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.6706e-04\n",
      "Epoch 108/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.3683e-04\n",
      "Epoch 109/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0013 - val_mean_squared_error: 9.5261e-04\n",
      "Epoch 110/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.0536e-04\n",
      "Epoch 111/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.5908e-04\n",
      "Epoch 112/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.8943e-04\n",
      "Epoch 113/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.6469e-04\n",
      "Epoch 114/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.5093e-04\n",
      "Epoch 115/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.8881e-04\n",
      "Epoch 116/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.9781e-04\n",
      "Epoch 117/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.8197e-04\n",
      "Epoch 118/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.6353e-04\n",
      "Epoch 119/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.3070e-04\n",
      "Epoch 120/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.7556e-04\n",
      "Epoch 121/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.6881e-04\n",
      "Epoch 122/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.7475e-04\n",
      "Epoch 123/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.6745e-04\n",
      "Epoch 124/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.6057e-04\n",
      "Epoch 125/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.6440e-04\n",
      "Epoch 126/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.7129e-04\n",
      "Epoch 127/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.4940e-04\n",
      "Epoch 128/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.6041e-04\n",
      "Epoch 129/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.8962e-04\n",
      "Epoch 130/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.4056e-04\n",
      "Epoch 131/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.2068e-04\n",
      "Epoch 132/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 8.0265e-04\n",
      "Epoch 133/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.3857e-04\n",
      "Epoch 134/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0013 - val_mean_squared_error: 9.2774e-04\n",
      "Epoch 135/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.6005e-04 - loss: 0.002\n",
      "Epoch 136/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.8407e-04\n",
      "Epoch 137/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.5956e-04\n",
      "Epoch 138/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.7500e-04\n",
      "Epoch 139/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.7431e-04\n",
      "Epoch 140/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0013 - val_mean_squared_error: 9.4354e-04\n",
      "Epoch 141/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.8849e-04\n",
      "Epoch 142/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.7074e-04\n",
      "Epoch 143/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.5873e-04\n",
      "Epoch 144/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 8.1321e-04\n",
      "Epoch 145/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.4297e-04\n",
      "Epoch 146/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.6366e-04\n",
      "Epoch 147/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.6908e-04\n",
      "Epoch 148/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.7836e-04\n",
      "Epoch 149/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.6194e-04\n",
      "Epoch 150/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 8.9636e-04\n",
      "Epoch 1/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0462 - mean_squared_error: 0.0431 - val_loss: 0.0051 - val_mean_squared_error: 0.0023\n",
      "Epoch 2/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0053 - mean_squared_error: 0.0027 - val_loss: 0.0035 - val_mean_squared_error: 0.0010\n",
      "Epoch 3/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0043 - mean_squared_error: 0.0020 - val_loss: 0.0031 - val_mean_squared_error: 9.3583e-04\n",
      "Epoch 4/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0040 - mean_squared_error: 0.0019 - val_loss: 0.0028 - val_mean_squared_error: 8.5484e-04\n",
      "Epoch 5/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0038 - mean_squared_error: 0.0019 - val_loss: 0.0027 - val_mean_squared_error: 8.4327e-04\n",
      "Epoch 6/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0036 - mean_squared_error: 0.0018 - val_loss: 0.0025 - val_mean_squared_error: 8.5194e-04\n",
      "Epoch 7/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0034 - mean_squared_error: 0.0018 - val_loss: 0.0025 - val_mean_squared_error: 9.4159e-04\n",
      "Epoch 8/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0033 - mean_squared_error: 0.0018 - val_loss: 0.0023 - val_mean_squared_error: 8.5141e-04_squared - ETA: 0s - loss: 0.0033 - mean_squared_error: 0.00 - ETA: 0s - loss: 0.0033 - mean_squ\n",
      "Epoch 9/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0032 - mean_squared_error: 0.0018 - val_loss: 0.0022 - val_mean_squared_error: 7.9189e-04\n",
      "Epoch 10/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_mean_squared_error: 7.7726e-04\n",
      "Epoch 11/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_mean_squared_error: 8.0784e-04\n",
      "Epoch 12/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0017 - val_loss: 0.0021 - val_mean_squared_error: 8.6726e-04s: 0.0029 - mean_squared_error: 0.00 - ETA: 1s - ETA: 0s - loss: 0.0030 - mean_squar\n",
      "Epoch 13/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_mean_squared_error: 7.6622e-04\n",
      "Epoch 14/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0028 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_mean_squared_error: 8.0718e-04\n",
      "Epoch 15/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0028 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_mean_squared_error: 8.2764e-04\n",
      "Epoch 16/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0027 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_mean_squared_error: 8.0860e-04\n",
      "Epoch 17/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0027 - mean_squared_error: 0.0017 - val_loss: 0.0017 - val_mean_squared_error: 7.4966e-04\n",
      "Epoch 18/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0026 - mean_squared_error: 0.0017 - val_loss: 0.0017 - val_mean_squared_error: 7.8899e-04\n",
      "Epoch 19/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0026 - mean_squared_error: 0.0017 - val_loss: 0.0017 - val_mean_squared_error: 7.8821e-04\n",
      "Epoch 20/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0026 - mean_squared_error: 0.0017 - val_loss: 0.0016 - val_mean_squared_error: 7.7017e-04\n",
      "Epoch 21/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0025 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 7.4679e-04\n",
      "Epoch 22/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0025 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 7.6395e-04\n",
      "Epoch 23/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0025 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 7.4580e-04\n",
      "Epoch 24/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 7.5960e-04\n",
      "Epoch 25/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 7.7424e-04\n",
      "Epoch 26/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 8.8208e-04\n",
      "Epoch 27/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 7.5601e-04\n",
      "Epoch 28/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 7.7312e-04\n",
      "Epoch 29/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0017 - val_loss: 0.0013 - val_mean_squared_error: 7.4170e-04\n",
      "Epoch 30/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 7.8766e-04\n",
      "Epoch 31/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0017 - val_loss: 0.0013 - val_mean_squared_error: 7.2833e-04\n",
      "Epoch 32/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0017 - val_loss: 0.0013 - val_mean_squared_error: 7.5714e-04\n",
      "Epoch 33/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0017 - val_loss: 0.0013 - val_mean_squared_error: 7.5569e-04\n",
      "Epoch 34/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0017 - val_loss: 0.0013 - val_mean_squared_error: 7.6604e-04\n",
      "Epoch 35/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0017 - val_loss: 0.0013 - val_mean_squared_error: 7.6044e-04\n",
      "Epoch 36/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.3562e-04\n",
      "Epoch 37/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.4376e-04\n",
      "Epoch 38/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.6160e-04\n",
      "Epoch 39/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.5150e-04\n",
      "Epoch 40/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.3839e-04\n",
      "Epoch 41/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.5378e-04\n",
      "Epoch 42/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.7788e-04\n",
      "Epoch 43/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 7.4916e-04\n",
      "Epoch 44/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.4637e-04\n",
      "Epoch 45/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.3456e-04\n",
      "Epoch 46/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.1481e-04\n",
      "Epoch 47/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 7.2205e-04\n",
      "Epoch 48/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0016 - val_loss: 0.0011 - val_mean_squared_error: 7.5819e-04\n",
      "Epoch 49/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0016 - val_loss: 0.0011 - val_mean_squared_error: 7.7203e-04\n",
      "Epoch 50/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0016 - val_loss: 0.0011 - val_mean_squared_error: 7.5844e-04\n",
      "Epoch 51/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0016 - val_loss: 0.0011 - val_mean_squared_error: 7.3944e-04\n",
      "Epoch 52/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 7.2044e-04\n",
      "Epoch 53/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0016 - val_loss: 0.0011 - val_mean_squared_error: 7.5711e-04\n",
      "Epoch 54/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0016 - val_loss: 0.0012 - val_mean_squared_error: 8.5054e-04\n",
      "Epoch 55/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 0.0011 - val_mean_squared_error: 7.5736e-04\n",
      "Epoch 56/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 0.0011 - val_mean_squared_error: 7.6817e-04\n",
      "Epoch 57/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 7.3462e-04\n",
      "Epoch 58/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 0.0011 - val_mean_squared_error: 7.8537e-04\n",
      "Epoch 59/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 7.2241e-04\n",
      "Epoch 60/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 0.0011 - val_mean_squared_error: 8.3822e-04\n",
      "Epoch 61/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 7.3554e-04\n",
      "Epoch 62/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.8355e-04 - val_mean_squared_error: 7.1345e-04\n",
      "Epoch 63/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.7503e-04 - val_mean_squared_error: 7.0822e-04\n",
      "Epoch 64/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.8235e-04 - val_mean_squared_error: 7.2016e-04\n",
      "Epoch 65/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.8161e-04 - val_mean_squared_error: 7.2284e-04\n",
      "Epoch 66/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.6224e-04 - val_mean_squared_error: 7.0754e-04\n",
      "Epoch 67/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.9248e-04 - val_mean_squared_error: 7.4066e-04\n",
      "Epoch 68/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.7351e-04 - val_mean_squared_error: 7.2607e-04\n",
      "Epoch 69/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.8169e-04 - val_mean_squared_error: 7.3646e-04\n",
      "Epoch 70/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.6226e-04 - val_mean_squared_error: 7.2179e-04\n",
      "Epoch 71/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 7.7485e-04\n",
      "Epoch 72/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.4104e-04 - val_mean_squared_error: 7.0606e-04\n",
      "Epoch 73/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.4936e-04 - val_mean_squared_error: 7.1643e-04\n",
      "Epoch 74/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.8904e-04 - val_mean_squared_error: 7.5939e-04\n",
      "Epoch 75/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.3784e-04 - val_mean_squared_error: 7.1199e-04\n",
      "Epoch 76/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.6401e-04 - val_mean_squared_error: 7.3984e-04\n",
      "Epoch 77/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.6591e-04 - val_mean_squared_error: 7.4485e-04\n",
      "Epoch 78/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.2125e-04 - val_mean_squared_error: 7.0239e-04\n",
      "Epoch 79/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.2643e-04 - val_mean_squared_error: 7.1006e-04\n",
      "Epoch 80/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.3996e-04 - val_mean_squared_error: 7.2515e-04\n",
      "Epoch 81/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.3737e-04 - val_mean_squared_error: 7.2501e-04\n",
      "Epoch 82/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.7226e-04 - val_mean_squared_error: 7.6280e-04\n",
      "Epoch 83/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.3863e-04 - val_mean_squared_error: 7.3196e-04\n",
      "Epoch 84/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.2936e-04 - val_mean_squared_error: 7.2439e-04\n",
      "Epoch 85/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.3402e-04 - val_mean_squared_error: 7.3013e-04\n",
      "Epoch 86/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.4521e-04 - val_mean_squared_error: 7.4304e-04\n",
      "Epoch 87/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 0.0011 - val_mean_squared_error: 8.6089e-04\n",
      "Epoch 88/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.2244e-04 - val_mean_squared_error: 7.2330e-04\n",
      "Epoch 89/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.1567e-04 - val_mean_squared_error: 7.1832e-04\n",
      "Epoch 90/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.0774e-04 - val_mean_squared_error: 7.1167e-04\n",
      "Epoch 91/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.1545e-04 - val_mean_squared_error: 7.2031e-04\n",
      "Epoch 92/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.0806e-04 - val_mean_squared_error: 7.1480e-04\n",
      "Epoch 93/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.0461e-04 - val_mean_squared_error: 7.1276e-04\n",
      "Epoch 94/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.0025e-04 - val_mean_squared_error: 7.1004e-04\n",
      "Epoch 95/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.2122e-04 - val_mean_squared_error: 7.3191e-04\n",
      "Epoch 96/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.9416e-04 - val_mean_squared_error: 7.0649e-04\n",
      "Epoch 97/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.1790e-04 - val_mean_squared_error: 7.3050e-04\n",
      "Epoch 98/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.1240e-04 - val_mean_squared_error: 7.2738e-04\n",
      "Epoch 99/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.9580e-04 - val_mean_squared_error: 7.1153e-04\n",
      "Epoch 100/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 8.1878e-04\n",
      "Epoch 101/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.1207e-04 - val_mean_squared_error: 7.3007e-04\n",
      "Epoch 102/150\n",
      "3463/3463 [==============================] - 6s 2ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.2081e-04 - val_mean_squared_error: 7.3843e-04\n",
      "Epoch 103/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.4058e-04 - val_mean_squared_error: 7.6009e-04\n",
      "Epoch 104/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.0064e-04 - val_mean_squared_error: 7.2171e-04\n",
      "Epoch 105/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.9622e-04 - val_mean_squared_error: 7.1769e-04\n",
      "Epoch 106/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.9715e-04 - val_mean_squared_error: 7.2022e-04\n",
      "Epoch 107/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.2534e-04 - val_mean_squared_error: 7.4975e-04\n",
      "Epoch 108/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.8383e-04 - val_mean_squared_error: 7.0847e-04\n",
      "Epoch 109/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.9049e-04 - val_mean_squared_error: 7.1655e-04\n",
      "Epoch 110/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.8535e-04 - val_mean_squared_error: 7.1235e-04\n",
      "Epoch 111/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.1731e-04 - val_mean_squared_error: 7.4499e-04\n",
      "Epoch 112/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.1408e-04 - val_mean_squared_error: 7.4286e-04\n",
      "Epoch 113/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.7318e-04 - val_mean_squared_error: 7.0327e-04\n",
      "Epoch 114/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.9606e-04 - val_mean_squared_error: 7.2683e-04\n",
      "Epoch 115/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.2318e-04 - val_mean_squared_error: 7.5396e-04\n",
      "Epoch 116/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.8381e-04 - val_mean_squared_error: 7.1561e-04\n",
      "Epoch 117/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.7460e-04 - val_mean_squared_error: 7.0693e-04\n",
      "Epoch 118/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.2069e-04 - val_mean_squared_error: 7.5418e-04\n",
      "Epoch 119/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.0275e-04 - val_mean_squared_error: 7.3704e-04\n",
      "Epoch 120/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.9308e-04 - val_mean_squared_error: 7.2757e-04\n",
      "Epoch 121/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.0782e-04 - val_mean_squared_error: 7.4308e-04\n",
      "Epoch 122/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.3873e-04 - val_mean_squared_error: 7.7345e-04\n",
      "Epoch 123/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.7235e-04 - val_mean_squared_error: 7.0940e-04\n",
      "Epoch 124/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.6368e-04 - val_mean_squared_error: 7.0133e-04\n",
      "Epoch 125/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.5381e-04 - val_mean_squared_error: 6.9378e-04oss: 0.0018 -  - - ETA: 0s - l\n",
      "Epoch 126/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.5332e-04 - val_mean_squared_error: 6.9386e-04\n",
      "Epoch 127/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.7670e-04 - val_mean_squared_error: 7.1807e-04\n",
      "Epoch 128/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 9.1252e-04 - val_mean_squared_error: 7.5503e-04\n",
      "Epoch 129/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.7785e-04 - val_mean_squared_error: 7.2117e-04\n",
      "Epoch 130/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.9474e-04 - val_mean_squared_error: 7.3916e-04\n",
      "Epoch 131/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.5441e-04 - val_mean_squared_error: 6.9893e-04\n",
      "Epoch 132/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.5537e-04 - val_mean_squared_error: 7.0099e-04\n",
      "Epoch 133/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.6899e-04 - val_mean_squared_error: 7.1472e-04\n",
      "Epoch 134/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.7424e-04 - val_mean_squared_error: 7.2158e-04\n",
      "Epoch 135/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.9560e-04 - val_mean_squared_error: 7.4274e-04\n",
      "Epoch 136/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.6856e-04 - val_mean_squared_error: 7.1666e-04\n",
      "Epoch 137/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.7535e-04 - val_mean_squared_error: 7.2323e-04\n",
      "Epoch 138/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 9.1868e-04 - val_mean_squared_error: 7.6785e-04\n",
      "Epoch 139/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.6846e-04 - val_mean_squared_error: 7.1761e-04\n",
      "Epoch 140/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.6434e-04 - val_mean_squared_error: 7.1483e-04\n",
      "Epoch 141/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.5322e-04 - val_mean_squared_error: 7.0411e-04\n",
      "Epoch 142/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.4900e-04 - val_mean_squared_error: 7.0013e-04\n",
      "Epoch 143/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.4271e-04 - val_mean_squared_error: 6.9456e-04\n",
      "Epoch 144/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.4875e-04 - val_mean_squared_error: 7.0147e-04\n",
      "Epoch 145/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.7244e-04 - val_mean_squared_error: 7.2525e-04\n",
      "Epoch 146/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.9470e-04 - val_mean_squared_error: 7.4688e-04\n",
      "Epoch 147/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.7905e-04 - val_mean_squared_error: 7.3267e-04\n",
      "Epoch 148/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.6181e-04 - val_mean_squared_error: 7.1638e-04\n",
      "Epoch 149/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.7527e-04 - val_mean_squared_error: 7.2974e-04\n",
      "Epoch 150/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.5860e-04 - val_mean_squared_error: 7.1395e-04\n",
      "Epoch 1/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0227 - mean_squared_error: 0.0223 - val_loss: 0.0028 - val_mean_squared_error: 0.0025\n",
      "Epoch 2/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0027 - val_loss: 0.0014 - val_mean_squared_error: 0.0011\n",
      "Epoch 3/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0020 - val_loss: 0.0012 - val_mean_squared_error: 8.8675e-04\n",
      "Epoch 4/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0019 - val_loss: 0.0012 - val_mean_squared_error: 9.0292e-04\n",
      "Epoch 5/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0018 - val_loss: 0.0012 - val_mean_squared_error: 9.0411e-04\n",
      "Epoch 6/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 8.2790e-04\n",
      "Epoch 7/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 9.1711e-04\n",
      "Epoch 8/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 8.1517e-04\n",
      "Epoch 9/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 8.1809e-04\n",
      "Epoch 10/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0017 - val_loss: 0.0010 - val_mean_squared_error: 7.6069e-04\n",
      "Epoch 11/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 8.0240e-04\n",
      "Epoch 12/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0017 - val_loss: 0.0010 - val_mean_squared_error: 7.8250e-04\n",
      "Epoch 13/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 7.6472e-04\n",
      "Epoch 14/150\n",
      "3463/3463 [==============================] - 6s 2ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 7.6709e-04\n",
      "Epoch 15/150\n",
      "3463/3463 [==============================] - 6s 2ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 7.6962e-04\n",
      "Epoch 16/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.9440e-04 - val_mean_squared_error: 7.4724e-04\n",
      "Epoch 17/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.9552e-04 - val_mean_squared_error: 7.5065e-04\n",
      "Epoch 18/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.8640e-04 - val_mean_squared_error: 7.4359e-04\n",
      "Epoch 19/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 7.6653e-04\n",
      "Epoch 20/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.8785e-04 - val_mean_squared_error: 7.4942e-04\n",
      "Epoch 21/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 7.7625e-04\n",
      "Epoch 22/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.8178e-04 - val_mean_squared_error: 7.4744e-04\n",
      "Epoch 23/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.7282e-04 - val_mean_squared_error: 7.4026e-04\n",
      "Epoch 24/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0016 - val_loss: 9.7482e-04 - val_mean_squared_error: 7.4414e-04.0019 - mean_squared_e - ETA: 0s - los\n",
      "Epoch 25/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.6810e-04 - val_mean_squared_error: 7.3935e-04\n",
      "Epoch 26/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.6258e-04 - val_mean_squared_error: 7.3573e-04\n",
      "Epoch 27/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.5539e-04 - val_mean_squared_error: 7.3046e-04\n",
      "Epoch 28/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.7673e-04 - val_mean_squared_error: 7.5358e-04\n",
      "Epoch 29/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 8.0548e-04\n",
      "Epoch 30/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 7.8383e-04\n",
      "Epoch 31/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.6390e-04 - val_mean_squared_error: 7.4618e-04\n",
      "Epoch 32/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.7341e-04 - val_mean_squared_error: 7.5750e-04\n",
      "Epoch 33/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.8484e-04 - val_mean_squared_error: 7.7068e-04\n",
      "Epoch 34/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.4079e-04 - val_mean_squared_error: 7.2824e-04\n",
      "Epoch 35/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.5751e-04 - val_mean_squared_error: 7.4669e-04\n",
      "Epoch 36/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.2926e-04 - val_mean_squared_error: 7.1998e-04\n",
      "Epoch 37/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.5299e-04 - val_mean_squared_error: 7.4533e-04\n",
      "Epoch 38/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.7726e-04 - val_mean_squared_error: 7.7114e-04\n",
      "Epoch 39/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.2289e-04 - val_mean_squared_error: 7.1844e-04\n",
      "Epoch 40/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 8.0504e-04\n",
      "Epoch 41/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.2860e-04 - val_mean_squared_error: 7.2723e-04\n",
      "Epoch 42/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.3894e-04 - val_mean_squared_error: 7.3909e-04.0018 - mean_squared_error: 0. - ETA: 0s - loss:\n",
      "Epoch 43/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 8.2806e-04oss: 0.0018 - mean_squared_error\n",
      "Epoch 44/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.7011e-04 - val_mean_squared_error: 7.7320e-04\n",
      "Epoch 45/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.8048e-04 - val_mean_squared_error: 7.8501e-04\n",
      "Epoch 46/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.0682e-04 - val_mean_squared_error: 7.1291e-04_error: 0.00 - ETA: 0s -\n",
      "Epoch 47/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.1473e-04 - val_mean_squared_error: 7.2202e-04\n",
      "Epoch 48/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.0586e-04 - val_mean_squared_error: 7.1471e-04\n",
      "Epoch 49/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.0410e-04 - val_mean_squared_error: 7.1430e-04\n",
      "Epoch 50/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.1134e-04 - val_mean_squared_error: 7.2289e-04\n",
      "Epoch 51/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.1999e-04 - val_mean_squared_error: 7.3286e-04\n",
      "Epoch 52/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.1182e-04 - val_mean_squared_error: 7.2603e-04\n",
      "Epoch 53/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.2703e-04 - val_mean_squared_error: 7.4259e-04\n",
      "Epoch 54/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.9075e-04 - val_mean_squared_error: 7.0759e-04s:\n",
      "Epoch 55/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.5364e-04 - val_mean_squared_error: 7.7163e-04\n",
      "Epoch 56/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.1529e-04 - val_mean_squared_error: 7.3465e-04\n",
      "Epoch 57/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.0907e-04 - val_mean_squared_error: 7.2955e-04\n",
      "Epoch 58/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.4034e-04 - val_mean_squared_error: 7.6201e-04\n",
      "Epoch 59/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.0182e-04 - val_mean_squared_error: 7.2493e-04\n",
      "Epoch 60/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.2990e-04 - val_mean_squared_error: 7.5400e-04\n",
      "Epoch 61/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.8728e-04 - val_mean_squared_error: 7.1281e-04\n",
      "Epoch 62/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.0090e-04 - val_mean_squared_error: 7.2752e-04\n",
      "Epoch 63/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.8606e-04 - val_mean_squared_error: 7.1381e-04\n",
      "Epoch 64/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.0237e-04 - val_mean_squared_error: 7.3124e-04\n",
      "Epoch 65/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.0622e-04 - val_mean_squared_error: 7.3616e-04\n",
      "Epoch 66/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.1178e-04 - val_mean_squared_error: 7.4289e-048 - mean_squared_error: 0.00\n",
      "Epoch 67/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.5289e-04 - val_mean_squared_error: 7.8521e-04\n",
      "Epoch 68/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.6988e-04 - val_mean_squared_error: 7.0318e-04\n",
      "Epoch 69/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.9434e-04 - val_mean_squared_error: 7.2870e-04\n",
      "Epoch 70/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.8874e-04 - val_mean_squared_error: 7.2421e-04\n",
      "Epoch 71/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 9.8697e-04 - val_mean_squared_error: 8.2346e-04\n",
      "Epoch 72/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 9.2226e-04 - val_mean_squared_error: 7.5976e-04\n",
      "Epoch 73/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0016 - val_loss: 8.9098e-04 - val_mean_squared_error: 7.2945e-04\n",
      "Epoch 74/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.8660e-04 - val_mean_squared_error: 7.2608e-04\n",
      "Epoch 75/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.8284e-04 - val_mean_squared_error: 7.2339e-04\n",
      "Epoch 76/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.6787e-04 - val_mean_squared_error: 7.0955e-04\n",
      "Epoch 77/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 9.5145e-04 - val_mean_squared_error: 7.9408e-04\n",
      "Epoch 78/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.7473e-04 - val_mean_squared_error: 7.1823e-04\n",
      "Epoch 79/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.6862e-04 - val_mean_squared_error: 7.1321e-04\n",
      "Epoch 80/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.7509e-04 - val_mean_squared_error: 7.2041e-04\n",
      "Epoch 81/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.8853e-04 - val_mean_squared_error: 7.3483e-04\n",
      "Epoch 82/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 9.1236e-04 - val_mean_squared_error: 7.5945e-04\n",
      "Epoch 83/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.8176e-04 - val_mean_squared_error: 7.2980e-04\n",
      "Epoch 84/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.6250e-04 - val_mean_squared_error: 7.1153e-04\n",
      "Epoch 85/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.9550e-04 - val_mean_squared_error: 7.4518e-04\n",
      "Epoch 86/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.5163e-04 - val_mean_squared_error: 7.0210e-04\n",
      "Epoch 87/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.8982e-04 - val_mean_squared_error: 7.4139e-04\n",
      "Epoch 88/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.9848e-04 - val_mean_squared_error: 7.5080e-04\n",
      "Epoch 89/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.8271e-04 - val_mean_squared_error: 7.3575e-04\n",
      "Epoch 90/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.5868e-04 - val_mean_squared_error: 7.1252e-04\n",
      "Epoch 91/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.7453e-04 - val_mean_squared_error: 7.2914e-04\n",
      "Epoch 92/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.5088e-04 - val_mean_squared_error: 7.0635e-04\n",
      "Epoch 93/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.7873e-04 - val_mean_squared_error: 7.3508e-04\n",
      "Epoch 94/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.6188e-04 - val_mean_squared_error: 7.1914e-04\n",
      "Epoch 95/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.4433e-04 - val_mean_squared_error: 7.0234e-04s: 0.0017 - mean_squared_error: 0. - ETA: 1s - los - ETA: 0s - loss: 0.0017 - mean_squared\n",
      "Epoch 96/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 9.1807e-04 - val_mean_squared_error: 7.7693e-04\n",
      "Epoch 97/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.4980e-04 - val_mean_squared_error: 7.0933e-04or: 0. - ETA: 2s - loss: 0.0017 - mean_squared_e - ETA: 1s - loss: 0 - ETA: 1s - loss:\n",
      "Epoch 98/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 9.0334e-04 - val_mean_squared_error: 7.6352e-04\n",
      "Epoch 99/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.5665e-04 - val_mean_squared_error: 7.1758e-04\n",
      "Epoch 100/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.4327e-04 - val_mean_squared_error: 7.0519e-04\n",
      "Epoch 101/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.8940e-04 - val_mean_squared_error: 7.5200e-04\n",
      "Epoch 102/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.6843e-04 - val_mean_squared_error: 7.3188e-04\n",
      "Epoch 103/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.4770e-04 - val_mean_squared_error: 7.1173e-04\n",
      "Epoch 104/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.7163e-04 - val_mean_squared_error: 7.3629e-04\n",
      "Epoch 105/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.6354e-04 - val_mean_squared_error: 7.2892e-04\n",
      "Epoch 106/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.4170e-04 - val_mean_squared_error: 7.0796e-04\n",
      "Epoch 107/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.4630e-04 - val_mean_squared_error: 7.1327e-04\n",
      "Epoch 108/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.6447e-04 - val_mean_squared_error: 7.3209e-04\n",
      "Epoch 109/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.3230e-04 - val_mean_squared_error: 7.0077e-04\n",
      "Epoch 110/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.3583e-04 - val_mean_squared_error: 7.0482e-04\n",
      "Epoch 111/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.7598e-04 - val_mean_squared_error: 7.4587e-04\n",
      "Epoch 112/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.6542e-04 - val_mean_squared_error: 7.3599e-04\n",
      "Epoch 113/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 9.1691e-04 - val_mean_squared_error: 7.8810e-04\n",
      "Epoch 114/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.6657e-04 - val_mean_squared_error: 7.3838e-04\n",
      "Epoch 115/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.6051e-04 - val_mean_squared_error: 7.3306e-04\n",
      "Epoch 116/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.4914e-04 - val_mean_squared_error: 7.2232e-04\n",
      "Epoch 117/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.9219e-04 - val_mean_squared_error: 7.6593e-04\n",
      "Epoch 118/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.3354e-04 - val_mean_squared_error: 7.0793e-04\n",
      "Epoch 119/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.3613e-04 - val_mean_squared_error: 7.1115e-04\n",
      "Epoch 120/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 9.3113e-04 - val_mean_squared_error: 8.0684e-04\n",
      "Epoch 121/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.4270e-04 - val_mean_squared_error: 7.1900e-04\n",
      "Epoch 122/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.5887e-04 - val_mean_squared_error: 7.3577e-04\n",
      "Epoch 123/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.1919e-04 - val_mean_squared_error: 6.9680e-04\n",
      "Epoch 124/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.3756e-04 - val_mean_squared_error: 7.1568e-04\n",
      "Epoch 125/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 9.0334e-04 - val_mean_squared_error: 7.8218e-04\n",
      "Epoch 126/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.3313e-04 - val_mean_squared_error: 7.1262e-04\n",
      "Epoch 127/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.3942e-04 - val_mean_squared_error: 7.1932e-04\n",
      "Epoch 128/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.2667e-04 - val_mean_squared_error: 7.0733e-04\n",
      "Epoch 129/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.2850e-04 - val_mean_squared_error: 7.0963e-04\n",
      "Epoch 130/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.3752e-04 - val_mean_squared_error: 7.1933e-04\n",
      "Epoch 131/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.3666e-04 - val_mean_squared_error: 7.1900e-04\n",
      "Epoch 132/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.2144e-04 - val_mean_squared_error: 7.0424e-04\n",
      "Epoch 133/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.2157e-04 - val_mean_squared_error: 7.0508e-04\n",
      "Epoch 134/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.3721e-04 - val_mean_squared_error: 7.2115e-04\n",
      "Epoch 135/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.1764e-04 - val_mean_squared_error: 7.0238e-04\n",
      "Epoch 136/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.1211e-04 - val_mean_squared_error: 6.9720e-04\n",
      "Epoch 137/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.1537e-04 - val_mean_squared_error: 7.0101e-04\n",
      "Epoch 138/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.1639e-04 - val_mean_squared_error: 7.0265e-04\n",
      "Epoch 139/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.3162e-04 - val_mean_squared_error: 7.1824e-04\n",
      "Epoch 140/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.3636e-04 - val_mean_squared_error: 7.2364e-04\n",
      "Epoch 141/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.3713e-04 - val_mean_squared_error: 7.2488e-04\n",
      "Epoch 142/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.8345e-04 - val_mean_squared_error: 7.7192e-04\n",
      "Epoch 143/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.6562e-04 - val_mean_squared_error: 7.5437e-04\n",
      "Epoch 144/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.4999e-04 - val_mean_squared_error: 7.3929e-04\n",
      "Epoch 145/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.2388e-04 - val_mean_squared_error: 7.1378e-04\n",
      "Epoch 146/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.6486e-04 - val_mean_squared_error: 7.5519e-04\n",
      "Epoch 147/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.3429e-04 - val_mean_squared_error: 7.2499e-04\n",
      "Epoch 148/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.0500e-04 - val_mean_squared_error: 6.9618e-04\n",
      "Epoch 149/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.0528e-04 - val_mean_squared_error: 6.9682e-04\n",
      "Epoch 150/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.6742e-04 - val_mean_squared_error: 7.5940e-04\n",
      "Epoch 1/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 2/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0032 - mean_squared_error: 0.0031 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 3/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0010 - val_mean_squared_error: 9.6829e-04\n",
      "Epoch 4/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 9.1904e-04 - val_mean_squared_error: 8.8634e-04\n",
      "Epoch 5/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0018 - val_loss: 8.5852e-04 - val_mean_squared_error: 8.2602e-04\n",
      "Epoch 6/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 8.3515e-04 - val_mean_squared_error: 8.0278e-04\n",
      "Epoch 7/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 8.2176e-04 - val_mean_squared_error: 7.8933e-04\n",
      "Epoch 8/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0018 - mean_squared_error: 0.0017 - val_loss: 8.3091e-04 - val_mean_squared_error: 7.9841e-04\n",
      "Epoch 9/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 8.1845e-04 - val_mean_squared_error: 7.8589e-04\n",
      "Epoch 10/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 8.1055e-04 - val_mean_squared_error: 7.7787e-04\n",
      "Epoch 11/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 7.8913e-04 - val_mean_squared_error: 7.5643e-04\n",
      "Epoch 12/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 8.3270e-04 - val_mean_squared_error: 7.9995e-04\n",
      "Epoch 13/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 7.9537e-04 - val_mean_squared_error: 7.6260e-04\n",
      "Epoch 14/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 8.2642e-04 - val_mean_squared_error: 7.9365e-04\n",
      "Epoch 15/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 8.2963e-04 - val_mean_squared_error: 7.9688e-04\n",
      "Epoch 16/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 9.4459e-04 - val_mean_squared_error: 9.1185e-04\n",
      "Epoch 17/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 8.6382e-04 - val_mean_squared_error: 8.3106e-04\n",
      "Epoch 18/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 8.1541e-04 - val_mean_squared_error: 7.8269e-04\n",
      "Epoch 19/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 8.0363e-04 - val_mean_squared_error: 7.7090e-04\n",
      "Epoch 20/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 7.7478e-04 - val_mean_squared_error: 7.4211e-04\n",
      "Epoch 21/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 7.5358e-04 - val_mean_squared_error: 7.2091e-04\n",
      "Epoch 22/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 7.7451e-04 - val_mean_squared_error: 7.4189e-04\n",
      "Epoch 23/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 7.7721e-04 - val_mean_squared_error: 7.4459e-04\n",
      "Epoch 24/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.3785e-04 - val_mean_squared_error: 8.0527e-04\n",
      "Epoch 25/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 8.0348e-04 - val_mean_squared_error: 7.7092e-04\n",
      "Epoch 26/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 7.5473e-04 - val_mean_squared_error: 7.2218e-04\n",
      "Epoch 27/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 7.8548e-04 - val_mean_squared_error: 7.5294e-04\n",
      "Epoch 28/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 7.4094e-04 - val_mean_squared_error: 7.0838e-04\n",
      "Epoch 29/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.1954e-04 - val_mean_squared_error: 7.8702e-04\n",
      "Epoch 30/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.4105e-04 - val_mean_squared_error: 8.0856e-04\n",
      "Epoch 31/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 8.3222e-04 - val_mean_squared_error: 7.9976e-04\n",
      "Epoch 32/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 7.9368e-04 - val_mean_squared_error: 7.6126e-04\n",
      "Epoch 33/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 7.9577e-04 - val_mean_squared_error: 7.6339e-04\n",
      "Epoch 34/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 7.4568e-04 - val_mean_squared_error: 7.1331e-04\n",
      "Epoch 35/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 7.7027e-04 - val_mean_squared_error: 7.3793e-04\n",
      "Epoch 36/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 7.7078e-04 - val_mean_squared_error: 7.3844e-04\n",
      "Epoch 37/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 7.8146e-04 - val_mean_squared_error: 7.4920e-04\n",
      "Epoch 38/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 7.5343e-04 - val_mean_squared_error: 7.2118e-04\n",
      "Epoch 39/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6236e-04 - val_mean_squared_error: 7.3011e-04\n",
      "Epoch 40/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 7.8050e-04 - val_mean_squared_error: 7.4832e-04\n",
      "Epoch 41/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 7.6463e-04 - val_mean_squared_error: 7.3248e-04\n",
      "Epoch 42/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6189e-04 - val_mean_squared_error: 7.2977e-04\n",
      "Epoch 43/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6606e-04 - val_mean_squared_error: 7.3397e-04\n",
      "Epoch 44/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4532e-04 - val_mean_squared_error: 7.1326e-04\n",
      "Epoch 45/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5416e-04 - val_mean_squared_error: 7.2213e-04\n",
      "Epoch 46/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 7.5636e-04 - val_mean_squared_error: 7.2436e-04\n",
      "Epoch 47/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6596e-04 - val_mean_squared_error: 7.3401e-04\n",
      "Epoch 48/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5223e-04 - val_mean_squared_error: 7.2031e-04\n",
      "Epoch 49/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.8484e-04 - val_mean_squared_error: 7.5295e-04\n",
      "Epoch 50/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.7610e-04 - val_mean_squared_error: 7.4426e-04\n",
      "Epoch 51/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5429e-04 - val_mean_squared_error: 7.2249e-04\n",
      "Epoch 52/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.7054e-04 - val_mean_squared_error: 7.3881e-04\n",
      "Epoch 53/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5246e-04 - val_mean_squared_error: 7.2075e-04\n",
      "Epoch 54/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5026e-04 - val_mean_squared_error: 7.1862e-04\n",
      "Epoch 55/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6916e-04 - val_mean_squared_error: 7.3756e-04\n",
      "Epoch 56/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.7155e-04 - val_mean_squared_error: 7.4002e-04\n",
      "Epoch 57/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4576e-04 - val_mean_squared_error: 7.1425e-04\n",
      "Epoch 58/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.7848e-04 - val_mean_squared_error: 7.4704e-04\n",
      "Epoch 59/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4362e-04 - val_mean_squared_error: 7.1225e-04\n",
      "Epoch 60/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6424e-04 - val_mean_squared_error: 7.3292e-04\n",
      "Epoch 61/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6661e-04 - val_mean_squared_error: 7.3534e-04\n",
      "Epoch 62/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4391e-04 - val_mean_squared_error: 7.1271e-04\n",
      "Epoch 63/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5826e-04 - val_mean_squared_error: 7.2713e-04\n",
      "Epoch 64/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.7634e-04 - val_mean_squared_error: 7.4527e-04\n",
      "Epoch 65/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 8.0963e-04 - val_mean_squared_error: 7.7862e-04\n",
      "Epoch 66/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5010e-04 - val_mean_squared_error: 7.1916e-04\n",
      "Epoch 67/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4327e-04 - val_mean_squared_error: 7.1239e-04\n",
      "Epoch 68/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.7154e-04 - val_mean_squared_error: 7.4074e-04\n",
      "Epoch 69/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.7198e-04 - val_mean_squared_error: 7.4125e-04\n",
      "Epoch 70/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.8616e-04 - val_mean_squared_error: 7.5547e-04\n",
      "Epoch 71/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6495e-04 - val_mean_squared_error: 7.3429e-04\n",
      "Epoch 72/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4835e-04 - val_mean_squared_error: 7.1773e-04\n",
      "Epoch 73/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4964e-04 - val_mean_squared_error: 7.1908e-04\n",
      "Epoch 74/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 8.1375e-04 - val_mean_squared_error: 7.8322e-04\n",
      "Epoch 75/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6709e-04 - val_mean_squared_error: 7.3659e-04\n",
      "Epoch 76/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5297e-04 - val_mean_squared_error: 7.2250e-04\n",
      "Epoch 77/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.7153e-04 - val_mean_squared_error: 7.4110e-04\n",
      "Epoch 78/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.9833e-04 - val_mean_squared_error: 7.6793e-04\n",
      "Epoch 79/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5724e-04 - val_mean_squared_error: 7.2690e-04\n",
      "Epoch 80/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4908e-04 - val_mean_squared_error: 7.1877e-04\n",
      "Epoch 81/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3914e-04 - val_mean_squared_error: 7.0883e-04\n",
      "Epoch 82/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3411e-04 - val_mean_squared_error: 7.0384e-04\n",
      "Epoch 83/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4749e-04 - val_mean_squared_error: 7.1729e-04\n",
      "Epoch 84/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5043e-04 - val_mean_squared_error: 7.2025e-04\n",
      "Epoch 85/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.8813e-04 - val_mean_squared_error: 7.5801e-04\n",
      "Epoch 86/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6041e-04 - val_mean_squared_error: 7.3030e-04\n",
      "Epoch 87/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6919e-04 - val_mean_squared_error: 7.3912e-04\n",
      "Epoch 88/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3976e-04 - val_mean_squared_error: 7.0969e-04\n",
      "Epoch 89/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3440e-04 - val_mean_squared_error: 7.0439e-04\n",
      "Epoch 90/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3511e-04 - val_mean_squared_error: 7.0512e-04\n",
      "Epoch 91/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5998e-04 - val_mean_squared_error: 7.2999e-04\n",
      "Epoch 92/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6552e-04 - val_mean_squared_error: 7.3558e-04\n",
      "Epoch 93/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3426e-04 - val_mean_squared_error: 7.0436e-04\n",
      "Epoch 94/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6752e-04 - val_mean_squared_error: 7.3765e-04\n",
      "Epoch 95/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4860e-04 - val_mean_squared_error: 7.1875e-04\n",
      "Epoch 96/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6721e-04 - val_mean_squared_error: 7.3739e-04\n",
      "Epoch 97/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3203e-04 - val_mean_squared_error: 7.0223e-04\n",
      "Epoch 98/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3851e-04 - val_mean_squared_error: 7.0873e-04\n",
      "Epoch 99/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4990e-04 - val_mean_squared_error: 7.2015e-04\n",
      "Epoch 100/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4665e-04 - val_mean_squared_error: 7.1692e-04\n",
      "Epoch 101/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3677e-04 - val_mean_squared_error: 7.0706e-04\n",
      "Epoch 102/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5426e-04 - val_mean_squared_error: 7.2459e-04 - ETA: 1s - loss: 0.0 - ETA: 0s - los\n",
      "Epoch 103/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5269e-04 - val_mean_squared_error: 7.2304e-04\n",
      "Epoch 104/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4462e-04 - val_mean_squared_error: 7.1500e-04\n",
      "Epoch 105/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6467e-04 - val_mean_squared_error: 7.3507e-04\n",
      "Epoch 106/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3008e-04 - val_mean_squared_error: 7.0050e-04\n",
      "Epoch 107/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.9204e-04 - val_mean_squared_error: 7.6250e-04\n",
      "Epoch 108/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5076e-04 - val_mean_squared_error: 7.2123e-04\n",
      "Epoch 109/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3136e-04 - val_mean_squared_error: 7.0187e-04\n",
      "Epoch 110/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6780e-04 - val_mean_squared_error: 7.3832e-04\n",
      "Epoch 111/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.9698e-04 - val_mean_squared_error: 7.6754e-04\n",
      "Epoch 112/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5930e-04 - val_mean_squared_error: 7.2988e-04\n",
      "Epoch 113/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3784e-04 - val_mean_squared_error: 7.0843e-04\n",
      "Epoch 114/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5128e-04 - val_mean_squared_error: 7.2189e-04\n",
      "Epoch 115/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 8.5217e-04 - val_mean_squared_error: 8.2279e-04\n",
      "Epoch 116/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.8550e-04 - val_mean_squared_error: 7.5616e-04\n",
      "Epoch 117/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3994e-04 - val_mean_squared_error: 7.1061e-04\n",
      "Epoch 118/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.8078e-04 - val_mean_squared_error: 7.5150e-04\n",
      "Epoch 119/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4204e-04 - val_mean_squared_error: 7.1276e-04\n",
      "Epoch 120/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.2245e-04 - val_mean_squared_error: 6.9319e-04\n",
      "Epoch 121/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5124e-04 - val_mean_squared_error: 7.2202e-04\n",
      "Epoch 122/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4764e-04 - val_mean_squared_error: 7.1844e-04\n",
      "Epoch 123/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3670e-04 - val_mean_squared_error: 7.0753e-04\n",
      "Epoch 124/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6926e-04 - val_mean_squared_error: 7.4011e-04\n",
      "Epoch 125/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4951e-04 - val_mean_squared_error: 7.2040e-04\n",
      "Epoch 126/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3722e-04 - val_mean_squared_error: 7.0809e-04\n",
      "Epoch 127/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3799e-04 - val_mean_squared_error: 7.0892e-04\n",
      "Epoch 128/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6259e-04 - val_mean_squared_error: 7.3354e-04\n",
      "Epoch 129/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4275e-04 - val_mean_squared_error: 7.1371e-04\n",
      "Epoch 130/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6937e-04 - val_mean_squared_error: 7.4037e-04\n",
      "Epoch 131/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.8133e-04 - val_mean_squared_error: 7.5233e-04\n",
      "Epoch 132/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4369e-04 - val_mean_squared_error: 7.1470e-04\n",
      "Epoch 133/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5164e-04 - val_mean_squared_error: 7.2268e-04\n",
      "Epoch 134/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5605e-04 - val_mean_squared_error: 7.2713e-04\n",
      "Epoch 135/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5373e-04 - val_mean_squared_error: 7.2482e-04\n",
      "Epoch 136/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6707e-04 - val_mean_squared_error: 7.3816e-04\n",
      "Epoch 137/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 9.2548e-04 - val_mean_squared_error: 8.9659e-04\n",
      "Epoch 138/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4247e-04 - val_mean_squared_error: 7.1359e-04\n",
      "Epoch 139/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4606e-04 - val_mean_squared_error: 7.1721e-04\n",
      "Epoch 140/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.9960e-04 - val_mean_squared_error: 7.7072e-04\n",
      "Epoch 141/150\n",
      "3463/3463 [==============================] - 21s 6ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3263e-04 - val_mean_squared_error: 7.0378e-04\n",
      "Epoch 142/150\n",
      "3463/3463 [==============================] - 10s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.4668e-04 - val_mean_squared_error: 7.1782e-04\n",
      "Epoch 143/150\n",
      "3463/3463 [==============================] - 8s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.6725e-04 - val_mean_squared_error: 7.3841e-04\n",
      "Epoch 144/150\n",
      "3463/3463 [==============================] - 7s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.2300e-04 - val_mean_squared_error: 6.9417e-04\n",
      "Epoch 145/150\n",
      "3463/3463 [==============================] - 7s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.7621e-04 - val_mean_squared_error: 7.4740e-04\n",
      "Epoch 146/150\n",
      "3463/3463 [==============================] - 7s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.5426e-04 - val_mean_squared_error: 7.2547e-04\n",
      "Epoch 147/150\n",
      "3463/3463 [==============================] - 7s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.2040e-04 - val_mean_squared_error: 6.9162e-04\n",
      "Epoch 148/150\n",
      "3463/3463 [==============================] - 7s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3995e-04 - val_mean_squared_error: 7.1119e-04\n",
      "Epoch 149/150\n",
      "3463/3463 [==============================] - 7s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.3338e-04 - val_mean_squared_error: 7.0464e-04\n",
      "Epoch 150/150\n",
      "3463/3463 [==============================] - 7s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 7.2604e-04 - val_mean_squared_error: 6.9734e-04\n",
      "Best Hyperparameter Values:\n",
      "reg_alpha: 1e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_hyperparams = None\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "\n",
    "def plot_training_progress(history, df_train, df_val):\n",
    "    history = pd.DataFrame(history.history)\n",
    "\n",
    "    pnl_train_bs = (calculate_pnl(df_train, df_train['delta_bs'])**2).mean()\n",
    "    pnl_val_bs = (calculate_pnl(df_val, df_val['delta_bs'])**2).mean()\n",
    "\n",
    "    hmse_train = history['mean_squared_error'] * pnl_train_bs\n",
    "    hmse_val = history['val_mean_squared_error'] * pnl_val_bs\n",
    "\n",
    "    x_min_train_hmse = hmse_train.idxmin()\n",
    "    x_min_val_hmse = hmse_val.idxmin()\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(ncols=2, nrows=1, sharey=True, figsize=(12, 4))\n",
    "    ax1.plot(hmse_train, label='Network HMSE')\n",
    "    ax1.axhline(pnl_train_bs, xmin=0, xmax=1, c='r', label='Black-Scholes HMSE')\n",
    "    ax1.axvline(x_min_train_hmse, ymin=0, ymax=1,  linestyle='dashed', label='Minimum loss')\n",
    "    ax1.legend()\n",
    "    ax2.plot(hmse_val, label='Network HMSE')\n",
    "    ax2.axhline(pnl_val_bs, xmin=0, xmax=1, c='r', label='Black-Scholes HMSE')\n",
    "    ax2.axvline(x_min_val_hmse, ymin=0, ymax=1,  linestyle='dashed', label='Minimum loss')\n",
    "    ax2.legend()\n",
    "    plt.ylim(0., 0.01)\n",
    "    ax1.set_xlim(20, history['mean_squared_error'].shape[0])\n",
    "    ax2.set_xlim(20, history['mean_squared_error'].shape[0])\n",
    "    plt.show()\n",
    "\n",
    "def train_neural_network(df_train, df_val, used_features, hypers):\n",
    "    global best_hyperparams, best_val_loss, best_model\n",
    "\n",
    "    net = HedgeNet()\n",
    "    if hypers['outact'] == 'normcdf':\n",
    "        hypers['outact'] = normcdf\n",
    "        \n",
    "    net.build_model(\n",
    "        (len(used_features),),\n",
    "        nodes_per_layer=hypers['nodes_per_layer'],\n",
    "        metrics=['mean_squared_error'],\n",
    "        reg_alpha=hypers['reg_alpha'],\n",
    "        lr=hypers['lr'],\n",
    "        outact=hypers['outact']\n",
    "    )\n",
    "    history = net.fit(\n",
    "        df_train, df_val,\n",
    "        used_features=used_features,\n",
    "        V1='V1_n',\n",
    "        epochs=hypers['epochs']\n",
    "    )\n",
    "\n",
    "    val_loss = history.history['val_mean_squared_error'][-1]\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = net.model\n",
    "        best_hyperparams = hypers.copy()\n",
    "\n",
    "    clear_session()\n",
    "    return history  # Return the history object\n",
    "\n",
    "def test_selected_model(df_test, used_features, best_hyperparams):\n",
    "    net = HedgeNet()\n",
    "    net.build_model(\n",
    "        (len(used_features),),\n",
    "        nodes_per_layer=best_hyperparams['nodes_per_layer'],\n",
    "        metrics=['mean_squared_error'],\n",
    "        reg_alpha=best_hyperparams['reg_alpha'],\n",
    "        lr=best_hyperparams['lr'],\n",
    "        outact=best_hyperparams['outact']\n",
    "    )\n",
    "    net.model.set_weights(best_model.get_weights())  # Set the best model's weights\n",
    "\n",
    "    delta_nn = net.calculate_delta(df_test, used_features)\n",
    "    clear_session()\n",
    "    return delta_nn\n",
    "\n",
    "# Rest of the code remains the same\n",
    "hypers = {\n",
    "    'nodes_per_layer': (30, 30),\n",
    "    'reg_alpha': 1e-4,\n",
    "    'lr': 1e-4,\n",
    "    'epochs': 150,\n",
    "    'outact': 'relu'\n",
    "}\n",
    "\n",
    "lab_tune = 'reg_alpha'\n",
    "set_of_values = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "\n",
    "# Create a dictionary to store the best hyperparameter values for each parameter\n",
    "best_hyperparameter_value = {}\n",
    "# Create a dictionary to store the MSE history for each alpha\n",
    "mse_history = {}\n",
    "\n",
    "def plot_training_progress(history, df_train, df_val, alphas):\n",
    "    \"\"\"\n",
    "    Plot the training progress of the neural network for different alpha values.\n",
    "\n",
    "    :param history: Dictionary containing the training history for different alpha values.\n",
    "    :param df_train: DataFrame of the training data.\n",
    "    :param df_val: DataFrame of the validation data.\n",
    "    :param alphas: List of alpha values for which training progress will be plotted.\n",
    "    \"\"\"\n",
    "    # Create a new figure and axis for the plot\n",
    "    f, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Loop over the provided alpha values\n",
    "    for alpha in alphas:\n",
    "        # Get the mean squared error for training and validation at each epoch for the current alpha\n",
    "        mse_train = history[alpha]['mean_squared_error']\n",
    "        mse_val = history[alpha]['val_mean_squared_error']\n",
    "\n",
    "        # Plot the training and validation MSE curves for the current alpha\n",
    "        ax.plot(mse_train, label=f'Training MSE (Alpha={alpha})')\n",
    "        ax.plot(mse_val, label=f'Validation MSE (Alpha={alpha})')\n",
    "\n",
    "    # Set the labels for x and y axes\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Mean Squared Error (MSE)')\n",
    "\n",
    "    # Add a legend to the plot\n",
    "    ax.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Loop over the values to tune the hyperparameter\n",
    "for value in set_of_values:\n",
    "    hypers[lab_tune] = value\n",
    "    # For each value, we train the network once.\n",
    "    history = train_neural_network(df_train, df_val, used_features, hypers)\n",
    "    mse_history[value] = history.history\n",
    "\n",
    "    # Each train is tested once on a single Monte Carlo set.\n",
    "    df_test = standardize_feature([df_test], scaler, original_features)\n",
    "\n",
    "    delta_nn = test_selected_model(df_test, used_features, best_hyperparams)\n",
    "\n",
    "    # We calculate NN pnl and BS pnl.\n",
    "    pnl_nn = calculate_pnl(df_test, delta_nn)\n",
    "    pnl_bs = calculate_pnl(df_test, df_test['delta_bs'])\n",
    "\n",
    "    df_metrics = pd.DataFrame({'BS': [(pnl_bs**2).mean()],\n",
    "                               'NN': [(pnl_nn**2).mean()]})\n",
    "\n",
    "    # Save the best hyperparameter value for this parameter\n",
    "    best_hyperparameter_value[lab_tune] = best_hyperparams[lab_tune]\n",
    "\n",
    "\n",
    "# Print the best hyperparameter values for each parameter\n",
    "print(\"Best Hyperparameter Values:\")\n",
    "for key, value in best_hyperparameter_value.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "plot_training_progress(mse_history, df_train, df_val, set_of_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Hyperparameter Tuning Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_alpha': 1e-06}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparameter_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_summary = pd.DataFrame(columns=['BS'] + [f'para={v:.0e}' for v in set_of_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used: ['M0_t', 'tau0_implvol0_t', 'cp_int']\n",
      "Set of Values used for Tuning: [0.01, 0.001, 0.0001, 1e-05, 1e-06]\n",
      "Best Hyperparameters:\n",
      "nodes_per_layer (30, 30)\n",
      "reg_alpha 1e-06\n",
      "lr 0.0001\n",
      "epochs 150\n",
      "outact relu\n"
     ]
    }
   ],
   "source": [
    "print('Features used:', used_features)\n",
    "print('Set of Values used for Tuning:', set_of_values)\n",
    "print('Best Hyperparameters:')\n",
    "for k, v in best_hyperparams.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes_per_layer': (30, 30),\n",
       " 'reg_alpha': 1e-06,\n",
       " 'lr': 0.0001,\n",
       " 'epochs': 150,\n",
       " 'outact': 'relu'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Neural Network\n",
    "\n",
    "This part of the code trains the neural network model on the full training data using the best hyperparameters that were obtained through hyperparameter tuning.\n",
    "\n",
    "Code explanation:\n",
    "\n",
    "1. Create the `best_model` object: An instance of the `HedgeNet` class is created, which represents the neural network model used for hedging.\n",
    "\n",
    "2. Build the model: The neural network model architecture is built using the `build_model` method. The model is constructed with the following parameters:\n",
    "   - `input_shape`: The shape of the input data, which is determined by the number of features in `original_features`.\n",
    "   - `nodes_per_layer`: The number of nodes in each hidden layer. The value for this parameter is taken from the best hyperparameters found during tuning.\n",
    "   - `metrics`: A list of evaluation metrics to be used during training. In this case, it's set to only include the mean squared error (MSE).\n",
    "   - `reg_alpha`: The regularization strength (alpha) used in the model's regularization. The value is taken from the best hyperparameters.\n",
    "   - `lr`: The learning rate of the optimizer. It's also taken from the best hyperparameters.\n",
    "   - `outact`: The activation function for the output layer. It's set to the best activation function found during tuning.\n",
    "\n",
    "3. Train the model: The `fit` method is called to train the model using the training data (`df_train`) and validating it on the validation data (`df_val`). The following parameters are passed to the `fit` method:\n",
    "   - `used_features`: The list of feature names that will be used as input for the model. In this case, it's set to `original_features`, which are the features used for training.\n",
    "   - `V1`: The name of the target feature for the model, which is `'V1_n'`.\n",
    "   - `epochs`: The number of training epochs, which is set to the best number of epochs found during tuning.\n",
    "\n",
    "After training, the `best_model` will now contain the weights and parameters learned from the full training data using the best hyperparameters. This model is ready to be used for predicting the delta values on the test data and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0509 - mean_squared_error: 0.0509 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
      "Epoch 2/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0206 - mean_squared_error: 0.0205 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n",
      "Epoch 3/150\n",
      "3463/3463 [==============================] - 3s 923us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0056 - val_mean_squared_error: 0.0055\n",
      "Epoch 4/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
      "Epoch 5/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
      "Epoch 6/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0079 - mean_squared_error: 0.0078 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 7/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "Epoch 8/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 9/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0030 - val_mean_squared_error: 0.0029\n",
      "Epoch 10/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0050 - mean_squared_error: 0.0049 - val_loss: 0.0026 - val_mean_squared_error: 0.0025\n",
      "Epoch 11/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 12/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0021 - val_mean_squared_error: 0.0020\n",
      "Epoch 13/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0038 - mean_squared_error: 0.0037 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 14/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 15/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 16/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 17/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 18/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 19/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 20/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0028 - mean_squared_error: 0.0027 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 21/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 22/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0027 - mean_squared_error: 0.0026 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 23/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 24/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 25/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0026 - mean_squared_error: 0.0025 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 26/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 27/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0014 - val_mean_squared_error: 0.0013\n",
      "Epoch 28/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0025 - mean_squared_error: 0.0024 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 29/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0025 - mean_squared_error: 0.0024 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 30/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 31/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 32/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 33/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 34/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 35/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0023 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 36/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 37/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 38/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 39/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 40/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 41/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 42/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 43/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 44/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 45/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 46/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0023 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 47/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 48/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 49/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 50/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 51/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 52/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 53/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 54/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 55/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 56/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 57/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 58/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 59/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 60/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 61/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0022 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 62/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 63/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 64/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 65/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 66/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 67/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 68/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0022 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 69/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 70/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 71/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 72/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 73/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 74/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 75/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 76/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 77/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 78/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 79/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 80/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 81/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 82/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 83/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 84/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 85/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 86/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 87/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 88/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 89/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 90/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0010 - val_mean_squared_error: 9.9819e-04\n",
      "Epoch 91/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 92/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 93/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 94/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 95/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 96/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 97/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 98/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 99/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 100/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0010 - val_mean_squared_error: 9.9118e-04\n",
      "Epoch 101/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 102/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 103/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 104/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 105/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 106/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 107/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0010 - val_mean_squared_error: 9.9228e-04\n",
      "Epoch 108/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 109/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 110/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0010 - val_mean_squared_error: 9.7996e-04\n",
      "Epoch 111/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0021 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 112/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0010 - val_mean_squared_error: 9.5359e-04\n",
      "Epoch 113/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 114/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0010 - val_mean_squared_error: 9.7533e-04\n",
      "Epoch 115/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0010 - val_mean_squared_error: 9.6200e-04\n",
      "Epoch 116/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 9.8938e-04 - val_mean_squared_error: 9.3577e-04\n",
      "Epoch 117/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0019 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 118/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0019 - val_loss: 9.8516e-04 - val_mean_squared_error: 9.3104e-04\n",
      "Epoch 119/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0019 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 120/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0019 - val_loss: 9.8833e-04 - val_mean_squared_error: 9.3368e-04\n",
      "Epoch 121/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0019 - val_loss: 9.6519e-04 - val_mean_squared_error: 9.1029e-04\n",
      "Epoch 122/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0019 - val_loss: 0.0010 - val_mean_squared_error: 9.6874e-04\n",
      "Epoch 123/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0019 - val_loss: 9.5957e-04 - val_mean_squared_error: 9.0416e-04\n",
      "Epoch 124/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0019 - val_loss: 0.0010 - val_mean_squared_error: 9.5455e-04\n",
      "Epoch 125/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0020 - mean_squared_error: 0.0019 - val_loss: 9.8272e-04 - val_mean_squared_error: 9.2674e-04\n",
      "Epoch 126/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0020 - mean_squared_error: 0.0019 - val_loss: 0.0010 - val_mean_squared_error: 9.5538e-04\n",
      "Epoch 127/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 9.6119e-04 - val_mean_squared_error: 9.0477e-04\n",
      "Epoch 128/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 9.6631e-04 - val_mean_squared_error: 9.0965e-04\n",
      "Epoch 129/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 130/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 9.4867e-04 - val_mean_squared_error: 8.9151e-04\n",
      "Epoch 131/150\n",
      "3463/3463 [==============================] - 6s 2ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0010 - val_mean_squared_error: 9.5292e-04\n",
      "Epoch 132/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 9.8472e-04 - val_mean_squared_error: 9.2716e-04\n",
      "Epoch 133/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0010 - val_mean_squared_error: 9.6957e-04\n",
      "Epoch 134/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 9.7550e-04 - val_mean_squared_error: 9.1750e-04\n",
      "Epoch 135/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 9.7863e-04 - val_mean_squared_error: 9.2047e-04\n",
      "Epoch 136/150\n",
      "3463/3463 [==============================] - 5s 2ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 9.5653e-04 - val_mean_squared_error: 8.9816e-04\n",
      "Epoch 137/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 9.4000e-04 - val_mean_squared_error: 8.8152e-04\n",
      "Epoch 138/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0018 - val_loss: 9.4353e-04 - val_mean_squared_error: 8.8487e-04\n",
      "Epoch 139/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0018 - val_loss: 9.3337e-04 - val_mean_squared_error: 8.7462e-04\n",
      "Epoch 140/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0018 - val_loss: 9.1274e-04 - val_mean_squared_error: 8.5385e-04\n",
      "Epoch 141/150\n",
      "3463/3463 [==============================] - 5s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0018 - val_loss: 9.4490e-04 - val_mean_squared_error: 8.8580e-04\n",
      "Epoch 142/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0018 - val_loss: 9.1987e-04 - val_mean_squared_error: 8.6065e-04\n",
      "Epoch 143/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0018 - val_loss: 9.0624e-04 - val_mean_squared_error: 8.4684e-04\n",
      "Epoch 144/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0018 - val_loss: 9.6640e-04 - val_mean_squared_error: 9.0681e-04\n",
      "Epoch 145/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0018 - val_loss: 9.9350e-04 - val_mean_squared_error: 9.3383e-04\n",
      "Epoch 146/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0018 - val_loss: 9.2770e-04 - val_mean_squared_error: 8.6801e-04\n",
      "Epoch 147/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0018 - val_loss: 9.5723e-04 - val_mean_squared_error: 8.9729e-04\n",
      "Epoch 148/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0018 - val_loss: 9.0273e-04 - val_mean_squared_error: 8.4258e-04\n",
      "Epoch 149/150\n",
      "3463/3463 [==============================] - 4s 1ms/step - loss: 0.0019 - mean_squared_error: 0.0018 - val_loss: 9.2940e-04 - val_mean_squared_error: 8.6914e-04\n",
      "Epoch 150/150\n",
      "3463/3463 [==============================] - 6s 2ms/step - loss: 0.0019 - mean_squared_error: 0.0018 - val_loss: 0.0010 - val_mean_squared_error: 9.7144e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e6cd044130>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on the full training data using the best hyperparameters\n",
    "best_model = HedgeNet()\n",
    "best_model.build_model(\n",
    "    (len(original_features),),\n",
    "    nodes_per_layer=best_hyperparams['nodes_per_layer'],\n",
    "    metrics=['mean_squared_error'],\n",
    "    reg_alpha=best_hyperparams['reg_alpha'],\n",
    "    lr=best_hyperparams['lr'],\n",
    "    outact=best_hyperparams['outact']\n",
    ")\n",
    "best_model.fit(\n",
    "    df_train, df_val,\n",
    "    used_features=original_features,\n",
    "    V1='V1_n',\n",
    "    epochs=best_hyperparams['epochs']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model\n",
    "\n",
    "In this part of the code, the best-trained model is tested on the test data (`df_test`) using the hyperparameters that were found to be the best during the tuning process.\n",
    "\n",
    "Code explanation:\n",
    "\n",
    "1. Copy the test data: A copy of the test data is created and stored in `df_test_copy`. This copy is used to ensure that the original test data remains unchanged.\n",
    "\n",
    "2. Standardize test data: The `standardize_feature` function is used to standardize the test data with the same scaler that was used for the training and validation data. The `original_features` are standardized to have zero mean and unit variance.\n",
    "\n",
    "3. Calculate delta using the best model: The `calculate_delta` method of the `best_model` is used to calculate the delta values for the test data. The method takes the standardized test data (`df_test_copy`) and the `original_features` as input.\n",
    "\n",
    "4. Calculate NN pnl and BS pnl: The calculated delta values (`delta_nn`) are used to calculate the profit and loss (pnl) for both the neural network model (`pnl_nn`) and the Black-Scholes model (`pnl_bs`). The pnl is calculated based on the squared difference between the predicted option price and the true option price (`delta_bs`).\n",
    "\n",
    "5. Create a DataFrame with the results: The pnl values for the neural network model (`pnl_nn`) and the Black-Scholes model (`pnl_bs`) are used to create a DataFrame called `df_metrics`. The DataFrame contains two columns, 'BS' and 'NN', where the values represent the mean squared pnl for each model.\n",
    "\n",
    "At this point, `df_metrics` contains the mean squared pnl for both the neural network model and the Black-Scholes model on the test data. This information can be used to compare the performance of the neural network model against the Black-Scholes model in terms of pnl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the best model on df_test using the best hyperparameters\n",
    "df_test_copy = df_test.copy()\n",
    "df_test_copy = standardize_feature(df_test_copy, scaler, original_features)\n",
    "\n",
    " # Standardize test data\n",
    "delta_nn = best_model.calculate_delta(df_test_copy, original_features)  # Use best_model instead of creating a new instance\n",
    "\n",
    "# Calculate NN pnl and BS pnl.\n",
    "pnl_nn = calculate_pnl(df_test_copy, delta_nn)\n",
    "pnl_bs = calculate_pnl(df_test_copy, df_test_copy['delta_bs'])\n",
    "\n",
    "df_metrics = pd.DataFrame({'NN': [(pnl_nn**2).mean()]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_metrics` is a DataFrame that stores the mean squared profit and loss (pnl) values for both the neural network (NN) model and the Black-Scholes (BS) model on the test data (`df_test`). It is used to compare the performance of the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NN\n",
       "0  0.001534"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_hyperparams is a dictionary that stores the best hyperparameters found during the hyperparameter tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes_per_layer': (30, 30),\n",
       " 'reg_alpha': 1e-06,\n",
       " 'lr': 0.0001,\n",
       " 'epochs': 150,\n",
       " 'outact': 'relu'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed: 42\n",
      "Features used: ['M0_t', 'tau0_implvol0_t', 'cp_int']\n",
      "Neurons per layer: (30, 30)\n",
      "Learning rate: 0.0001\n",
      "L2 regularization alpha: 1e-06\n",
      "Number of training epochs: 150\n"
     ]
    }
   ],
   "source": [
    "print('Random seed:', seed),\n",
    "print('Features used:', used_features),\n",
    "print('Neurons per layer:', best_hyperparams['nodes_per_layer']),\n",
    "print('Learning rate:', best_hyperparams['lr']),\n",
    "print('L2 regularization alpha:', best_hyperparams['reg_alpha']),\n",
    "print('Number of training epochs:', best_hyperparams['epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Results\n",
    "\n",
    "Now we generate a scatter plot to visualize the predicted option prices (V1) by the neural network (NN) model against the actual option prices (V1_n) from the test data (df_test_copy).\n",
    "\n",
    "#### The insights from the scatter plot:\n",
    "\n",
    "1. Model Accuracy: By examining how closely the points align with the diagonal line, you can assess the overall accuracy of the Neural Network model. Points close to the diagonal indicate more accurate predictions, while points away from the diagonal represent prediction errors.\n",
    "\n",
    "2. Underestimation/Overestimation: If the points tend to cluster below or above the diagonal, it suggests that the Neural Network is systematically underestimating or overestimating option prices.\n",
    "\n",
    "3. Prediction Range: The spread of points along the diagonal can indicate the range of option prices where the model performs well and where it struggles to make accurate predictions.\n",
    "\n",
    "4. Outliers: Any data points that deviate significantly from the diagonal represent potential outliers where the model has difficulty capturing complex patterns.\n",
    "\n",
    "5. Model Consistency: If the points are closely concentrated around the diagonal, it indicates that the Neural Network consistently predicts option prices close to the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df_test_copy['V1_n'], df_test_copy['V1_n'] + pnl_nn, label='Neural Network Predictions', alpha=0.5)\n",
    "plt.xlabel('Actual V1')\n",
    "plt.ylabel('Predicted V1')\n",
    "plt.title('Scatter Plot: Predicted vs. Actual V1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below, plots a line chart that compares the actual portfolio value (V1) with the predictions made by the Neural Network (NN) over time.\n",
    "\n",
    "#### Insights from time chart:\n",
    "\n",
    "1. Model Performance: By comparing the actual portfolio value (represented by the 'Actual V1' line) with the Neural Network's predictions (represented by the 'Neural Network Predictions' line), you can assess how well the model performs in capturing the dynamics of the portfolio value over time.\n",
    "\n",
    "2. Accuracy: If the 'Neural Network Predictions' line closely follows the 'Actual V1' line, it indicates that the Neural Network is making accurate predictions, and the model is capturing the underlying patterns in the portfolio value effectively.\n",
    "\n",
    "3. Prediction Lag: Any deviation or delay between the 'Neural Network Predictions' line and the 'Actual V1' line could suggest that the model is lagging in reacting to changes in the portfolio value. This could be an area for improvement in the model's predictive capabilities.\n",
    "\n",
    "4. Volatility: Differences in the slopes or fluctuations between the two lines can indicate differences in volatility estimation. If the Neural Network's predictions show more significant swings than the actual portfolio value, it may suggest that the model is overestimating volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(df_test_copy['V1_n'], label='Actual V1')\n",
    "plt.plot(df_test_copy['V1_n'] + pnl_nn, label='Neural Network Predictions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Portfolio Value (V1)')\n",
    "plt.title('Comparison of Portfolio Value Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is plotting a line graph with markers showing the difference between the actual portfolio value (`V1_n`) and the predicted portfolio value using the Neural Network (`V1_n + pnl_nn`) over time. The plot of the difference between the actual and predicted portfolio values provides valuable insight into the accuracy of the neural network's predictions.\n",
    "\n",
    "\n",
    "#### Insights from the  difference plot:\n",
    "\n",
    "1. Prediction Accuracy: The plot shows how well the Neural Network model is able to predict the actual V1 values. When the line is close to zero, it indicates that the predictions are accurate and align well with the actual values.\n",
    "\n",
    "2. Model Performance Over Time: The plot provides a visual representation of the model's performance over time. It allows you to observe if there are specific periods where the model performs better or worse.\n",
    "\n",
    "3. Trend and Patterns: Any trends or patterns in the difference between the actual and predicted values can be observed. Consistent patterns in the difference may indicate certain market conditions or data patterns where the model struggles to make accurate predictions.\n",
    "\n",
    "4. Outliers and Anomalies: Large spikes or outliers in the difference may indicate instances where the model fails to capture certain market behaviors or faces challenges in making accurate predictions.\n",
    "\n",
    "5. Model Evaluation: The plot can be used for model evaluation and comparison against other models or benchmarks. For example, you can overlay the performance of other models or the Black-Scholes model to see how the Neural Network model fares in comparison.\n",
    "\n",
    "6. Identifying Improvements: If there are consistent patterns of high differences, it may suggest areas for model improvement or data preprocessing to enhance prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "diff_nn = df_test_copy['V1_n'] - (df_test_copy['V1_n'] + pnl_nn)\n",
    "plt.plot(diff_nn, label='Neural Network Difference', marker='o')\n",
    "plt.xlabel('Time')\n",
    "plt.xticks([])\n",
    "plt.ylabel('Difference')\n",
    "plt.title('Difference between Actual V1 and Neural Network Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plotted duagram below shows, \"HMSE\" which stands for \"Hedging Mean Squared Error.\" It represents the mean squared error between the actual portfolio value (V1) and the portfolio value predicted by the Neural Network model after applying a hedging strategy.\n",
    "\n",
    "#### Insights from the MSHE diagram:\n",
    "\n",
    "1. Hedging Performance: The plot shows how well the Neural Network model's hedging strategy performs over time. A lower HMSE indicates that the model's hedging strategy is effectively reducing the risk in the portfolio.\n",
    "\n",
    "2. Hedging Accuracy: The HMSE gives an idea of the accuracy of the hedging strategy. A lower value indicates that the model's hedging approach is better at minimizing the variance between the predicted portfolio value and the actual portfolio value.\n",
    "\n",
    "3. Time-Varying Performance: The plot allows us to observe how the hedging performance changes over different periods. If the HMSE fluctuates significantly over time, it may suggest that the effectiveness of the hedging strategy varies with market conditions or underlying asset behavior.\n",
    "\n",
    "4. Model Performance Evaluation: Comparing the HMSE of the Neural Network's hedging strategy against other models or benchmarks can help evaluate the effectiveness of the model's hedging approach.\n",
    "\n",
    "5. Identification of Risky Periods: Significant spikes or peaks in HMSE may indicate periods when the hedging strategy struggled to minimize risk effectively. These periods might be associated with market volatility or specific events impacting the underlying assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate HMSE for Neural Network predictions\n",
    "hmse_nn = (df_test_copy['V1_n'] - (df_test_copy['V1_n'] + pnl_nn)) ** 2\n",
    "\n",
    "# Plot HMSE values\n",
    "plt.plot(hmse_nn, label='Neural Network HMSE', marker='o')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('HMSE')\n",
    "plt.title('HMSE between Actual V1 and Predictions')\n",
    "plt.legend()\n",
    "plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0015342187035403355\n"
     ]
    }
   ],
   "source": [
    "# Print the overal HMSE\n",
    "print(np.mean(hmse_nn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
